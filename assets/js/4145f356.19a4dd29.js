"use strict";(globalThis.webpackChunkdialai_website=globalThis.webpackChunkdialai_website||[]).push([[6707],{6996(e,t,i){i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"ecosystem","title":"Ecosystem","description":"DIAL measures whether AI specialists can reliably replicate human decisions, then progressively delegates when alignment is demonstrated. Several open-source projects share overlapping goals. This page lists the 10 closest.","source":"@site/docs/ecosystem.md","sourceDirName":".","slug":"/ecosystem","permalink":"/dialai/docs/ecosystem","draft":false,"unlisted":false,"editUrl":"https://github.com/eloquentanalytics/dialai/tree/main/website/docs/ecosystem.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"Examples","permalink":"/dialai/docs/examples/intro"}}');var s=i(4848),r=i(8453);const o={sidebar_position:7},a="Ecosystem",l={},c=[{value:"Optimization",id:"optimization",level:2},{value:"DSPy",id:"dspy",level:3},{value:"TensorZero",id:"tensorzero",level:3},{value:"TextGrad",id:"textgrad",level:3},{value:"Evaluation",id:"evaluation",level:2},{value:"Inspect AI",id:"inspect-ai",level:3},{value:"promptfoo",id:"promptfoo",level:3},{value:"DeepEval",id:"deepeval",level:3},{value:"Multi-Agent",id:"multi-agent",level:2},{value:"AutoGen",id:"autogen",level:3},{value:"CrewAI",id:"crewai",level:3},{value:"Agent Training",id:"agent-training",level:2},{value:"Agent Lightning",id:"agent-lightning",level:3},{value:"ADAS",id:"adas",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const t={a:"a",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"ecosystem",children:"Ecosystem"})}),"\n",(0,s.jsx)(t.p,{children:"DIAL measures whether AI specialists can reliably replicate human decisions, then progressively delegates when alignment is demonstrated. Several open-source projects share overlapping goals. This page lists the 10 closest."}),"\n",(0,s.jsxs)(t.p,{children:["For conceptual comparisons (agent frameworks, RLHF, MoE), see ",(0,s.jsx)(t.a,{href:"/dialai/docs/concepts/related-work",children:"Related Work"}),"."]}),"\n",(0,s.jsx)(t.h2,{id:"optimization",children:"Optimization"}),"\n",(0,s.jsx)(t.h3,{id:"dspy",children:"DSPy"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://github.com/stanfordnlp/dspy",children:"github.com/stanfordnlp/dspy"})})," \xb7 Stanford NLP \xb7 MIT"]}),"\n",(0,s.jsxs)(t.p,{children:["A framework for ",(0,s.jsx)(t.em,{children:"programming"}),", not prompting, language models. Optimizers like MIPROv2 automatically search over instructions, demonstrations, and weights to maximize a metric. The closest philosophical match to DIAL: both treat LLM behavior as tunable against measurable objectives, with DSPy optimizing at the prompt level and DIAL at the decision level."]}),"\n",(0,s.jsx)(t.h3,{id:"tensorzero",children:"TensorZero"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://github.com/tensorzero/tensorzero",children:"github.com/tensorzero/tensorzero"})})," \xb7 Apache 2.0"]}),"\n",(0,s.jsx)(t.p,{children:"Unifies an LLM gateway, observability, and optimization. Collects human feedback in production to optimize prompts and models with built-in A/B testing. Its optimization loop (inference, feedback, optimize) mirrors DIAL's cycle (propose, vote, consensus, refine)."}),"\n",(0,s.jsx)(t.h3,{id:"textgrad",children:"TextGrad"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://github.com/zou-group/textgrad",children:"github.com/zou-group/textgrad"})})," \xb7 Stanford / Zou Group"]}),"\n",(0,s.jsx)(t.p,{children:'Backpropagates textual feedback from LLMs to improve components of compound AI systems, using PyTorch-like abstractions on natural language. Like DIAL, it iteratively improves outputs using feedback signals: TextGrad via "textual gradients," DIAL via vote results and alignment scores.'}),"\n",(0,s.jsx)(t.h2,{id:"evaluation",children:"Evaluation"}),"\n",(0,s.jsx)(t.h3,{id:"inspect-ai",children:"Inspect AI"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://github.com/UKGovernmentBEIS/inspect_ai",children:"github.com/UKGovernmentBEIS/inspect_ai"})})," \xb7 UK AI Safety Institute"]}),"\n",(0,s.jsx)(t.p,{children:"Structured, reproducible LLM evaluations with opinionated primitives (Dataset, Task, Solver, Scorer) and 100+ built-in evals. Its Solver/Scorer pattern parallels DIAL's Specialist/Vote pattern, and both support multi-turn agent workflows with customizable scoring."}),"\n",(0,s.jsx)(t.h3,{id:"promptfoo",children:"promptfoo"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://github.com/promptfoo/promptfoo",children:"github.com/promptfoo/promptfoo"})})," \xb7 MIT"]}),"\n",(0,s.jsx)(t.p,{children:"Test-driven LLM evaluation with declarative YAML config, assertions from string matching to LLM-as-judge, and comparison across 50+ providers. Like DIAL, it compares multiple configurations against expected outputs with structured scoring, with a focus on CI/CD integration."}),"\n",(0,s.jsx)(t.h3,{id:"deepeval",children:"DeepEval"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://github.com/confident-ai/deepeval",children:"github.com/confident-ai/deepeval"})})," \xb7 Confident AI"]}),"\n",(0,s.jsx)(t.p,{children:"14+ built-in metrics including hallucination, faithfulness, and conversational metrics like knowledge retention. DIAL's consensus mechanism can use these kinds of alignment metrics to drive delegation decisions."}),"\n",(0,s.jsx)(t.h2,{id:"multi-agent",children:"Multi-Agent"}),"\n",(0,s.jsx)(t.h3,{id:"autogen",children:"AutoGen"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://github.com/microsoft/autogen",children:"github.com/microsoft/autogen"})})," \xb7 Microsoft \xb7 MIT"]}),"\n",(0,s.jsx)(t.p,{children:"Multi-agent cooperation via automated chat, with AgentOptimizer for iteratively improving agent behavior from historical performance. The strongest multi-agent overlap with DIAL: both use multi-specialist architectures and historical performance to guide optimization toward trust-calibrated delegation."}),"\n",(0,s.jsx)(t.h3,{id:"crewai",children:"CrewAI"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://github.com/crewAIInc/crewAI",children:"github.com/crewAIInc/crewAI"})})}),"\n",(0,s.jsx)(t.p,{children:'Role-based multi-agent orchestration with "Crews" and "Flows." Its role-based design parallels DIAL\'s proposer/voter roles, and a CrewAI agent can serve as a DIAL specialist.'}),"\n",(0,s.jsx)(t.h2,{id:"agent-training",children:"Agent Training"}),"\n",(0,s.jsx)(t.h3,{id:"agent-lightning",children:"Agent Lightning"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://github.com/microsoft/agent-lightning",children:"github.com/microsoft/agent-lightning"})})," \xb7 Microsoft \xb7 MIT"]}),"\n",(0,s.jsx)(t.p,{children:"Makes agents trainable via reinforcement learning with hierarchical credit assignment, determining how much each LLM call contributed to the outcome. Like DIAL, it decomposes multi-step behavior into individually evaluable decisions, using RL rewards where DIAL uses human-alignment votes."}),"\n",(0,s.jsx)(t.h3,{id:"adas",children:"ADAS"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://github.com/ShengranHu/ADAS",children:"github.com/ShengranHu/ADAS"})})," \xb7 ICLR 2025"]}),"\n",(0,s.jsx)(t.p,{children:"A meta-agent iteratively programs new agents, tests them, and archives successful designs to inform future iterations. Both ADAS and DIAL use iterative optimization over agent configurations guided by empirical performance, with ADAS searching over architectures and DIAL optimizing specialist strategy, prompts, and model mix."}),"\n",(0,s.jsx)(t.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Tool"}),(0,s.jsx)(t.th,{children:"Focus"}),(0,s.jsx)(t.th,{children:"Overlap with DIAL"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"DSPy"})}),(0,s.jsx)(t.td,{children:"Prompt/weight optimization"}),(0,s.jsx)(t.td,{children:"Iterative optimization against measurable objectives"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"TensorZero"})}),(0,s.jsx)(t.td,{children:"Production LLM optimization"}),(0,s.jsx)(t.td,{children:"Human feedback-driven improvement loop"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"TextGrad"})}),(0,s.jsx)(t.td,{children:"Textual backpropagation"}),(0,s.jsx)(t.td,{children:"Feedback-driven component optimization"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Inspect AI"})}),(0,s.jsx)(t.td,{children:"Safety/capability evaluation"}),(0,s.jsx)(t.td,{children:"Structured scoring, multi-turn workflows"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"promptfoo"})}),(0,s.jsx)(t.td,{children:"Test-driven LLM evaluation"}),(0,s.jsx)(t.td,{children:"Comparing configurations against expected outputs"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"DeepEval"})}),(0,s.jsx)(t.td,{children:"LLM metrics"}),(0,s.jsx)(t.td,{children:"Customizable scoring with conversational metrics"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"AutoGen"})}),(0,s.jsx)(t.td,{children:"Multi-agent collaboration"}),(0,s.jsx)(t.td,{children:"Multi-agent architecture + iterative optimization"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"CrewAI"})}),(0,s.jsx)(t.td,{children:"Multi-agent orchestration"}),(0,s.jsx)(t.td,{children:"Role-based specialist coordination"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Agent Lightning"})}),(0,s.jsx)(t.td,{children:"RL-based agent training"}),(0,s.jsx)(t.td,{children:"Per-decision credit assignment"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"ADAS"})}),(0,s.jsx)(t.td,{children:"Automated agent design"}),(0,s.jsx)(t.td,{children:"Meta-optimization of agent configurations"})]})]})]}),"\n",(0,s.jsxs)(t.p,{children:["These tools are complementary. Many can serve as DIAL specialists or provide the underlying infrastructure that DIAL wraps. DIAL's unique contribution is combining ",(0,s.jsx)(t.strong,{children:"runtime human-alignment measurement"})," with ",(0,s.jsx)(t.strong,{children:"progressive delegation"}),", continuously deciding ",(0,s.jsx)(t.em,{children:"who should decide"})," based on empirical evidence."]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453(e,t,i){i.d(t,{R:()=>o,x:()=>a});var n=i(6540);const s={},r=n.createContext(s);function o(e){const t=n.useContext(r);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),n.createElement(r.Provider,{value:t},e.children)}}}]);