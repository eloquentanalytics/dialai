"use strict";(globalThis.webpackChunkdialai_website=globalThis.webpackChunkdialai_website||[]).push([[4583],{8198(e,s,a){a.r(s),a.d(s,{default:()=>m});var i=a(4164),c=a(8774),t=a(4586),n=a(9139),r=a(1107);const l="heroBanner_qdFl",d="buttons_AeoN";var o=a(4848);function h(){const{siteConfig:e}=(0,t.A)();return(0,o.jsx)("header",{className:(0,i.A)("hero hero--primary",l),children:(0,o.jsxs)("div",{className:"container",children:[(0,o.jsx)(r.A,{as:"h1",className:"hero__title",children:e.title}),(0,o.jsx)("p",{className:"hero__subtitle",children:e.tagline}),(0,o.jsxs)("div",{className:d,children:[(0,o.jsx)(c.A,{className:"button button--secondary button--lg",to:"/docs/intro",children:"Get Started"}),(0,o.jsx)(c.A,{className:"button button--outline button--secondary button--lg",to:"https://github.com/eloquentanalytics/dialai",style:{marginLeft:"1rem"},children:"GitHub"})]})]})})}function m(){const{siteConfig:e}=(0,t.A)();return(0,o.jsxs)(n.A,{title:`${e.title}`,description:"Dynamic Integration between AI and Labor - A coordination framework for AI and human specialists making decisions together within state machines.",children:[(0,o.jsx)(h,{}),(0,o.jsx)("main",{children:(0,o.jsx)("div",{className:"container margin-vert--lg",children:(0,o.jsxs)("div",{className:"row",children:[(0,o.jsx)("div",{className:"col col--4",children:(0,o.jsxs)("div",{className:"card",children:[(0,o.jsx)("div",{className:"card__header",children:(0,o.jsx)(r.A,{as:"h3",children:"Human Primacy"})}),(0,o.jsx)("div",{className:"card__body",children:(0,o.jsx)("p",{children:"The human is always right \u2014 not because humans are infallible, but because humans have context that AI cannot access. AI specialists learn to predict human choices, not to replace human judgment."})})]})}),(0,o.jsx)("div",{className:"col col--4",children:(0,o.jsxs)("div",{className:"card",children:[(0,o.jsx)("div",{className:"card__header",children:(0,o.jsx)(r.A,{as:"h3",children:"Progressive Collapse"})}),(0,o.jsx)("div",{className:"card__body",children:(0,o.jsx)("p",{children:"Over repeated decision cycles, measuring how well AI predicts human choices causes the multi-agent deliberation structure to progressively collapse into deterministic execution."})})]})}),(0,o.jsx)("div",{className:"col col--4",children:(0,o.jsxs)("div",{className:"card",children:[(0,o.jsx)("div",{className:"card__header",children:(0,o.jsx)(r.A,{as:"h3",children:"Empirical Trust"})}),(0,o.jsx)("div",{className:"card__body",children:(0,o.jsx)("p",{children:"Trust is earned through demonstrated alignment with human decisions, not assumed. LLM specialists start with weight 0.0 and must prove their value."})})]})})]})})})]})}}}]);