"use strict";(globalThis.webpackChunkdialai_website=globalThis.webpackChunkdialai_website||[]).push([[6289],{9101(e,t,n){n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>a,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"concepts/related-work","title":"Related Work","description":"DIAL solves a different problem than most AI frameworks. Understanding the distinction helps clarify what DIAL is, and what it isn\'t.","source":"@site/docs/concepts/related-work.md","sourceDirName":"concepts","slug":"/concepts/related-work","permalink":"/dialai/docs/concepts/related-work","draft":false,"unlisted":false,"editUrl":"https://github.com/eloquentanalytics/dialai/tree/main/website/docs/concepts/related-work.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Human Primacy","permalink":"/dialai/docs/concepts/human-primacy"},"next":{"title":"State Machines","permalink":"/dialai/docs/guides/state-machines"}}');var i=n(4848),r=n(8453);const a={sidebar_position:6},o="Related Work",l={},d=[{value:"What DIAL Is",id:"what-dial-is",level:2},{value:"How DIAL Relates to Other Approaches",id:"how-dial-relates-to-other-approaches",level:2},{value:"Agent Frameworks (LangGraph, LangChain, CrewAI)",id:"agent-frameworks-langgraph-langchain-crewai",level:3},{value:"Multi-Agent Debate",id:"multi-agent-debate",level:3},{value:"Constitutional AI / RLHF",id:"constitutional-ai--rlhf",level:3},{value:"Mixture of Experts (MoE)",id:"mixture-of-experts-moe",level:3},{value:"Using DIAL with Other Systems",id:"using-dial-with-other-systems",level:2}];function h(e){const t={em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"related-work",children:"Related Work"})}),"\n",(0,i.jsx)(t.p,{children:"DIAL solves a different problem than most AI frameworks. Understanding the distinction helps clarify what DIAL is, and what it isn't."}),"\n",(0,i.jsx)(t.h2,{id:"what-dial-is",children:"What DIAL Is"}),"\n",(0,i.jsxs)(t.p,{children:["DIAL is a ",(0,i.jsx)(t.strong,{children:"measurement and delegation harness"}),". It answers the question: ",(0,i.jsx)(t.em,{children:"can this AI specialist reliably predict what this human would choose, in this specific context?"})," When the answer is yes (empirically demonstrated over repeated decisions), DIAL progressively delegates. When alignment degrades, it reverts."]}),"\n",(0,i.jsxs)(t.p,{children:["DIAL is not an agent framework, an alignment technique, or a model architecture. It can ",(0,i.jsx)(t.strong,{children:"wrap"})," any of them."]}),"\n",(0,i.jsx)(t.h2,{id:"how-dial-relates-to-other-approaches",children:"How DIAL Relates to Other Approaches"}),"\n",(0,i.jsxs)(t.p,{children:["The key dimension of comparison is ",(0,i.jsx)(t.strong,{children:"where ground truth comes from"}),": the signal used to judge whether AI behavior is correct."]}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:"Approach"}),(0,i.jsx)(t.th,{children:"Ground truth source"}),(0,i.jsx)(t.th,{children:"When trust is established"}),(0,i.jsx)(t.th,{children:"Can trust change at runtime?"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"LangGraph / LangChain"}),(0,i.jsx)(t.td,{children:"Designer's predefined graph"}),(0,i.jsx)(t.td,{children:"Before deployment"}),(0,i.jsx)(t.td,{children:"No"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Multi-agent debate"}),(0,i.jsx)(t.td,{children:"Human judges per decision"}),(0,i.jsx)(t.td,{children:"Each decision"}),(0,i.jsx)(t.td,{children:"No (static)"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Constitutional AI / RLHF"}),(0,i.jsx)(t.td,{children:"Offline training signal"}),(0,i.jsx)(t.td,{children:"Training time"}),(0,i.jsx)(t.td,{children:"No"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Mixture of Experts"}),(0,i.jsx)(t.td,{children:"Gating network"}),(0,i.jsx)(t.td,{children:"Training time"}),(0,i.jsx)(t.td,{children:"No"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.strong,{children:"DIAL"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.strong,{children:"Human's actual runtime choices"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.strong,{children:"Empirically, per decision cycle"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.strong,{children:"Yes (progressive collapse + trip line)"})})]})]})]}),"\n",(0,i.jsx)(t.h3,{id:"agent-frameworks-langgraph-langchain-crewai",children:"Agent Frameworks (LangGraph, LangChain, CrewAI)"}),"\n",(0,i.jsxs)(t.p,{children:["Agent frameworks define ",(0,i.jsx)(t.strong,{children:"how"})," an AI system operates: the graph of states, tools, and control flow. DIAL defines ",(0,i.jsx)(t.strong,{children:"whether"})," an AI system should be trusted to operate autonomously at each decision point."]}),"\n",(0,i.jsxs)(t.p,{children:["These are complementary. A DIAL specialist can ",(0,i.jsx)(t.em,{children:"be"})," a LangGraph agent. DIAL wraps the agent and measures whether its decisions match human choices. The agent framework handles execution; DIAL handles trust calibration."]}),"\n",(0,i.jsx)(t.h3,{id:"multi-agent-debate",children:"Multi-Agent Debate"}),"\n",(0,i.jsx)(t.p,{children:"Multi-agent debate uses multiple AI models to argue and a human to judge. DIAL's voting mechanism is superficially similar, but the purpose differs: debate aims to improve answer quality through adversarial argument; DIAL aims to measure which specialist best predicts the human, with the goal of eventually removing the human from routine decisions."}),"\n",(0,i.jsx)(t.h3,{id:"constitutional-ai--rlhf",children:"Constitutional AI / RLHF"}),"\n",(0,i.jsx)(t.p,{children:"Constitutional AI and RLHF train models against offline signals: a constitution document or human preference data collected in advance. The trust relationship is fixed at training time. DIAL's ground truth is the human's live, runtime choices in a specific operational context. Trust evolves continuously, per-specialist, per-state. A constitutionally-trained model can serve as a DIAL specialist; DIAL then measures whether the training generalizes to this particular human's preferences."}),"\n",(0,i.jsx)(t.h3,{id:"mixture-of-experts-moe",children:"Mixture of Experts (MoE)"}),"\n",(0,i.jsx)(t.p,{children:"MoE architectures route inputs to specialized sub-networks via a learned gating function. The analogy to DIAL's specialist selection is real but shallow: MoE routing is learned at training time and frozen; DIAL's trust in specialists updates at runtime based on human feedback. MoE optimizes for task performance; DIAL optimizes for human prediction."}),"\n",(0,i.jsx)(t.h2,{id:"using-dial-with-other-systems",children:"Using DIAL with Other Systems"}),"\n",(0,i.jsx)(t.p,{children:"DIAL is designed to be wrapped around existing AI systems, not to replace them:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Your agent framework"})," handles task execution, tool calls, and control flow"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Your model"})," handles reasoning, generation, and tool use"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"DIAL"})," handles the question: ",(0,i.jsx)(t.em,{children:"should this agent/model be trusted to act autonomously here, or does a human need to decide?"})]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"The specialist interface is intentionally minimal: anything that can propose a state transition and compare two proposals can participate in DIAL's decision cycle."})]})}function c(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},8453(e,t,n){n.d(t,{R:()=>a,x:()=>o});var s=n(6540);const i={},r=s.createContext(i);function a(e){const t=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(r.Provider,{value:t},e.children)}}}]);