"use strict";(globalThis.webpackChunkdialai_website=globalThis.webpackChunkdialai_website||[]).push([[3976],{2053(e,s,t){t.r(s),t.d(s,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"intro","title":"Introduction to DIAL","description":"DIAL (Dynamic Integration between AI and Labor) is a coordination framework for AI and human specialists making decisions together within state machines.","source":"@site/docs/intro.md","sourceDirName":".","slug":"/intro","permalink":"/dialai/docs/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/eloquentanalytics/dialai/tree/main/website/docs/intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","next":{"title":"Installation","permalink":"/dialai/docs/getting-started/installation"}}');var n=t(4848),a=t(8453);const r={sidebar_position:1},o="Introduction to DIAL",l={},c=[{value:"Why DIAL?",id:"why-dial",level:2},{value:"The Core Insight",id:"the-core-insight",level:2},{value:"Three Foundational Principles",id:"three-foundational-principles",level:2},{value:"1. Human Primacy",id:"1-human-primacy",level:3},{value:"2. Progressive Collapse",id:"2-progressive-collapse",level:3},{value:"3. Empirical Trust",id:"3-empirical-trust",level:3},{value:"What DIAL Is Not",id:"what-dial-is-not",level:2},{value:"How It Works",id:"how-it-works",level:2},{value:"What&#39;s Next?",id:"whats-next",level:2},{value:"Key Terminology",id:"key-terminology",level:2}];function h(e){const s={blockquote:"blockquote",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(s.header,{children:(0,n.jsx)(s.h1,{id:"introduction-to-dial",children:"Introduction to DIAL"})}),"\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"DIAL"})," (Dynamic Integration between AI and Labor) is a coordination framework for AI and human specialists making decisions together within state machines."]}),"\n",(0,n.jsx)(s.h2,{id:"why-dial",children:"Why DIAL?"}),"\n",(0,n.jsx)(s.p,{children:"The promise of AI is efficiency\u2014faster, cheaper execution of narrow tasks. But the question organizations face isn't \"Can AI do this?\" It's:"}),"\n",(0,n.jsxs)(s.blockquote,{children:["\n",(0,n.jsx)(s.p,{children:(0,n.jsx)(s.strong,{children:"How do you know \u2014 in dollars, time, and quality \u2014 exactly what it would cost to turn any task over to a minimally competent AI decision-maker? And how involved should humans remain as quality control?"})}),"\n"]}),"\n",(0,n.jsxs)(s.p,{children:["DIAL provides the answer through ",(0,n.jsx)(s.strong,{children:"empirical measurement"}),", not speculation."]}),"\n",(0,n.jsx)(s.h2,{id:"the-core-insight",children:"The Core Insight"}),"\n",(0,n.jsx)(s.p,{children:"AI models are created by us. Their works are based on our works. They cannot be better than us because they can never have as large a context as we do."}),"\n",(0,n.jsxs)(s.p,{children:["An AI model operates on a bounded context window\u2014thousands or millions of tokens. A human operates on a ",(0,n.jsx)(s.strong,{children:"lifetime of embodied experience"}),", tacit knowledge, institutional context, and real-time sensory input that no model has access to."]}),"\n",(0,n.jsx)(s.p,{children:"The human knows things they cannot tell the machine."}),"\n",(0,n.jsx)(s.h2,{id:"three-foundational-principles",children:"Three Foundational Principles"}),"\n",(0,n.jsx)(s.h3,{id:"1-human-primacy",children:"1. Human Primacy"}),"\n",(0,n.jsx)(s.p,{children:"The human is always right\u2014not because humans are infallible, but because humans have context that AI cannot access."}),"\n",(0,n.jsx)(s.p,{children:"It is always safer for the AI to assume the human had reasons, just as it is safer for a child to defer to a parent\u2014not because the parent is infallible, but because the parent has context the child cannot access."}),"\n",(0,n.jsx)(s.p,{children:"An AI specialist should choose what the human would choose, even if its own reasoning disagrees. It will be judged on alignment with the human, and that judgment is correct."}),"\n",(0,n.jsx)(s.h3,{id:"2-progressive-collapse",children:"2. Progressive Collapse"}),"\n",(0,n.jsxs)(s.p,{children:["Over repeated decision cycles, measuring how well AI predicts human choices causes the multi-agent deliberation structure to ",(0,n.jsx)(s.strong,{children:"progressively collapse into deterministic execution"}),"."]}),"\n",(0,n.jsx)(s.p,{children:"This collapse is emergent, not designed. As AI specialists prove their alignment with human judgment through accumulated data, the expensive deliberation process naturally simplifies."}),"\n",(0,n.jsx)(s.h3,{id:"3-empirical-trust",children:"3. Empirical Trust"}),"\n",(0,n.jsx)(s.p,{children:"Trust is earned through demonstrated alignment with human decisions, not assumed."}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"LLM specialists start with weight 0.0"}),"\u2014no autonomous authority"]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Humans have weight 1.0"}),"\u2014full authority"]}),"\n",(0,n.jsx)(s.li,{children:"AI specialists earn trust by accurately predicting what humans would choose"}),"\n",(0,n.jsx)(s.li,{children:"Trust is measured in precise terms: cost per decision, latency, alignment rate"}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"what-dial-is-not",children:"What DIAL Is Not"}),"\n",(0,n.jsx)(s.p,{children:"DIAL is not about AI replacing humans. It's about discovering\u2014with precise cost data\u2014which decisions are narrow enough for AI to handle, and what the ongoing human quality-control cost is to maintain that delegation over time."}),"\n",(0,n.jsxs)(s.p,{children:["The value of AI is not superiority. ",(0,n.jsx)(s.strong,{children:"It is efficiency."})," AI is faster and cheaper at narrow tasks where the required context fits within the model's window."]}),"\n",(0,n.jsx)(s.h2,{id:"how-it-works",children:"How It Works"}),"\n",(0,n.jsxs)(s.ol,{children:["\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Model the task as a state machine"})," \u2014 Define states, transitions, and decision prompts"]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Register specialists"})," \u2014 Both AI models and humans that can propose transitions and vote"]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Run decision cycles"})," \u2014 Solicit \u2192 Propose \u2192 Vote \u2192 Arbitrate \u2192 Execute"]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Measure everything"})," \u2014 Cost, latency, and alignment with human choices"]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Adjust weights"})," \u2014 Specialists that predict human choices accurately earn more trust"]}),"\n"]}),"\n",(0,n.jsx)(s.mermaid,{value:"graph LR\n    A[Solicit] --\x3e B[Propose]\n    B --\x3e C[Vote]\n    C --\x3e D[Arbitrate]\n    D --\x3e E[Execute]\n    E --\x3e A"}),"\n",(0,n.jsx)(s.h2,{id:"whats-next",children:"What's Next?"}),"\n",(0,n.jsxs)("div",{className:"row",children:[(0,n.jsx)("div",{className:"col col--6",children:(0,n.jsxs)("div",{className:"card margin-bottom--md",children:[(0,n.jsx)("div",{className:"card__header",children:(0,n.jsx)("h3",{children:"\ud83d\ude80 Get Started"})}),(0,n.jsxs)("div",{className:"card__body",children:[(0,n.jsx)("p",{children:"Install DIAL and run your first state machine with AI and human specialists."}),(0,n.jsx)("a",{href:"/docs/getting-started/installation",className:"button button--primary",children:"Installation Guide \u2192"})]})]})}),(0,n.jsx)("div",{className:"col col--6",children:(0,n.jsxs)("div",{className:"card margin-bottom--md",children:[(0,n.jsx)("div",{className:"card__header",children:(0,n.jsx)("h3",{children:"\ud83d\udcda Learn Concepts"})}),(0,n.jsxs)("div",{className:"card__body",children:[(0,n.jsx)("p",{children:"Understand sessions, specialists, decision cycles, and arbitration strategies."}),(0,n.jsx)("a",{href:"/docs/concepts/intro",className:"button button--secondary",children:"Explore Concepts \u2192"})]})]})})]}),"\n",(0,n.jsx)(s.h2,{id:"key-terminology",children:"Key Terminology"}),"\n",(0,n.jsxs)(s.table,{children:[(0,n.jsx)(s.thead,{children:(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.th,{children:"Term"}),(0,n.jsx)(s.th,{children:"Definition"})]})}),(0,n.jsxs)(s.tbody,{children:[(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.strong,{children:"Session"})}),(0,n.jsx)(s.td,{children:"An instance of a state machine being navigated by specialists"})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.strong,{children:"Specialist"})}),(0,n.jsx)(s.td,{children:"A pluggable actor (AI or human) that proposes transitions or votes"})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.strong,{children:"Decision Cycle"})}),(0,n.jsx)(s.td,{children:"The five-phase process: Solicit \u2192 Propose \u2192 Vote \u2192 Arbitrate \u2192 Execute"})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.strong,{children:"Arbiter"})}),(0,n.jsx)(s.td,{children:"The strategy that evaluates consensus and determines when a proposal wins"})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.strong,{children:"Weight"})}),(0,n.jsx)(s.td,{children:"A specialist's voting authority, earned through alignment with human choices"})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.strong,{children:"Risk Dial"})}),(0,n.jsx)(s.td,{children:"A confidence threshold that gates whether the system takes a fast or slow path"})]})]})]})]})}function d(e={}){const{wrapper:s}={...(0,a.R)(),...e.components};return s?(0,n.jsx)(s,{...e,children:(0,n.jsx)(h,{...e})}):h(e)}}}]);