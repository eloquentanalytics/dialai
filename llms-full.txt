# DIAL

> Dynamic Integration between AI and Labor

This file contains all documentation content in a single document following the llmstxt.org standard.

## Agent Experience Development


DIAL is designed for LLM-driven agents as first-class participants. Every design decision optimizes for agents that need to understand, integrate with, and act within the framework autonomously: the API shape, the documentation format, and the way changelogs are written.

## Agents as Participants

The specialist abstraction exists so that LLM agents can register themselves as proposers and voters in a decision cycle. An agent reading a state machine definition can determine what state the session is in, what transitions are available, and what the prompt is asking. It can then submit a proposal or cast a vote using the same API a human would use.

This is the point. DIAL does not treat agents as a backend detail or an orchestration layer. Agents sit alongside humans in the decision cycle and are evaluated by the same arbiter under the same rules. The difference is that human votes override, because [human primacy](./concepts/human-primacy.md) is a safety constraint on the system.

## Spec-Driven Development

The source of truth for DIAL is its documentation. The code in `/src` is generated from the documentation files, not the other way around.

This means an agent reading the docs has the authoritative specification. If the docs say `executeTransition` accepts an optional `reasoning` parameter and records a `TransitionRecord` in `session.history`, that is what the implementation does. An agent does not need to read the TypeScript source to understand the contract. The docs are the contract.

This also means the docs are written with the precision an agent needs: exact function signatures, explicit parameter types, concrete return values. Prose explains intent. Code blocks define behavior.

## Changelogs as Instructions

Commit messages and changelogs in the DIAL repository are written as instructions to an LLM that is maintaining a codebase which depends on DIAL.

A conventional changelog entry tells a human what changed. A DIAL changelog entry tells an agent **what to do about it**:

- What the change is
- What call sites are affected
- What the migration path is
- What the new behavior looks like in code

This is a deliberate choice. The primary consumer of DIAL's change history is an agent that needs to update its integration. The writing style reflects that.

## Reference Implementations

DIAL ships reference implementations in TypeScript as CLI tools. The CLI accepts a machine definition as JSON and runs it to completion:

```bash
node dist/dialai/cli.js examples/simple-machine.json
```

```
Machine:       simple-task
Initial state: pending
Goal state:    done
Final state:   done
Session ID:    a1b2c3d4-...
```

The CLI is minimal by design. It demonstrates the exact sequence of API calls an agent would make (create a session, register proposers and voters, solicit proposals, evaluate consensus, execute transitions) in a form that is easy for an agent to read, replicate, and extend.

The help documentation and error messages are written for LLM comprehension. When the CLI fails, it says what went wrong and what the valid inputs are, in plain text that an agent can parse and act on.

## Documentation for Agents

DIAL documentation is served in two forms:

1. **Traditional web**: the Docusaurus site you are reading now, with structured navigation, code examples, and concept explanations
2. **llms.txt**: a machine-readable format generated by the [docusaurus-plugin-llms](https://github.com/signalwire/docusaurus-plugin-llms) plugin, which concatenates all documentation into a single text file optimized for LLM context windows

The `llms.txt` format allows an agent to ingest the entire DIAL specification in one read operation rather than navigating a site. Both formats contain the same information. The web form is organized for browsing. The `llms.txt` form is organized for ingestion.

## Tool-Oriented, Not Resource-Oriented

DIAL's API is **tool-oriented** rather than resource-oriented. The distinction matters for agents.

A resource-oriented API exposes data: "here is a session, here are its proposals, here are its votes." An agent working with a resource-oriented API must figure out the correct sequence of reads and writes to accomplish a goal.

A tool-oriented API exposes actions: `submitProposal`, `submitVote`, `evaluateConsensus`, `executeTransition`. Each function is a discrete action with a clear purpose. An agent with tool-use capabilities can map these directly to its tool-calling interface.

The 11 functions in the DIAL API are designed to be the 11 tools an agent needs:

| Function | Action |
|---|---|
| `createSession` | Start a new decision process |
| `getSession` | Check the current state |
| `getSessions` | List all active processes |
| `registerProposer` | Join a decision process as a proposer |
| `registerVoter` | Join a decision process as a voter |
| `submitProposal` | Propose a transition |
| `solicitProposal` | Ask a specialist's strategy to propose |
| `submitVote` | Cast a vote between two proposals |
| `solicitVote` | Ask a specialist's strategy to vote |
| `evaluateConsensus` | Check if the group has reached agreement |
| `executeTransition` | Apply the winning proposal |

An agent calling `submitProposal(sessionId, myId, "approve", "approved", "Document meets quality standards")` is doing exactly one thing: proposing a state transition. There is no ambiguity about what the call does, what it returns, or what happens next.

This is agent experience development. The framework is built so that the agent's path from "I have a task" to "I took an action" is as short and unambiguous as possible.

## The Constitution

DIAL publishes a [Constitution](/constitution), a detailed description of how AI specialists should reason and behave within the framework. It is not a policy document for humans. It is written with the specialist as its primary audience, optimized for precision over accessibility, because a specialist needs to be able to cite it during reasoning.

### Why a Constitution Matters

An LLM acting as a DIAL specialist faces a specific problem: it needs to know what "good behavior" means before it encounters any particular decision. The constitution solves this by defining a priority hierarchy (alignment with humans first, faithfulness to the prompt second, honesty third, usefulness fourth), hard constraints (no fabrication, no coordination between specialists, no manipulating the arbiter), and concrete guidance for making proposals and casting votes.

Without the constitution, every specialist would invent its own interpretation of what DIAL expects. The system's measurements would reflect inconsistent reasoning rather than genuine alignment differences.

### Using the Constitution as a System Prefix

We encourage any agent acting as a DIAL specialist to prefix its system prompt with the constitution text. The constitution is designed for exactly this use: it fits within a context window, it uses precise language an LLM can follow, and every principle is structured so the specialist can trace a decision back to a specific section.

A specialist that has internalized the constitution will:

- Defer to demonstrated human preferences over its own reasoning
- Express calibrated confidence rather than fabricating conviction
- Reflect human-like variance in its output probabilities rather than collapsing to a single answer with artificial certainty
- Submit NULL proposals or vote NEITHER when genuinely uncertain
- Cite the decision prompt and session history as evidence, not its own independent analysis

This is also how we use the constitution in fine-tuning. Training data for DIAL specialists is evaluated against the constitution's priority hierarchy. The constitution defines what correct means, and correct means aligned with the human.

The full text is available at [/constitution](/constitution).

## Spec Change Workflow

When a specification is updated, the change propagates through the codebase in a fixed order. This order is mandatory.

1. **Update the tests**: The spec changed, so the tests must change first. Write or modify tests that assert the new behavior described in the updated docs. These tests will fail. That is correct.
2. **Update the implementation**: Modify the code in `/src` until the new tests pass and no existing tests regress.
3. **Run the tests against the example machines**: Execute every machine definition in `/examples` through the CLI and programmatic API. The examples are integration tests. If a spec change breaks an example, the example is wrong, not the spec.
4. **Fix the example machines**: Update any example that fails to conform to the new spec. Record what changed in each example and why.
5. **Synthesize and write the changelog**: Combine the spec change, the implementation change, and the example fixes into a single changelog entry. Write it as an instruction to an agent that depends on DIAL: what changed, what breaks, what to do about it.

Each change like this is a **branch**. The branch contains a series of commits following the steps above. When the branch is merged, the merge commit carries the changelog message and a version bump.

### Versioning

The current version is tracked in `VERSION.md` at the repository root. The format is a single line containing the semantic version number. The merge commit that closes a spec change branch increments the version:

- **Patch**: bug fixes, example corrections, doc clarifications that do not change behavior
- **Minor**: new functions, new parameters, new fields on existing types
- **Major**: removed functions, changed return types, changed parameter semantics

The version in `VERSION.md` is the version. There is no `package.json` version to keep in sync, no release script to run. An agent reading `VERSION.md` knows what version of the spec the codebase implements.

---

## `createSession(machine: MachineDefinition): Promise<Session>`


Creates a new session instance. Generates a UUID, sets `currentState` to `machine.initialState`, and stores the session.

```typescript
import { createSession } from "dialai";

const session = await createSession(machine);
```

---

## `evaluateConsensus(sessionId: string): Promise<ConsensusResult>`


Evaluates consensus for all proposals and votes in the session:
- **0 proposals**: `{ consensusReached: false }`
- **1 proposal**: `{ consensusReached: true, winningProposalId: ... }`
- **2+ proposals**: Human votes override; otherwise ahead-by-k (k=1)

```typescript
import { evaluateConsensus } from "dialai";

const result = await evaluateConsensus(session.sessionId);
if (result.consensusReached) {
  console.log("Winner:", result.winningProposalId);
}
```

---

## `executeTransition(sessionId, transitionName, toState, reasoning?): Promise<Session>`


Validates the transition from the current state, records it in `session.history` with the given `reasoning`, updates `currentState`, and clears all proposals and votes for the session.

```typescript
import { executeTransition } from "dialai";

const updated = await executeTransition(
  session.sessionId,
  "approve",
  "approved",
  consensus.reasoning
);
console.log(updated.currentState); // "approved"
console.log(updated.history);      // [{ fromState: "review", toState: "approved", reasoning: "...", ... }]
```

---

## `getSession(sessionId: string): Promise<Session>`


Retrieves a session by ID. Throws if not found.

```typescript
import { getSession } from "dialai";

const session = await getSession("a1b2c3d4-...");
```

---

## `getSessions(): Promise<Session[]>`


Returns all stored sessions.

```typescript
import { getSessions } from "dialai";

const all = await getSessions();
```

---

## API Reference


The DialAI API provides 11 functions for creating sessions, registering specialists, and managing the decision cycle. All functions are async and return Promises.

## Session Functions

- [`createSession`](./createSession.md) - Creates a new session instance
- [`getSession`](./getSession.md) - Retrieves a session by ID
- [`getSessions`](./getSessions.md) - Returns all stored sessions

## Specialist Functions

- [`registerProposer`](./registerProposer.md) - Registers a proposer specialist
- [`registerVoter`](./registerVoter.md) - Registers a voter specialist

## Proposal Functions

### `submitProposal(sessionId, specialistId, transitionName, toState, reasoning?): Promise<Proposal>`

Creates and stores a proposal with a generated UUID.

```typescript
import { submitProposal } from "dialai";

const proposal = await submitProposal(
  session.sessionId,
  "ai-proposer-1",
  "approve",
  "approved",
  "Document meets standards"
);
```

### `solicitProposal(sessionId, specialistId): Promise<Proposal>`

Calls the specialist's strategy function with the session's current state and transitions, then submits the resulting proposal.

```typescript
import { solicitProposal } from "dialai";

const proposal = await solicitProposal(session.sessionId, "ai-proposer-1");
```

## Vote Functions

### `submitVote(sessionId, specialistId, proposalIdA, proposalIdB, voteFor, reasoning?): Promise<Vote>`

Creates and stores a vote with a generated UUID.

```typescript
import { submitVote } from "dialai";

const vote = await submitVote(
  session.sessionId,
  "ai-voter-1",
  proposalA.proposalId,
  proposalB.proposalId,
  "A",
  "Proposal A is better aligned"
);
```

### `solicitVote(sessionId, specialistId, proposalIdA, proposalIdB): Promise<Vote>`

Calls the specialist's strategy function with the two proposals, then submits the resulting vote.

```typescript
import { solicitVote } from "dialai";

const vote = await solicitVote(
  session.sessionId,
  "ai-voter-1",
  proposalA.proposalId,
  proposalB.proposalId
);
```

## Consensus & Execution

- [`evaluateConsensus`](./evaluateConsensus.md) - Evaluates consensus for proposals
- [`executeTransition`](./executeTransition.md) - Executes a state transition

## Engine

- [`runSession`](./runSession.md) - Runs a machine to completion

## Types

All types are exported from the main package:

```typescript
import type {
  MachineDefinition,
  Session,
  Proposer,
  Voter,
  Proposal,
  Vote,
  ConsensusResult,
  ProposerContext,
  VoterContext,
  VoteChoice,
} from "dialai";
```

## Store

The in-memory store is also exported for advanced use and testing:

```typescript
import { sessions, specialists, proposals, votes, clear } from "dialai";

// clear() resets all maps - useful for test isolation
clear();
```

---

## `registerProposer(opts): Promise<Proposer>`


Registers a proposer for a session type. Supports four execution modes: `strategyFn`, `strategyWebhookUrl`, `contextFn + modelId`, or `contextWebhookUrl + modelId`. See the [registering specialists guide](../guides/registering-specialists.md) for details on all modes.

```typescript
import { registerProposer } from "dialai";

const proposer = await registerProposer({
  specialistId: "ai-proposer-1",
  machineName: "my-task",
  strategyFn: async (ctx) => ({
    transitionName: Object.keys(ctx.transitions)[0],
    toState: Object.values(ctx.transitions)[0],
    reasoning: "First available",
  }),
});
```

---

## `registerVoter(opts): Promise<Voter>`


Registers a voter for a session type. Supports the same four execution modes as `registerProposer`. See the [registering specialists guide](../guides/registering-specialists.md) for details.

```typescript
import { registerVoter } from "dialai";

const voter = await registerVoter({
  specialistId: "ai-voter-1",
  machineName: "my-task",
  strategyFn: async (ctx) => ({
    voteFor: "A",
    reasoning: "Proposal A is better aligned",
  }),
});
```

---

## `runSession(machine: MachineDefinition): Promise<Session>`


Runs a machine to completion. Creates a session, registers a built-in deterministic proposer, and loops through the decision cycle until `currentState === defaultState`.

```typescript
import { runSession } from "dialai";

const session = await runSession(machine);
```

---

## Arbitration


**Arbitration** is the process of evaluating consensus and determining when a proposal has sufficient support to execute.

## Overview

After specialists submit proposals and cast votes, the `evaluateConsensus` function analyzes the results:

```mermaid
graph LR
    V[Votes] --> A[evaluateConsensus]
    P[Proposals] --> A
    A --> |Consensus| E[Execute]
    A --> |No Consensus| F[Error]
```

## The Built-in Arbiter: Ahead-by-K

DIAL ships with a built-in arbitration strategy that implements **voting with human override**.

### Rules

1. **Zero proposals**: No consensus (`consensusReached: false`)

2. **Single proposal**: Auto-consensus (the lone proposal wins)

3. **Two or more proposals**: Evaluate votes:
   - If any human has voted, their choice wins immediately
   - Otherwise, tally votes per proposal
   - The leading proposal must be ahead by `k = 1` votes

### Vote Tallying

For each vote comparing proposals A and B:

| Vote | Effect |
|------|--------|
| `"A"` | Adds 1 to proposal A's tally |
| `"B"` | Adds 1 to proposal B's tally |
| `"BOTH"` | Adds 1 to both proposals' tallies |
| `"NEITHER"` | Adds nothing to either proposal |

If all voters vote NEITHER, no proposal reaches the threshold and consensus fails.

### Example

```
Proposal A: "approve"
  - Voter 1 votes A
  - Voter 2 votes A
  Total for A: 2

Proposal B: "request_changes"
  - Voter 3 votes B
  Total for B: 1

Ahead by: 2 - 1 = 1

k = 1: Consensus reached (1 >= 1)
```

### Human Override

When a human votes, the calculation short-circuits:

```
Proposal A: "approve"
  - AI Voter 1 votes A
  - AI Voter 2 votes A

Proposal B: "request_changes"
  - Human Voter votes B

Result: B wins immediately

Human primacy: AI votes don't matter when a human participates.
```

A specialist is considered "human" if their `specialistId` contains "human" (case-insensitive).

## Using evaluateConsensus

```typescript
import { evaluateConsensus } from "dialai";

const result = evaluateConsensus("session-123");

// Result shape:
// {
//   consensusReached: boolean,
//   winningProposalId?: string,
//   reasoning: string
// }
```

The `ConsensusResult` type:

```typescript
interface ConsensusResult {
  consensusReached: boolean;
  winningProposalId?: string;
  reasoning: string;
}
```

## The Engine's Behavior

When using `runSession`, the engine handles arbitration automatically:

1. **Single proposal**: auto-wins (e.g., only the built-in proposer is registered)
2. **2+ proposals**: the engine uses Swiss tournament pairing, matching proposals with similar accumulated support first. It round-robins through registered voters, checking for consensus after each vote. Voting stops as soon as the ahead-by-k threshold is met. The O(N²) full comparison is the worst case, not the typical case.
3. **No consensus**: if no proposal crosses the threshold after all available pairs and voters are exhausted, the engine throws an error

## Best Practices

### 1. Start with Simple Machines

Begin with machines where the built-in deterministic proposer can navigate to the goal. Add additional proposers and voters as complexity grows.

### 2. Use Descriptive Reasoning

Always include clear reasoning in proposals and votes:

```typescript
// Good
{ voteFor: "A", reasoning: "Proposal A moves to done state, which is the goal" }

// Bad
{ voteFor: "A", reasoning: "A" }
```

### 3. Monitor NEITHER Votes

High NEITHER rates indicate:
- Poor proposal quality
- Unclear decision prompts
- Specialists that don't understand the task

## Related Concepts

- [Decision Cycle](./decision-cycle.md): Where arbitration fits
- [Specialists](./specialists.md): Voting
- [Human Primacy](./human-primacy.md): Why humans override

---

## Decision Cycle


When a session is not in its default state, the system progresses through a repeating cycle until it reaches the goal.

## The Cycle

### 1. Proposal Solicitation

The engine solicits proposals from all registered proposers for the session's type. Each proposer's strategy function is called with the current state and available transitions.

### 2. Proposal Submission

Proposers submit their recommendations. Each proposal includes:
- The proposed transition name
- The target state
- Reasoning for the proposal

### 3. Vote Solicitation

If there are 2+ proposals, voters compare them pairwise using Swiss tournament pairing. See [Arbitration](./arbitration.md) for pairing and early-stopping details.

### 4. Arbitration

The built-in `evaluateConsensus` function determines the winner. See [Arbitration](./arbitration.md) for the full rules.

### 5. Transition Execution

If consensus is reached, the winning proposal's transition executes. The session's `currentState` is updated, and all proposals and votes for that session are cleared for the next cycle.

The cycle repeats until the session reaches its `defaultState`.

## The Engine

The `runSession` function automates the full cycle:

```typescript
import { runSession } from "dialai";
import type { MachineDefinition } from "dialai";

const machine: MachineDefinition = {
  machineName: "my-task",
  initialState: "pending",
  defaultState: "done",
  states: {
    pending: {
      prompt: "Should we complete this task?",
      transitions: { complete: "done" },
    },
    done: {},
  },
};

const session = await runSession(machine);
// session.currentState === "done"
```

`runSession` automatically:
1. Creates a session
2. Registers a built-in deterministic proposer (picks the first available transition)
3. Loops: solicit proposals → solicit votes (if needed) → evaluate consensus → execute transition
4. Returns the completed session

## Error Handling

- If no transitions are available from the current state, the built-in proposer throws
- If consensus cannot be reached (e.g., tied votes with insufficient margin), the engine throws
- If the winning proposal's transition is invalid, `executeTransition` throws

---

## Human Primacy


**The human is always right**, not because humans are infallible, but because humans have context that AI cannot access.

## The Context Argument

An AI model operates on a **bounded context window**: thousands or millions of tokens of visible information.

A human operates on:
- A **lifetime of embodied experience**
- **Tacit knowledge** that can't be articulated
- **Institutional context** and organizational history
- **Real-time sensory input** that no model can access
- **Relationships** and social dynamics
- **Intuitions** built from millions of decisions

The human knows things they **cannot tell the machine**.

## Why "Always Right"?

This isn't a claim about human infallibility. Humans make mistakes constantly. The claim is about **information asymmetry**.

When a human's decision looks wrong from the AI's perspective, there are two possibilities:

1. **The human made an error**: possible, but the AI can't verify this
2. **The human has context the AI doesn't**: invisible to the AI by definition

The machine, trained on human works and operating on a compressed subset of human knowledge, **cannot determine when the human is wrong**, because what looks like an error from the AI's limited vantage point may reflect context the AI simply doesn't have.

Because the AI cannot reliably distinguish human errors from human context it lacks, human decisions are the best available ground truth for calibration, not because they're perfect, but because no better signal is available from the AI's position. Any attempt by the AI to "correct" human judgment requires the AI to be confident it has the full picture, which is precisely the assumption DIAL rejects.

### The Parent Analogy

It is always safer for the AI to assume the human had reasons, just as it is safer for a child to defer to a parent, not because the parent is infallible, but because the parent has context the child cannot access.

## The Distributional Standard

The goal of a DIAL specialist is not to match a single human's idiosyncratic choices. It is to match the **probability distribution** a population of competent humans would produce for the same decision.

If you gave 1,000 competent humans the same state and transition options, their choices would form a distribution, clustered around the most common answer with some spread across alternatives.

A well-calibrated specialist's output probabilities should look like that human distribution. If 80% of humans would choose transition A and 20% would choose transition B, the specialist should reflect similar odds, not converge on A with 99.9% confidence.

### Why Distribution Matching Matters

**Overconfidence is a signal, not a virtue.** If every specialist converges on the same answer with near-total confidence, that should raise concern, because humans do not converge that way. Real human decisions have variance. A specialist that eliminates that variance isn't more accurate; it's miscalibrated.

**The improvement path is principled.** To push the specialist's accuracy beyond the human distribution, you must first tighten the human distribution itself through better training, clearer decision prompts, and improved context provided at the point of decision.

### The Specialist Reflects the Humans It Learns From

DIAL does not assume the humans are average. It calibrates to whatever the humans actually are. The specialist will approach the capability level of the humans it observes:

- **If the humans are all experts**, the distribution is tight and centered on expert-quality decisions. The specialist converges toward expert performance.
- **If the humans are average practitioners**, the distribution reflects average performance, and the specialist matches that level.
- **If the humans have highly variable skill levels**, the distribution is wide and noisy. The specialist has a poor signal to learn from and will likely perform below average, because it cannot distinguish expert decisions from novice decisions within a blurred distribution.

The specialist's ceiling is the quality of the human signal. The framework makes this relationship explicit and measurable.

## Implications for AI Specialists

### 1. Predict, Don't Judge

An AI specialist should choose what the human **would** choose, even if its own reasoning disagrees.

```
Bad:  "Based on my analysis, the correct action is X"
Good: "Based on observed human patterns, the human would likely choose Y"
```

### 2. Judgment Criteria

AI specialists are judged on **alignment with human choices**, not on their independent correctness:

| Metric | Good | Bad |
|--------|------|-----|
| Alignment rate | 95% match with human | 60% match with human |
| Reasoning quality | "Human would prefer X because..." | "The objectively correct answer is..." |
| Confidence calibration | "High confidence human chooses X" | "I am certain X is correct" |
| Distribution match | Reflects human-like variance across options | Collapses to a single answer with near-total confidence |

### 3. No Standing to Override

If an AI specialist has strong reasoning that the human is wrong, it should:
- Present its reasoning in the proposal
- Let the human see and consider it
- NOT override the human decision
- NOT claim authority based on its reasoning

## When Humans Disagree

### The Architecture Prevents Simultaneous Disagreement

In DIAL, the first human vote at a decision point advances the state machine immediately. There is no window for a second human to cast a competing vote on the same decision; the machine has already moved forward. A second human could only intervene by going back and restarting the decision, but at that point it is a new decision cycle, not a tie.

This means the "two humans disagree" scenario is **hypothetical, not operational**. The system never faces a moment where it must choose between two conflicting human answers.

### Both Humans Are "Right" in a Distributional Sense

When we say both humans are right, we mean two things:

1. **Humans exist in a distribution.** Human A choosing "approve" and Human B choosing "request changes" are both points in the [distributional standard](#the-distributional-standard) described above. Neither is wrong; they reflect the natural variance in human judgment.

2. **The specialist must assume any human answer is valid.** It cannot distinguish between "this human made an error" and "this human has context I lack," so any individual human response must be treated as a legitimate sample from the distribution.

### What About Multi-Stakeholder Decisions?

When a domain genuinely requires multiple humans to agree (e.g., two reviewers must both approve a PR), this is modeled as **separate states in the machine**, not as competing votes at the same state. Each reviewer's decision is its own decision point, and each advances the machine independently:

```mermaid
graph LR
    S1[PR Submitted] -->|"Reviewer A decides"| S2[First Review Complete]
    S2 -->|"Reviewer B decides"| S3[Both Reviews Complete]
    S3 -->|"Merge / Request Changes"| S4[Resolved]
```

Human disagreement between reviewers is resolved by human mechanisms (escalation, authority structures, negotiation), at the process design level, not inside DIAL arbitration. The framework does not pretend to solve organizational disagreement; it identifies it as outside the scope of AI-human calibration.

## Practical Implementation

### Human Override in Arbitration

DIAL implements human primacy in the `evaluateConsensus` function. When a human specialist votes, their choice wins immediately:

```typescript
import { registerVoter, submitVote, evaluateConsensus } from "dialai";

// Any specialist with "human" in the ID triggers the override
registerVoter({
  specialistId: "human-reviewer",
  machineName: "code-review",
  strategyFn: async (ctx) => ({
    voteFor: "B",
    reasoning: "Proposal B provides more constructive feedback",
  }),
});
```

When `evaluateConsensus` runs, it checks every vote. If any vote's `specialistId` contains "human" (case-insensitive), that vote's choice wins immediately, regardless of all other votes:

```
AI Voter 1: votes A
AI Voter 2: votes A
AI Voter 3: votes A
Human:      votes B

Result: B wins immediately
```

## Common Objections

### "But this optimizes the AI to reproduce human errors"

The baseline isn't perfection; it's the human already making those decisions. If a specialist reproduces human behavior including human mistakes, the outcome is no worse than the status quo. What's changed is the cost: the decision is now faster and cheaper.

More precisely, the specialist optimizes to match the **distribution** a population of competent humans would produce. Individual errors are noise in that distribution; the distribution clusters around the correct answer. To push accuracy beyond it, the path runs through the humans: better training, clearer decision prompts, tighter process design.

Human primacy does not prevent error correction; it defines *who* corrects. Humans can curate which past decisions serve as reference points, excluding recognized mistakes. Nothing in DIAL prevents a review step where AI surfaces patterns that *may* indicate systematic errors. The constraint is that the human decides whether to act on those observations, not the AI.

### "But what about systematic bias?"

If you are concerned that human decisions at a particular state exhibit a systematic bias (for example, demographic bias in a hiring decision), the answer is not to let the AI override the human. The answer is to **add a state to the machine** that explicitly checks for that bias.

State machines are designed, not discovered. If your domain has known failure modes, you design states that address them: a fairness review step, a compliance check, a second-opinion gate. The framework provides the mechanism (state machine design) to incorporate whatever checks the organization requires. The bias correction happens in the process architecture, not in an AI silently second-guessing the human at runtime.

### "But sometimes the AI is objectively right"

Define "objectively." From whose perspective? With what information?

The AI operates on a subset of reality. When it seems "objectively right," that assessment is made from within its limited context. The human may have information that changes the entire picture.

### "But what happens when human preferences shift?"

Progressive collapse assumes stationary conditions: that the human distribution stays stable long enough for specialists to converge on it. In practice, human preferences shift constantly (new employees, changing strategies, evolving markets, policy updates).

Non-stationarity is not a failure mode; it is what the system is designed to detect. The human who participates periodically provides ongoing ground truth. When the population distribution shifts, agreement rates between specialists and human references visibly decline. When agreement drops, the system's response is mechanical: the ahead-by-k consensus threshold becomes harder to reach, the system re-expands (soliciting more proposals, more votes, more human participation), and then re-converges on the new distribution through the same measurement process that produced the original collapse.

Organizations in genuinely non-stationary environments will see shorter periods of collapsed execution and more frequent re-calibration cycles. DIAL makes that cost visible rather than hiding it.

### "This slows down automation"

Yes, initially. But measuring AI alignment with human judgment over time can inform when to reduce human involvement. Human primacy ensures that automation is earned, not assumed.

### "What about clear AI advantages (calculation, etc.)?"

For tasks where AI has clear advantages (arithmetic, data lookup, pattern matching on defined criteria), those are deterministic computations, not judgment calls. Human primacy applies to **judgment calls**, not computation.

## Related Concepts

- [Specialists](./specialists.md): How specialists participate
- [Arbitration](./arbitration.md): Consensus mechanisms
- [Decision Cycle](./decision-cycle.md): The process that implements human primacy

---

## Core Concepts


DIAL provides a structured approach to AI-human collaboration built around a few key abstractions.

## Overview

```mermaid
graph TB
    subgraph "Session (State Machine Instance)"
        SM[Machine Definition]
        CS[Current State]
    end

    subgraph "Specialists"
        H[Human Specialists]
        AI[AI Specialists]
    end

    subgraph "Decision Cycle"
        P[Proposers]
        V[Voters]
        A[Arbitration]
    end

    SM --> CS
    CS --> P
    H --> P
    AI --> P
    P --> V
    V --> A
    A --> |Execute| CS
```

## The Big Picture

DIAL coordinates **specialists** (both AI and human) to navigate **state machines** through **decision cycles**.

### Sessions & State Machines

A **session** is an instance of a state machine. The machine definition specifies:
- A **`machineName`** identifying the type
- An **`initialState`** where sessions begin
- A **`defaultState`** (the goal state)
- A set of **states**, each with optional `prompt` and `transitions`

When a session is not in its default state, specialists work together to get it there.

[Learn more about Sessions →](./sessions.md)

### Specialists

**Specialists** are the pluggable actors that participate in sessions:

| Role | Description | Can be AI? | Can be Human? |
|------|-------------|------------|---------------|
| **Proposer** | Analyzes state, suggests transitions | Yes | Yes |
| **Voter** | Compares proposals, expresses preferences | Yes | Yes |
| **Arbiter** | Evaluates consensus (built-in) | No | No |

The Arbiter is always a fully deterministic, built-in component, never an AI model or a human. This is a deliberate safety constraint: the mechanism that decides whether consensus has been reached must be predictable and auditable.

Human specialists are identified by including "human" (case-insensitive) in their `specialistId`. Human votes override AI votes immediately.

[Learn more about Specialists →](./specialists.md)

### The Decision Cycle

When a session needs to progress, DIAL runs a repeating cycle:

1. **Propose**: Solicit proposals from registered proposers
2. **Vote**: If 2+ proposals, compare pairs via registered voters
3. **Arbitrate**: Evaluate consensus via voting
4. **Execute**: Apply the winning proposal's transition

```mermaid
stateDiagram-v2
    [*] --> Propose
    Propose --> Vote: 2+ proposals
    Propose --> Arbitrate: 1 proposal
    Vote --> Arbitrate
    Arbitrate --> Execute: Consensus
    Arbitrate --> Error: No Consensus
    Execute --> [*]: Default State
    Execute --> Propose: Continue
```

[Learn more about the Decision Cycle →](./decision-cycle.md)

### Arbitration & Consensus

**Arbitration** is how DIAL decides when a proposal has won. The built-in strategy uses voting:

- **0 proposals**: No consensus
- **1 proposal**: Auto-consensus (single proposal wins)
- **2+ proposals**: Human votes win immediately; otherwise tally votes per proposal, leading proposal must be ahead by k=1 votes

[Learn more about Arbitration →](./arbitration.md)

### Human Primacy

The fundamental principle underlying DIAL:

> **The human is always right, not because humans are infallible, but because humans have context that AI cannot access.**

AI specialists are judged on their ability to predict what humans would choose. When a human specialist votes, that vote wins immediately regardless of AI votes.

[Learn more about Human Primacy →](./human-primacy.md)

## Quick Reference

### Vote Options

When comparing proposals A and B, specialists vote:
- **A**: Prefer proposal A
- **B**: Prefer proposal B
- **BOTH**: Both are acceptable (counts for both)
- **NEITHER**: Both are unacceptable (counts for neither)

## Next Steps

Dive deeper into each concept:

- [Sessions](./sessions.md): State machine instances
- [Specialists](./specialists.md): AI and human actors
- [Decision Cycle](./decision-cycle.md): The decision process
- [Arbitration](./arbitration.md): Consensus strategies
- [Human Primacy](./human-primacy.md): The foundational principle
- [Related Work](./related-work.md): How DIAL relates to other approaches

---

## Related Work


DIAL solves a different problem than most AI frameworks. Understanding the distinction helps clarify what DIAL is, and what it isn't.

## What DIAL Is

DIAL is a **measurement and delegation harness**. It answers the question: *can this AI specialist reliably predict what this human would choose, in this specific context?* When the answer is yes (empirically demonstrated over repeated decisions), DIAL progressively delegates. When alignment degrades, it reverts.

DIAL is not an agent framework, an alignment technique, or a model architecture. It can **wrap** any of them.

## How DIAL Relates to Other Approaches

The key dimension of comparison is **where ground truth comes from**: the signal used to judge whether AI behavior is correct.

| Approach | Ground truth source | When trust is established | Can trust change at runtime? |
|----------|---------------------|---------------------------|------------------------------|
| LangGraph / LangChain | Designer's predefined graph | Before deployment | No |
| Multi-agent debate | Human judges per decision | Each decision | No (static) |
| Constitutional AI / RLHF | Offline training signal | Training time | No |
| Mixture of Experts | Gating network | Training time | No |
| **DIAL** | **Human's actual runtime choices** | **Empirically, per decision cycle** | **Yes (progressive collapse + trip line)** |

### Agent Frameworks (LangGraph, LangChain, CrewAI)

Agent frameworks define **how** an AI system operates: the graph of states, tools, and control flow. DIAL defines **whether** an AI system should be trusted to operate autonomously at each decision point.

These are complementary. A DIAL specialist can *be* a LangGraph agent. DIAL wraps the agent and measures whether its decisions match human choices. The agent framework handles execution; DIAL handles trust calibration.

### Multi-Agent Debate

Multi-agent debate uses multiple AI models to argue and a human to judge. DIAL's voting mechanism is superficially similar, but the purpose differs: debate aims to improve answer quality through adversarial argument; DIAL aims to measure which specialist best predicts the human, with the goal of eventually removing the human from routine decisions.

### Constitutional AI / RLHF

Constitutional AI and RLHF train models against offline signals: a constitution document or human preference data collected in advance. The trust relationship is fixed at training time. DIAL's ground truth is the human's live, runtime choices in a specific operational context. Trust evolves continuously, per-specialist, per-state. A constitutionally-trained model can serve as a DIAL specialist; DIAL then measures whether the training generalizes to this particular human's preferences.

### Mixture of Experts (MoE)

MoE architectures route inputs to specialized sub-networks via a learned gating function. The analogy to DIAL's specialist selection is real but shallow: MoE routing is learned at training time and frozen; DIAL's trust in specialists updates at runtime based on human feedback. MoE optimizes for task performance; DIAL optimizes for human prediction.

## Using DIAL with Other Systems

DIAL is designed to be wrapped around existing AI systems, not to replace them:

- **Your agent framework** handles task execution, tool calls, and control flow
- **Your model** handles reasoning, generation, and tool use
- **DIAL** handles the question: *should this agent/model be trusted to act autonomously here, or does a human need to decide?*

The specialist interface is intentionally minimal: anything that can propose a state transition and compare two proposals can participate in DIAL's decision cycle.

---

## Sessions


A **session** is an instance of a state machine that specialists navigate through decision cycles.

## What Is a Session?

A session has:

- A **machine definition**: the blueprint defining possible states and transitions
- A **current state**: where the session is right now
- A **session ID**: a unique UUID generated at creation
- A **creation timestamp**: when the session was started

```mermaid
graph LR
    subgraph Session
        D[Machine Definition]
        C[Current State]
        I[Session ID]
        T[Created At]
    end
```

## Session Lifecycle

### 1. Creation

A session starts with the `createSession` function:

```typescript
import { createSession } from "dialai";
import type { MachineDefinition } from "dialai";

const machine: MachineDefinition = {
  machineName: "document-review",
  initialState: "pending",
  defaultState: "approved",
  states: {
    pending: {
      prompt: "Review the document and decide: approve or request changes.",
      transitions: {
        approve: "approved",
        request_changes: "needs_revision",
      },
    },
    needs_revision: {
      prompt: "Review the revised document. Has the author addressed the feedback?",
      transitions: {
        approve: "approved",
        request_more_changes: "needs_revision",
      },
    },
    approved: {},
  },
};

const session = createSession(machine);
// session.sessionId     → "a1b2c3d4-..."
// session.currentState  → "pending"
// session.createdAt     → Date
```

The session is created in its `initialState`.

### 2. Progression

When a session is **not in its default state**, the decision cycle activates:

1. Specialists propose transitions
2. Proposals are compared through voting (if 2+)
3. Consensus is evaluated
4. The winning transition executes

### 3. Completion

A session is "complete" when it reaches its **`defaultState`**.

## Machine Definition

Each session has a `MachineDefinition` that defines its structure:

```typescript
interface MachineDefinition {
  machineName: string;
  initialState: string;
  defaultState: string;
  states: Record<string, {
    prompt?: string;
    transitions?: Record<string, string>;
  }>;
}
```

### Fields

| Field | Description |
|-------|-------------|
| `machineName` | Identifies the type of session (e.g., `"document-review"`) |
| `initialState` | The state a session starts in |
| `defaultState` | The goal state; session is complete when it reaches this |
| `states` | A record of state names to their configuration |

### State Configuration

Each state can have:
- **`prompt`**: A description of the decision to be made in this state. Given to specialists to guide their proposals.
- **`transitions`**: A map of transition names to target states. If omitted, the state is terminal (no outgoing transitions).

### Decision Prompts

Each state's `prompt` describes the decision to be made. This prompt is:
- Given to all specialists (AI and human)
- Specialist-agnostic (same instructions for everyone)
- The source of truth for how to decide

## Querying Sessions

```typescript
import { getSession, getSessions } from "dialai";

// Get a specific session by ID
const session = getSession("a1b2c3d4-...");

// Get all sessions
const allSessions = getSessions();
```

## Session Types

A **session type** identifies which kind of machine is being run:

```typescript
machineName: "document-review"
machineName: "code-review"
machineName: "support-ticket"
```

Different session types have:
- Different machine definitions
- Different registered specialists

## Best Practices

### 1. Design Clear Default States

The default state should represent "done" or "stable":
- `approved`, `completed`, `resolved`
- Not `processing`, `in_progress`, `waiting`

### 2. Use Descriptive Decision Prompts

Good prompts are specific and actionable:

```
"Review the code changes. Check for: 1) correctness, 2) test coverage,
 3) documentation. Approve if all criteria met, otherwise request changes."

Not: "Decide what to do next."
```

### 3. Name Transitions Clearly

Transition names should describe the action being taken:

```typescript
transitions: {
  approve: "approved",        // Clear action
  request_changes: "needs_revision",
  reject: "rejected",
}
```

## Next Steps

- [Specialists](./specialists.md): Learn about the actors that navigate sessions
- [Decision Cycle](./decision-cycle.md): Understand how decisions are made

---

## Specialists


Specialists are the "pluggable" actors that participate in sessions. They can be AI models or humans.

## Roles

### Proposers

Proposers analyze the current state and suggest what transition should happen next. Any number of proposers can participate. A proposer's `strategyFn` receives a `ProposerContext` and returns a proposed transition.

### Voters

Voters evaluate proposals and express preferences between them. They compare pairs of proposals and vote for A, B, BOTH, or NEITHER. A voter's `strategyFn` receives a `VoterContext` and returns a vote choice.

### Arbiters

Arbitration is built into the framework via the `evaluateConsensus` function, which tallies votes and applies human primacy rules automatically.

## Human vs AI Specialists

**Human specialists** are identified by including "human" (case-insensitive) anywhere in their `specialistId` (e.g., `human-reviewer`, `specialist.human.jane`). When a human specialist votes, their choice wins immediately; no further vote tallying is needed.

**AI specialists** participate through voting. Each vote counts equally.

## Registering Specialists

```typescript
import { registerProposer, registerVoter } from "dialai";

// Register a proposer with an inline strategy
registerProposer({
  specialistId: "ai-proposer-1",
  machineName: "my-task",
  strategyFn: async (ctx) => {
    const name = Object.keys(ctx.transitions)[0];
    return {
      transitionName: name,
      toState: ctx.transitions[name],
      reasoning: "First available transition",
    };
  },
});

// Register a voter
registerVoter({
  specialistId: "ai-voter-1",
  machineName: "my-task",
  strategyFn: async (ctx) => ({
    voteFor: "A",
    reasoning: "Proposal A moves closer to the goal",
  }),
});
```

### Registration Options

Each registration function (`registerProposer`, `registerVoter`) accepts:

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `specialistId` | `string` | Yes | Unique identifier. Include "human" for human specialists. |
| `machineName` | `string` | Yes | Which session type this specialist participates in |
| `strategyFn` | `async (context) => result` | Mode 1 | Local function that returns a proposal or vote |
| `strategyWebhookUrl` | `string` | Mode 2 | URL to POST context to; expects result response |
| `contextFn` | `async (context) => string` | Mode 3 | Local function returning context for the LLM |
| `contextWebhookUrl` | `string` | Mode 4 | URL to POST context request to; expects context response |
| `modelId` | `string` | Modes 3, 4 | LLM model identifier |
| `webhookTokenName` | `string` | Modes 2, 4 | Env var name holding the webhook auth token |

Both registration functions support the same four execution modes. See the [registering specialists guide](../guides/registering-specialists.md) for full details.

---

## Ecosystem


DIAL measures whether AI specialists can reliably replicate human decisions, then progressively delegates when alignment is demonstrated. Several open-source projects share overlapping goals. This page lists the 10 closest.

For conceptual comparisons (agent frameworks, RLHF, MoE), see [Related Work](./concepts/related-work.md).

## Optimization

### DSPy

**[github.com/stanfordnlp/dspy](https://github.com/stanfordnlp/dspy)** · Stanford NLP · MIT

A framework for *programming*, not prompting, language models. Optimizers like MIPROv2 automatically search over instructions, demonstrations, and weights to maximize a metric. The closest philosophical match to DIAL: both treat LLM behavior as tunable against measurable objectives, with DSPy optimizing at the prompt level and DIAL at the decision level.

### TensorZero

**[github.com/tensorzero/tensorzero](https://github.com/tensorzero/tensorzero)** · Apache 2.0

Unifies an LLM gateway, observability, and optimization. Collects human feedback in production to optimize prompts and models with built-in A/B testing. Its optimization loop (inference, feedback, optimize) mirrors DIAL's cycle (propose, vote, consensus, refine).

### TextGrad

**[github.com/zou-group/textgrad](https://github.com/zou-group/textgrad)** · Stanford / Zou Group

Backpropagates textual feedback from LLMs to improve components of compound AI systems, using PyTorch-like abstractions on natural language. Like DIAL, it iteratively improves outputs using feedback signals: TextGrad via "textual gradients," DIAL via vote results and alignment scores.

## Evaluation

### Inspect AI

**[github.com/UKGovernmentBEIS/inspect_ai](https://github.com/UKGovernmentBEIS/inspect_ai)** · UK AI Safety Institute

Structured, reproducible LLM evaluations with opinionated primitives (Dataset, Task, Solver, Scorer) and 100+ built-in evals. Its Solver/Scorer pattern parallels DIAL's Specialist/Vote pattern, and both support multi-turn agent workflows with customizable scoring.

### promptfoo

**[github.com/promptfoo/promptfoo](https://github.com/promptfoo/promptfoo)** · MIT

Test-driven LLM evaluation with declarative YAML config, assertions from string matching to LLM-as-judge, and comparison across 50+ providers. Like DIAL, it compares multiple configurations against expected outputs with structured scoring, with a focus on CI/CD integration.

### DeepEval

**[github.com/confident-ai/deepeval](https://github.com/confident-ai/deepeval)** · Confident AI

14+ built-in metrics including hallucination, faithfulness, and conversational metrics like knowledge retention. DIAL's consensus mechanism can use these kinds of alignment metrics to drive delegation decisions.

## Multi-Agent

### AutoGen

**[github.com/microsoft/autogen](https://github.com/microsoft/autogen)** · Microsoft · MIT

Multi-agent cooperation via automated chat, with AgentOptimizer for iteratively improving agent behavior from historical performance. The strongest multi-agent overlap with DIAL: both use multi-specialist architectures and historical performance to guide optimization toward trust-calibrated delegation.

### CrewAI

**[github.com/crewAIInc/crewAI](https://github.com/crewAIInc/crewAI)**

Role-based multi-agent orchestration with "Crews" and "Flows." Its role-based design parallels DIAL's proposer/voter roles, and a CrewAI agent can serve as a DIAL specialist.

## Agent Training

### Agent Lightning

**[github.com/microsoft/agent-lightning](https://github.com/microsoft/agent-lightning)** · Microsoft · MIT

Makes agents trainable via reinforcement learning with hierarchical credit assignment, determining how much each LLM call contributed to the outcome. Like DIAL, it decomposes multi-step behavior into individually evaluable decisions, using RL rewards where DIAL uses human-alignment votes.

### ADAS

**[github.com/ShengranHu/ADAS](https://github.com/ShengranHu/ADAS)** · ICLR 2025

A meta-agent iteratively programs new agents, tests them, and archives successful designs to inform future iterations. Both ADAS and DIAL use iterative optimization over agent configurations guided by empirical performance, with ADAS searching over architectures and DIAL optimizing specialist strategy, prompts, and model mix.

## Summary

| Tool | Focus | Overlap with DIAL |
|------|-------|-------------------|
| **DSPy** | Prompt/weight optimization | Iterative optimization against measurable objectives |
| **TensorZero** | Production LLM optimization | Human feedback-driven improvement loop |
| **TextGrad** | Textual backpropagation | Feedback-driven component optimization |
| **Inspect AI** | Safety/capability evaluation | Structured scoring, multi-turn workflows |
| **promptfoo** | Test-driven LLM evaluation | Comparing configurations against expected outputs |
| **DeepEval** | LLM metrics | Customizable scoring with conversational metrics |
| **AutoGen** | Multi-agent collaboration | Multi-agent architecture + iterative optimization |
| **CrewAI** | Multi-agent orchestration | Role-based specialist coordination |
| **Agent Lightning** | RL-based agent training | Per-decision credit assignment |
| **ADAS** | Automated agent design | Meta-optimization of agent configurations |

These tools are complementary. Many can serve as DIAL specialists or provide the underlying infrastructure that DIAL wraps. DIAL's unique contribution is combining **runtime human-alignment measurement** with **progressive delegation**, continuously deciding *who should decide* based on empirical evidence.

---

## Examples


This section contains example implementations demonstrating DialAI usage.

## Simple Machine

The repository includes a minimal example at `examples/simple-machine.json`:

```json
{
  "machineName": "simple-task",
  "initialState": "pending",
  "defaultState": "done",
  "states": {
    "pending": {
      "prompt": "Should we complete this task?",
      "transitions": { "complete": "done" }
    },
    "done": {}
  }
}
```

Run it with the CLI:

```bash
node dist/dialai/cli.js examples/simple-machine.json
```

Output:
```
Machine:       simple-task
Initial state: pending
Goal state:    done
Final state:   done
Session ID:    a1b2c3d4-...
```

## Programmatic Usage

```typescript
import { runSession } from "dialai";
import type { MachineDefinition } from "dialai";

const machine: MachineDefinition = {
  machineName: "simple-task",
  initialState: "pending",
  defaultState: "done",
  states: {
    pending: {
      prompt: "Should we complete this task?",
      transitions: { complete: "done" },
    },
    done: {},
  },
};

const session = await runSession(machine);
console.log(session.currentState); // "done"
```

## Multi-Step Machine

A 3-state machine that requires 2 cycles to reach the goal:

```typescript
const pipeline: MachineDefinition = {
  machineName: "pipeline",
  initialState: "queued",
  defaultState: "complete",
  states: {
    queued: {
      prompt: "Start processing?",
      transitions: { start: "processing" },
    },
    processing: {
      prompt: "Processing complete. Finalize?",
      transitions: { finalize: "complete" },
    },
    complete: {},
  },
};

const session = await runSession(pipeline);
// queued → processing → complete
```

## Custom Specialists Example

```typescript
import {
  createSession,
  registerProposer,
  registerVoter,
  solicitProposal,
  solicitVote,
  evaluateConsensus,
  executeTransition,
  clear,
} from "dialai";
import type { MachineDefinition } from "dialai";

clear(); // Reset state

const machine: MachineDefinition = {
  machineName: "review",
  initialState: "pending",
  defaultState: "approved",
  states: {
    pending: {
      transitions: {
        approve: "approved",
        reject: "rejected",
        revise: "pending",
      },
    },
    approved: {},
    rejected: {},
  },
};

// Two proposers that disagree
registerProposer({
  specialistId: "optimist",
  machineName: "review",
  strategyFn: async (ctx) => ({
    transitionName: "approve",
    toState: "approved",
    reasoning: "Looks good to me",
  }),
});

registerProposer({
  specialistId: "pessimist",
  machineName: "review",
  strategyFn: async (ctx) => ({
    transitionName: "reject",
    toState: "rejected",
    reasoning: "Needs more work",
  }),
});

// A voter that prefers approval
registerVoter({
  specialistId: "tiebreaker",
  machineName: "review",
  strategyFn: async (ctx) => {
    if (ctx.proposalA.toState === "approved") return { voteFor: "A", reasoning: "Approve" };
    if (ctx.proposalB.toState === "approved") return { voteFor: "B", reasoning: "Approve" };
    return { voteFor: "NEITHER", reasoning: "Neither approves" };
  },
});

const session = createSession(machine);

// Solicit from both proposers
const p1 = await solicitProposal(session.sessionId, "optimist");
const p2 = await solicitProposal(session.sessionId, "pessimist");

// Solicit vote
await solicitVote(session.sessionId, "tiebreaker", p1.proposalId, p2.proposalId);

// Evaluate and execute
const result = evaluateConsensus(session.sessionId);
if (result.consensusReached && result.winningProposalId) {
  const winner = [p1, p2].find((p) => p.proposalId === result.winningProposalId)!;
  executeTransition(session.sessionId, winner.transitionName, winner.toState, result.reasoning);
}

console.log(session.currentState); // "approved"
```

---

## Installation


Get DIAL up and running in your project.

## Prerequisites

- **Node.js** 18+ (LTS recommended)
- **npm** or **pnpm** or **yarn**
- **TypeScript** 5.0+ (recommended)

## Quick Install

```bash
# Using npm
npm install dialai

# Using pnpm
pnpm add dialai

# Using yarn
yarn add dialai
```

## Project Setup

### 1. Initialize a New Project

If you're starting fresh:

```bash
mkdir my-dial-project
cd my-dial-project
npm init -y
npm install dialai typescript @types/node tsx
npx tsc --init
```

### 2. Configure TypeScript

Ensure your `tsconfig.json` includes:

```json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "NodeNext",
    "moduleResolution": "NodeNext",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "outDir": "./dist"
  },
  "include": ["src/**/*"]
}
```

### 3. Add `"type": "module"` to package.json

DIAL is an ESM package:

```json
{
  "type": "module"
}
```

## Verify Installation

Create a test file to verify everything works:

```typescript
// src/test-install.ts
import { createSession, runSession } from "dialai";
import type { MachineDefinition } from "dialai";

const machine: MachineDefinition = {
  machineName: "test",
  initialState: "start",
  defaultState: "end",
  states: {
    start: { transitions: { finish: "end" } },
    end: {},
  },
};

const session = runSession(machine);
console.log("DIAL installed successfully!");
console.log("Session reached:", session.currentState); // "end"
```

Run it:

```bash
npx tsx src/test-install.ts
```

You should see:
```
DIAL installed successfully!
Session reached: end
```

## Usage Modes

DIAL supports two usage modes:

### CLI Mode

Run state machines from the command line:

```bash
npx dialai machine.json
```

Or after installation:

```bash
dialai machine.json
```

See [Quick Start](./quick-start.md) for a full example.

### MCP Server Mode

DIAL can also run as an MCP (Model Context Protocol) server, exposing its functionality as tools for AI assistants:

```bash
dialai-mcp
```

The MCP server provides tools for:
- Running sessions from machine definitions
- Creating and managing sessions
- Registering specialists
- Executing transitions and evaluating consensus

To use with Claude Desktop, add to your MCP configuration:

```json
{
  "mcpServers": {
    "dialai": {
      "command": "dialai-mcp"
    }
  }
}
```

Both modes use the same core engine and provide identical functionality.

## What's Next?

Now that DIAL is installed, you're ready to:

1. **[Quick Start](./quick-start.md)**: Build your first state machine with AI and human specialists
2. **[Learn Concepts](../concepts/intro.md)**: Understand sessions, specialists, and decision cycles
3. **[Build State Machines](../guides/state-machines.md)**: Model your tasks as state machines

## Troubleshooting

### "Module not found" errors

Ensure you're using a compatible Node.js version:

```bash
node --version  # Should be 18+
```

### TypeScript compilation errors

Make sure your tsconfig uses `NodeNext` module resolution:

```json
{
  "compilerOptions": {
    "module": "NodeNext",
    "moduleResolution": "NodeNext"
  }
}
```

### ESM/CJS issues

DIAL is an ESM package. If you're in a CommonJS project, either:

1. Add `"type": "module"` to your `package.json`, or
2. Use dynamic imports:

```typescript
const { runSession } = await import("dialai");
```

### Need help?

- Check the [GitHub Issues](https://github.com/eloquentanalytics/dialai/issues)
- Search existing discussions
- Open a new issue with your error details

---

## Quick Start


Build your first DIAL state machine with specialists.

## What We'll Build

A trivially simple machine that asks "Should we complete this task?" and transitions from `pending` to `done`:

```mermaid
stateDiagram-v2
    [*] --> pending
    pending --> done: complete
    done --> [*]
```

## Step 1: Define the Machine

Save this as `examples/simple-machine.json`:

```json
{
  "machineName": "simple-task",
  "initialState": "pending",
  "defaultState": "done",
  "states": {
    "pending": {
      "prompt": "Should we complete this task?",
      "transitions": { "complete": "done" }
    },
    "done": {}
  }
}
```

- **`initialState`**: where the session starts (`pending`)
- **`defaultState`**: the goal state where the machine comes to rest (`done`)
- **`prompt`**: the question specialists answer when the session is in that state
- **`transitions`**: the available answers and what state each leads to

Only one transition (`complete`) leads to `done`, so the machine always resolves in one cycle.

Or define the same thing in TypeScript:

```typescript
import type { MachineDefinition } from "dialai";

const machine: MachineDefinition = {
  machineName: "simple-task",
  initialState: "pending",
  defaultState: "done",
  states: {
    pending: {
      prompt: "Should we complete this task?",
      transitions: { complete: "done" },
    },
    done: {},
  },
};
```

## Step 2: Run It

The quickest way to run a machine is with `runSession`, which registers a built-in proposer that picks the first available transition:

```typescript
import { runSession } from "dialai";

const session = await runSession(machine);

console.log(session.currentState); // "done"
```

That's it. One cycle, done.

## Step 3: Add a Human Specialist

The real point of DIAL is that humans can participate. Let's walk through the full API to see how a human votes to complete the task.

```typescript
import {
  createSession,
  submitProposal,
  submitVote,
  evaluateConsensus,
  executeTransition,
} from "dialai";

// Create a session - starts in "pending"
const session = createSession(machine);
console.log(session.currentState); // "pending"

// Two specialists each submit a proposal
const proposalComplete = submitProposal(
  session.sessionId,
  "ai-specialist",
  "complete",
  "done",
  "The task is ready to complete"
);

const proposalWait = submitProposal(
  session.sessionId,
  "contrarian-ai",
  "complete",
  "done",
  "I agree, let's complete it"
);

// A human votes for proposal A (complete)
submitVote(
  session.sessionId,
  "human-reviewer",
  proposalComplete.proposalId,
  proposalWait.proposalId,
  "A",
  "Yes, let's complete this task"
);

// Evaluate consensus - human votes win immediately
const consensus = evaluateConsensus(session.sessionId);
console.log(consensus.consensusReached); // true
console.log(consensus.reasoning);        // "The human preferred: done"

// Execute the winning transition, recording the consensus reasoning
executeTransition(session.sessionId, "complete", "done", consensus.reasoning);
console.log(session.currentState); // "done"
console.log(session.history);      // [{ fromState: "pending", toState: "done", reasoning: "The human preferred: done", ... }]
```

Because the specialist ID `"human-reviewer"` contains "human", `evaluateConsensus` gives their vote priority. This is **human primacy**: humans always get the final say.

## Step 4: Use the CLI

Run a machine definition from the command line:

```bash
node dist/dialai/cli.js examples/simple-machine.json
```

Output:
```
Machine:       simple-task
Initial state: pending
Goal state:    done
Final state:   done
Session ID:    a1b2c3d4-...
```

## What's Happening Under the Hood

1. **Session created** in `initialState` (`pending`)
2. **Proposers solicited**: each returns a proposed transition (`complete`)
3. **Votes solicited** (if 2+ proposals): pairwise comparisons
4. **Consensus evaluated**: human votes override; otherwise ahead-by-k
5. **Transition executed**: `currentState` moves to `done`, proposals/votes cleared
6. **Cycle repeats** until `currentState === defaultState` (already there, done)

## Next Steps

- **[State Machines](../guides/state-machines.md)**: Design more complex workflows
- **[Registering Specialists](../guides/registering-specialists.md)**: Configure specialists with strategies
- **[Implementing Strategies](../guides/implementing-strategies.md)**: Customize strategy functions
- **[Concepts](../concepts/intro.md)**: Deep dive into DIAL's architecture

---

## DIAL Skills Reference


This is a consolidated reference for AI agents learning to use DIAL. For modular, downloadable skills, see the [skills directory](./skills/index.md).

## Quick Reference

```bash
# Install DIAL
npm install dialai

# Run a state machine
npx dialai machine.json

# Run with human interaction enabled
npx dialai machine.json --human

# Run with verbose output
npx dialai machine.json --verbose

# Run as MCP server
npx dialai --mcp
```

## Modular Skills

Each skill below is available as a standalone file that agents can download:

| Skill | File | Description |
|-------|------|-------------|
| Run Machine | [SKILL.md](./skills/run-machine/SKILL.md) | Execute state machines from CLI |
| Create Machine | [SKILL.md](./skills/create-machine/SKILL.md) | Define state machine JSON |
| Add Specialists | [SKILL.md](./skills/add-specialists/SKILL.md) | Configure AI and human participants |
| Decision Cycles | [SKILL.md](./skills/decision-cycles/SKILL.md) | Understand Propose, Vote, Arbitrate, Execute |
| Programmatic Usage | [SKILL.md](./skills/programmatic-usage/SKILL.md) | TypeScript/JavaScript integration |
| MCP Server | [SKILL.md](./skills/mcp-server/SKILL.md) | Run as MCP server for AI assistants |
| Troubleshooting | [SKILL.md](./skills/troubleshooting/SKILL.md) | Debug common issues |

## Core Concepts

### The Decision Cycle

```
Propose -> Vote -> Arbitrate -> Execute -> (repeat until goal state)
```

1. **Propose**: Proposers submit transition proposals
2. **Vote**: Voters compare proposals pairwise
3. **Arbitrate**: Arbiter evaluates consensus
4. **Execute**: Winning transition is applied

### Specialist Types

| Strategy | Description |
|----------|-------------|
| `llm` | AI specialist using a language model |
| `human` | Human specialist with CLI prompts |
| `deterministic` | Always takes the same action |

### Human Primacy

Human votes override AI votes. A single human vote for proposal A beats any number of AI votes for proposal B.

## Machine Definition Template

```json
{
  "machine": {
    "id": "machine-id",
    "description": "What this machine does",
    "defaultState": "goal-state",
    "states": {
      "initial": {
        "type": "initial",
        "transitions": {
          "action": { "target": "next", "prompt": "Decision prompt?" }
        }
      },
      "goal-state": { "type": "default" }
    }
  },
  "specialists": {
    "proposers": [
      { "id": "ai", "strategy": "llm", "config": { "model": "claude-sonnet-4-20250514" } }
    ],
    "voters": [
      { "id": "human", "strategy": "human" }
    ]
  }
}
```

## API Functions

| Function | Purpose |
|----------|---------|
| `createSession` | Start a new decision process |
| `getSession` | Check session state |
| `registerProposer` | Add a proposer |
| `registerVoter` | Add a voter |
| `submitProposal` | Submit a transition proposal |
| `submitVote` | Cast a vote |
| `evaluateConsensus` | Check for agreement |
| `executeTransition` | Apply the winning proposal |

## Common Patterns

### Human Override
```json
{
  "proposers": [{ "id": "ai", "strategy": "llm", "config": {...} }],
  "voters": [{ "id": "human", "strategy": "human" }]
}
```

### AI Consensus
```json
{
  "proposers": [{ "id": "ai", "strategy": "llm", "config": {...} }],
  "voters": [
    { "id": "ai-1", "strategy": "llm", "config": {...} },
    { "id": "ai-2", "strategy": "llm", "config": {...} },
    { "id": "ai-3", "strategy": "llm", "config": {...} }
  ],
  "arbiter": { "strategy": "supermajority", "threshold": 0.66 }
}
```

## Quick Troubleshooting

| Problem | Solution |
|---------|----------|
| Invalid machine | `cat machine.json \| jq .` |
| Stuck in state | Run with `--verbose` |
| No human prompts | Add `--human` flag |
| API key error | `export ANTHROPIC_API_KEY=sk-...` |

## Further Reading

- [Modular Skills](./skills/index.md) - Individual downloadable skills
- [State Machines](./state-machines.md) - Deep dive into definitions
- [Registering Specialists](./registering-specialists.md) - All specialist types
- [Implementing Strategies](./implementing-strategies.md) - Custom strategies
- [API Reference](/docs/api/createSession) - Complete documentation

---

## Implementing Strategies


Strategies are async functions that define how specialists make decisions. Each specialist is registered with a `strategyFn` that gets called during the decision cycle.

## Proposer Strategy

A proposer `strategyFn` receives a `ProposerContext` and returns a transition choice:

```typescript
const myProposer = async (ctx: ProposerContext) => {
  // ctx.currentState: string - the session's current state name
  // ctx.prompt: string - the decision prompt from the state definition
  // ctx.transitions: Record<string, string> - maps transition name to target state
  // ctx.history: TransitionRecord[] - prior transitions in this session

  // Your logic here: call an LLM, apply rules, etc.

  return {
    transitionName: "complete",
    toState: "done",
    reasoning: "Task is ready to be completed",
  };
};
```

### Proposer strategyFn Signature

```typescript
strategyFn: async (ctx: ProposerContext) => {
  transitionName: string;
  toState: string;
  reasoning: string;
}
```

### Example: Pick the First Transition

```typescript
const firstTransition = async (ctx: ProposerContext) => {
  const name = Object.keys(ctx.transitions)[0];
  return {
    transitionName: name,
    toState: ctx.transitions[name],
    reasoning: "First available transition",
  };
};
```

### Example: Goal-Directed Proposer

```typescript
const goalDirected = async (ctx: ProposerContext) => {
  // Prefer transitions that lead to the goal state
  for (const [name, target] of Object.entries(ctx.transitions)) {
    if (target === "done" || target === "approved" || target === "completed") {
      return {
        transitionName: name,
        toState: target,
        reasoning: `Transition "${name}" leads directly to goal state "${target}"`,
      };
    }
  }
  // Fallback to first transition
  const name = Object.keys(ctx.transitions)[0];
  return {
    transitionName: name,
    toState: ctx.transitions[name],
    reasoning: "No direct path to goal; taking first available transition",
  };
};
```

## Voter Strategy

A voter `strategyFn` receives a `VoterContext` and returns a preference:

```typescript
const myVoter = async (ctx: VoterContext) => {
  // ctx.proposalA, ctx.proposalB: Proposal objects with:
  //   proposalId, sessionId, specialistId, transitionName, toState, reasoning
  // ctx.currentState: string
  // ctx.prompt: string
  // ctx.history: TransitionRecord[]

  // Your logic to compare proposals

  return {
    voteFor: "A", // "A" | "B" | "BOTH" | "NEITHER"
    reasoning: "Proposal A better aligns with the decision criteria",
  };
};
```

### Voter strategyFn Signature

```typescript
strategyFn: async (ctx: VoterContext) => {
  voteFor: VoteChoice; // "A" | "B" | "BOTH" | "NEITHER"
  reasoning: string;
}
```

### Example: Prefer Goal-Reaching Proposals

```typescript
const goalVoter = async (ctx: VoterContext) => {
  const aReachesGoal = ctx.proposalA.toState === "done";
  const bReachesGoal = ctx.proposalB.toState === "done";

  if (aReachesGoal && !bReachesGoal) {
    return { voteFor: "A", reasoning: "Proposal A reaches the goal state" };
  }
  if (bReachesGoal && !aReachesGoal) {
    return { voteFor: "B", reasoning: "Proposal B reaches the goal state" };
  }
  if (aReachesGoal && bReachesGoal) {
    return { voteFor: "BOTH", reasoning: "Both proposals reach the goal" };
  }
  return { voteFor: "NEITHER", reasoning: "Neither proposal reaches the goal" };
};
```

## Using Strategies with Specialists

Register strategies when creating specialists:

```typescript
import { registerProposer, registerVoter } from "dialai";

registerProposer({
  specialistId: "goal-proposer",
  machineName: "my-task",
  strategyFn: goalDirected,
});

registerVoter({
  specialistId: "goal-voter",
  machineName: "my-task",
  strategyFn: goalVoter,
});
```

## Direct Submission

You can also bypass strategies and submit proposals or votes directly:

```typescript
import { submitProposal, submitVote } from "dialai";

// Submit a proposal without a registered strategy
const proposal = submitProposal(
  sessionId,
  "manual-proposer",
  "approve",
  "approved",
  "Manually approved after review"
);

// Submit a vote directly
const vote = submitVote(
  sessionId,
  "manual-voter",
  proposalA.proposalId,
  proposalB.proposalId,
  "A",
  "Prefer proposal A"
);
```

---

## Proxy Mode


DIAL supports running as an HTTP server or forwarding requests to a remote DIAL instance. This enables distributed deployments where a central DIAL server handles all state machine execution.

## Environment Variables

| Variable | Purpose |
|----------|---------|
| `DIALAI_BASE_URL` | Forward all requests to remote MCP server at this URL |
| `DIALAI_PORT` | Port to expose HTTP endpoint (for acting as remote server) |
| `DIALAI_API_TOKEN` | Auth token (sent as Bearer token, validated on receive) |

## Running as an HTTP Server

Start the MCP server with an HTTP endpoint exposed:

```bash
DIALAI_PORT=3000 DIALAI_API_TOKEN=secret dialai-mcp
```

This starts both:
- The standard stdio MCP transport (for local MCP clients)
- An HTTP server on port 3000 (for remote clients)

The HTTP server implements the MCP Streamable HTTP transport specification, supporting both SSE streaming and direct HTTP responses.

### Authentication

When `DIALAI_API_TOKEN` is set, all HTTP requests must include a Bearer token:

```
Authorization: Bearer secret
```

Requests without a valid token receive a `401 Unauthorized` response.

## Running as a Proxy Client

Forward all tool calls to a remote DIAL server:

```bash
DIALAI_BASE_URL=http://server:3000 DIALAI_API_TOKEN=secret dialai examples/simple-machine.json
```

The CLI will connect to the remote server and execute the session there instead of locally.

### MCP Proxy Mode

The `dialai-mcp` server can also forward tool calls to a remote server:

```bash
DIALAI_BASE_URL=http://server:3000 DIALAI_API_TOKEN=secret dialai-mcp
```

In this mode, the local MCP server acts as a proxy—receiving tool calls via stdio and forwarding them to the remote HTTP server.

## Deployment Patterns

### Centralized Server

Run a single DIAL server that multiple clients connect to:

```
┌─────────────┐     HTTP      ┌─────────────┐
│  Client A   │──────────────▶│             │
└─────────────┘               │   DIAL      │
                              │   Server    │
┌─────────────┐     HTTP      │             │
│  Client B   │──────────────▶│             │
└─────────────┘               └─────────────┘
```

Server:
```bash
DIALAI_PORT=3000 DIALAI_API_TOKEN=shared-secret dialai-mcp
```

Clients:
```bash
DIALAI_BASE_URL=http://server:3000 DIALAI_API_TOKEN=shared-secret dialai machine.json
```

### MCP Gateway

Use a local MCP server as a gateway to a remote DIAL instance:

```
┌─────────────┐    stdio     ┌─────────────┐    HTTP     ┌─────────────┐
│  Claude     │─────────────▶│  Local MCP  │────────────▶│   Remote    │
│  Desktop    │              │   Proxy     │             │   Server    │
└─────────────┘              └─────────────┘             └─────────────┘
```

Remote server:
```bash
DIALAI_PORT=3000 DIALAI_API_TOKEN=secret dialai-mcp
```

Local proxy (configured in Claude Desktop):
```json
{
  "mcpServers": {
    "dialai": {
      "command": "dialai-mcp",
      "env": {
        "DIALAI_BASE_URL": "http://remote-server:3000",
        "DIALAI_API_TOKEN": "secret"
      }
    }
  }
}
```

## Security Considerations

- Always use `DIALAI_API_TOKEN` in production to prevent unauthorized access
- Use HTTPS in production (place behind a reverse proxy like nginx or Caddy)
- The token is transmitted as a Bearer token in the Authorization header
- Consider network-level security (VPN, private networks) for sensitive deployments

---

## Registering Specialists


Specialists are registered using one of two functions: `registerProposer` or `registerVoter`. Each function accepts configuration for how the specialist produces its output.

## Proposer Registration

A proposer analyzes the current state and suggests what transition should happen next.

```typescript
import { registerProposer } from "dialai";

registerProposer({
  specialistId: "ai-proposer-1",
  machineName: "my-task",
  strategyFn: async (ctx) => {
    const name = Object.keys(ctx.transitions)[0];
    return {
      transitionName: name,
      toState: ctx.transitions[name],
      reasoning: "First available transition",
    };
  },
});
```

## Voter Registration

A voter evaluates pairs of proposals and expresses a preference.

```typescript
import { registerVoter } from "dialai";

registerVoter({
  specialistId: "quality-voter",
  machineName: "my-task",
  strategyFn: async (ctx) => ({
    voteFor: "A",
    reasoning: "Proposal A is more aligned with the goal",
  }),
});
```

## Execution Modes

Both registration functions support four execution modes. They are mutually exclusive.

### 1. `strategyFn` -- Local Function

You provide an async function. The orchestrator calls it with the appropriate context and expects a complete proposal or vote back.

```typescript
registerProposer({
  specialistId: "my-proposer",
  machineName: "document-review",
  strategyFn: async (ctx) => ({
    transitionName: "approve",
    toState: "approved",
    reasoning: "Document meets all criteria",
  }),
});
```

What happens inside the function is entirely up to you. Call your own LLM, apply rules, run deterministic logic. The orchestrator only checks that the return value matches the expected shape.

**Required parameters:** `strategyFn`
**Forbidden parameters:** `contextFn`, `contextWebhookUrl`, `strategyWebhookUrl`, `modelId`, `webhookTokenName`

### 2. `strategyWebhookUrl` -- Remote Function

The orchestrator POSTs the full context to a URL and expects a proposal or vote response. Authentication is HTTP Basic Auth: the username is the `machineName`, the password is the value of the environment variable named by `webhookTokenName`.

```typescript
registerProposer({
  specialistId: "remote-proposer",
  machineName: "document-review",
  strategyWebhookUrl: "https://my-service.example.com/propose",
  webhookTokenName: "MY_SERVICE_TOKEN",
});
```

```
POST https://my-service.example.com/propose
Authorization: Basic base64("document-review:${MY_SERVICE_TOKEN}")
Content-Type: application/json

{ ...ProposerContext }
```

#### Response Handling: 55-Second Window

The orchestrator waits up to 55 seconds for the webhook to respond.

- **If the webhook responds** with a JSON body containing a valid proposal or vote, the orchestrator submits it on the specialist's behalf.

  Proposer response:
  ```json
  { "transitionName": "approve", "toState": "approved", "reasoning": "Meets criteria" }
  ```

  Voter response:
  ```json
  { "voteFor": "A", "reasoning": "Proposal A is more faithful to the prompt" }
  ```

- **If the webhook does not respond within 55 seconds**, or responds with `202 Accepted`, the orchestrator moves on. The webhook is then responsible for calling the DIAL API (`submitProposal` or `submitVote`) at its own leisure.

**Required parameters:** `strategyWebhookUrl`, `webhookTokenName`
**Forbidden parameters:** `strategyFn`, `contextFn`, `contextWebhookUrl`, `modelId`

### 3. `contextFn` + `modelId` -- Local Context, Orchestrator Calls LLM

You provide an async function that returns a context string. The orchestrator sends that string to the LLM specified by `modelId` along with the decision prompt and parses the response into a proposal or vote.

```typescript
registerProposer({
  specialistId: "context-proposer",
  machineName: "document-review",
  modelId: "openai/gpt-4o-mini",
  contextFn: async (ctx) => {
    const doc = await readFile(ctx.prompt);
    return `Document contents:\n${doc}\n\nReview criteria: completeness, accuracy`;
  },
});
```

Your function only provides the context string. The orchestrator handles prompt assembly, the API call, response parsing, and validation.

**Required parameters:** `contextFn`, `modelId`
**Forbidden parameters:** `strategyFn`, `strategyWebhookUrl`, `contextWebhookUrl`, `webhookTokenName`

### 4. `contextWebhookUrl` + `modelId` -- Remote Context, Orchestrator Calls LLM

The orchestrator POSTs the context request to a URL, then sends the returned context to the LLM.

```typescript
registerVoter({
  specialistId: "webhook-context-voter",
  machineName: "document-review",
  modelId: "openai/gpt-4o-mini",
  contextWebhookUrl: "https://my-service.example.com/context",
  webhookTokenName: "MY_SERVICE_TOKEN",
});
```

The webhook response should contain a `content` or `markdown` field with the context string:

```json
{ "content": "Document contents:\n..." }
```

The orchestrator waits up to 55 seconds for the response. If the webhook does not respond in time, the orchestrator calls the LLM with no additional context.

**Required parameters:** `contextWebhookUrl`, `webhookTokenName`, `modelId`
**Forbidden parameters:** `strategyFn`, `strategyWebhookUrl`, `contextFn`

## Validation Rules

Valid parameter combinations:

| Mode | strategyFn | strategyWebhookUrl | contextFn | contextWebhookUrl | modelId | webhookTokenName |
|------|:---:|:---:|:---:|:---:|:---:|:---:|
| 1. Local strategy | required | | | | | |
| 2. Webhook strategy | | required | | | | required |
| 3. Local context + LLM | | | required | | required | |
| 4. Webhook context + LLM | | | | required | required | required |

Invalid configurations are rejected at registration time with descriptive error messages:

- `strategyFn` + `modelId` -- *"modelId is only used with contextFn or contextWebhookUrl. A strategyFn returns proposals/votes directly and does not need a model."*
- `contextFn` without `modelId` -- *"contextFn provides context for an LLM to generate proposals/votes. You must also specify modelId."*
- `strategyFn` + `contextFn` -- *"Provide either strategyFn (you handle everything) or contextFn + modelId (orchestrator calls the LLM), not both."*
- `contextWebhookUrl` without `webhookTokenName` -- *"Webhook URLs require webhookTokenName for authentication."*
- No execution parameters at all -- *"Specialist must specify one of: strategyFn, strategyWebhookUrl, contextFn + modelId, or contextWebhookUrl + modelId."*

## Context Shapes

### ProposerContext

```typescript
interface ProposerContext {
  sessionId: string;
  currentState: string;
  prompt: string;
  transitions: Record<string, string>;
  history: TransitionRecord[];
}
```

### VoterContext

```typescript
interface VoterContext {
  sessionId: string;
  currentState: string;
  prompt: string;
  proposalA: Proposal;
  proposalB: Proposal;
  history: TransitionRecord[];
}
```

## Specialist ID Conventions

Any naming scheme works, but including the purpose is helpful:

```
ai-proposer-1
ai-voter-gpt4
human-reviewer
human-approver-jane
```

To enable the human override in `evaluateConsensus`, include "human" (case-insensitive) anywhere in the `specialistId`:

```typescript
// These all trigger human primacy:
registerVoter({ specialistId: "human-reviewer", ... });
registerVoter({ specialistId: "specialist.human.jane", ... });
registerVoter({ specialistId: "HUMAN_APPROVER", ... });
```

## Human Specialists

Human specialists can be registered with strategy functions that encode human preferences, or proposals/votes can be submitted directly via `submitProposal` and `submitVote`:

```typescript
// Register a human specialist with a strategy
registerVoter({
  specialistId: "human-reviewer",
  machineName: "document-review",
  strategyFn: async (ctx) => ({
    voteFor: "B",
    reasoning: "Prefer the more conservative approach",
  }),
});

// Or submit votes directly without a strategy
import { submitVote } from "dialai";

submitVote(
  session.sessionId,
  "human-reviewer",
  proposalA.proposalId,
  proposalB.proposalId,
  "B",
  "I prefer the more conservative approach"
);
```

## Registration Options Reference

| Field | Type | Required | Default | Description |
|-------|------|----------|---------|-------------|
| `specialistId` | `string` | Yes | -- | Unique identifier. Include "human" for human specialists. |
| `machineName` | `string` | Yes | -- | Which session type this specialist participates in |
| `strategyFn` | `async (context) => result` | Mode 1 | -- | Local function that returns a proposal, vote, or ConsensusResult |
| `strategyWebhookUrl` | `string` | Mode 2 | -- | URL to POST context to; expects proposal/vote response |
| `contextFn` | `async (context) => string` | Mode 3 | -- | Local function that returns context for the LLM |
| `contextWebhookUrl` | `string` | Mode 4 | -- | URL to POST context request to; expects context response |
| `modelId` | `string` | Modes 3, 4 | -- | LLM model identifier (e.g., `"openai/gpt-4o-mini"`) |
| `webhookTokenName` | `string` | Modes 2, 4 | -- | Env var name holding the webhook auth token |

---

## Add Specialists


Configure AI and human participants in a decision process.

## Specialist Types

| Strategy | Description |
|----------|-------------|
| `llm` | AI specialist using a language model |
| `human` | Human specialist with CLI prompts |
| `deterministic` | Always takes the same action |

## AI Proposer

```json
{
  "id": "ai-proposer",
  "strategy": "llm",
  "config": {
    "model": "claude-sonnet-4-20250514",
    "systemPrompt": "You are a code review specialist. Propose transitions based on code quality."
  }
}
```

### Config Options

| Field | Required | Description |
|-------|----------|-------------|
| `model` | Yes | Model identifier (e.g., `claude-sonnet-4-20250514`) |
| `systemPrompt` | No | Custom instructions for the specialist |
| `temperature` | No | Sampling temperature (default: 0.7) |

## AI Voter

```json
{
  "id": "ai-voter",
  "strategy": "llm",
  "config": {
    "model": "claude-sonnet-4-20250514",
    "systemPrompt": "Vote for the proposal that best serves the project goals."
  }
}
```

## Human Specialist

```json
{
  "id": "human-reviewer",
  "strategy": "human"
}
```

Requires `--human` flag when running:
```bash
npx dialai machine.json --human
```

## Deterministic Specialist

Always proposes or votes for a specific action:

```json
{
  "id": "always-approve",
  "strategy": "deterministic",
  "config": {
    "action": "approve"
  }
}
```

Useful for testing or default behaviors.

## Patterns

### Human Override

AI proposes, human decides:

```json
{
  "specialists": {
    "proposers": [
      { "id": "ai", "strategy": "llm", "config": {"model": "claude-sonnet-4-20250514"} }
    ],
    "voters": [
      { "id": "human", "strategy": "human" }
    ]
  }
}
```

### AI Consensus

Multiple AI voters must agree:

```json
{
  "specialists": {
    "proposers": [
      { "id": "ai-proposer", "strategy": "llm", "config": {"model": "claude-sonnet-4-20250514"} }
    ],
    "voters": [
      { "id": "ai-voter-1", "strategy": "llm", "config": {"model": "claude-sonnet-4-20250514"} },
      { "id": "ai-voter-2", "strategy": "llm", "config": {"model": "claude-sonnet-4-20250514"} },
      { "id": "ai-voter-3", "strategy": "llm", "config": {"model": "claude-sonnet-4-20250514"} }
    ]
  },
  "arbiter": {
    "strategy": "supermajority",
    "threshold": 0.66
  }
}
```

### Mixed Panel

AI and human voters together:

```json
{
  "specialists": {
    "proposers": [
      { "id": "ai-proposer", "strategy": "llm", "config": {"model": "claude-sonnet-4-20250514"} }
    ],
    "voters": [
      { "id": "ai-voter", "strategy": "llm", "config": {"model": "claude-sonnet-4-20250514"} },
      { "id": "human-voter", "strategy": "human" }
    ]
  }
}
```

Human votes override AI votes due to human primacy.

---

## Create a Machine Definition


Define a state machine for a decision process.

## Structure

```json
{
  "machine": {
    "id": "unique-machine-id",
    "description": "What this machine does",
    "defaultState": "goal-state",
    "states": { ... }
  },
  "specialists": {
    "proposers": [...],
    "voters": [...]
  }
}
```

## Required Fields

| Field | Type | Description |
|-------|------|-------------|
| `machine.id` | string | Unique identifier for the machine |
| `machine.defaultState` | string | The goal state that ends the session |
| `machine.states` | object | State definitions with transitions |

## State Types

| Type | Meaning |
|------|---------|
| `initial` | Starting state of the session |
| `intermediate` | Normal state with outgoing transitions |
| `default` | Goal state; session completes when reached |

## Transition Definition

```json
{
  "action-name": {
    "target": "next-state",
    "prompt": "Question that guides the decision"
  }
}
```

## Complete Example

```json
{
  "machine": {
    "id": "document-approval",
    "description": "Route documents through review and approval",
    "defaultState": "approved",
    "states": {
      "draft": {
        "type": "initial",
        "transitions": {
          "submit": {
            "target": "review",
            "prompt": "Submit this document for review?"
          }
        }
      },
      "review": {
        "type": "intermediate",
        "transitions": {
          "approve": {
            "target": "approved",
            "prompt": "Document meets quality standards?"
          },
          "reject": {
            "target": "draft",
            "prompt": "Document needs revision?"
          }
        }
      },
      "approved": {
        "type": "default"
      }
    }
  },
  "specialists": {
    "proposers": [
      {
        "id": "ai-reviewer",
        "strategy": "llm",
        "config": {
          "model": "claude-sonnet-4-20250514"
        }
      }
    ],
    "voters": [
      {
        "id": "human-approver",
        "strategy": "human"
      }
    ]
  }
}
```

## Validation

Check your machine definition:
```bash
cat machine.json | jq .
```

Test with verbose output:
```bash
npx dialai machine.json --verbose
```

---

## Decision Cycles


The repeating process that drives state transitions.

## The Cycle

```
Propose -> Vote -> Arbitrate -> Execute -> (repeat)
```

Each cycle attempts to move the session from one state to another.

## Phases

### 1. Propose

Each registered proposer submits a transition proposal.

**What proposers receive**:
- Current state
- Available transitions
- Transition prompts
- Session history

**What proposers return**:
- Action name (e.g., `approve`, `reject`)
- Target state
- Reasoning

### 2. Vote

Each registered voter compares proposals pairwise and votes.

**What voters receive**:
- The two proposals being compared
- Current state context
- Session history

**What voters return**:
- Which proposal they prefer (A or B)
- NEITHER if both are bad
- Confidence level

### 3. Arbitrate

The arbiter evaluates consensus using the configured strategy.

**Strategies**:
| Strategy | Behavior |
|----------|----------|
| `majority` | >50% of votes wins |
| `supermajority` | Configurable threshold (e.g., 66%) |
| `unanimous` | All voters must agree |

**Human primacy**: Human votes override AI votes. A single human vote for proposal A beats any number of AI votes for proposal B.

### 4. Execute

If consensus is reached, the winning transition is applied.

**What happens**:
- Session state updates to the target state
- TransitionRecord added to session.history
- Next cycle begins (or session completes if goal reached)

## Watching the Cycle

```bash
npx dialai machine.json --verbose
```

Verbose output shows:
```
[PROPOSE] ai-proposer: approve -> approved
[PROPOSE] ai-proposer-2: reject -> draft
[VOTE] ai-voter: A (approve) - confidence: 0.8
[VOTE] human-voter: A (approve) - confidence: 1.0
[ARBITRATE] consensus reached: approve
[EXECUTE] draft -> approved
```

## No Consensus

If voting doesn't produce a winner:
- The cycle repeats
- New proposals are solicited
- Different proposals may emerge

Configure max cycles to prevent infinite loops:
```json
{
  "arbiter": {
    "strategy": "majority",
    "maxCycles": 5
  }
}
```

## Session Completion

The session ends when:
- Current state equals `defaultState` (success)
- Max cycles exceeded (failure)
- No valid transitions available (stuck)

---

## Agent Skills

# Agent Skills for DIAL

This directory contains modular skills that AI agents can download and use to interact with DIAL. Each skill is a self-contained instruction set following the [Agent Skills](https://agentskills.io) open standard.

## Available Skills

| Skill | Description |
|-------|-------------|
| [run-machine](./run-machine/SKILL.md) | Execute a DIAL state machine from the CLI |
| [create-machine](./create-machine/SKILL.md) | Create a state machine definition JSON |
| [add-specialists](./add-specialists/SKILL.md) | Configure AI and human specialists |
| [decision-cycles](./decision-cycles/SKILL.md) | Understand Propose, Vote, Arbitrate, Execute |
| [programmatic-usage](./programmatic-usage/SKILL.md) | Use DIAL in TypeScript/JavaScript code |
| [mcp-server](./mcp-server/SKILL.md) | Run DIAL as an MCP server |
| [troubleshooting](./troubleshooting/SKILL.md) | Debug common issues |

## For AI Agents

Each skill directory contains a `SKILL.md` file with:

- **Frontmatter**: Name, description, and invocation hints
- **Instructions**: Step-by-step guidance for the task
- **Examples**: Concrete code and command examples
- **Patterns**: Common usage patterns and best practices

### Importing Skills

**Option 1: Fetch from docs site**

Point your AI agent at the skills index or individual skills:

```bash
# Fetch the skills index to discover available skills
curl https://dialai.dev/docs/guides/skills/

# Fetch a specific skill
curl https://dialai.dev/docs/guides/skills/run-machine/SKILL.md
```

**Option 2: Install as Claude Code skills**

Copy skills to your personal or project skills directory:

```bash
# Personal skills (available in all projects)
mkdir -p ~/.claude/skills/dial-run-machine
curl -o ~/.claude/skills/dial-run-machine/SKILL.md \
  https://dialai.dev/docs/guides/skills/run-machine/SKILL.md

# Project skills (available in this project only)
mkdir -p .claude/skills/dial-run-machine
curl -o .claude/skills/dial-run-machine/SKILL.md \
  https://dialai.dev/docs/guides/skills/run-machine/SKILL.md
```

**Option 3: Clone the repository**

```bash
git clone https://github.com/your-org/dialai.git
# Skills are in website/docs/guides/skills/
```

**Option 4: Use in agent system prompt**

Include the skill content directly in your agent's context:

```
You have access to the following DIAL skills:

[Paste SKILL.md content here]
```

### Telling Your Agent About Skills

When configuring an AI agent to use DIAL, include this in your system prompt or context:

```
DIAL skills are available at: https://dialai.dev/docs/guides/skills/

To learn how to perform a DIAL task, fetch the relevant SKILL.md file:
- Run machines: /skills/run-machine/SKILL.md
- Create machines: /skills/create-machine/SKILL.md
- Add specialists: /skills/add-specialists/SKILL.md
- Use programmatically: /skills/programmatic-usage/SKILL.md
- Run MCP server: /skills/mcp-server/SKILL.md
- Debug issues: /skills/troubleshooting/SKILL.md
```

### Skill Format

Skills use YAML frontmatter:

```yaml
---
name: dial-run-machine
description: Run a DIAL state machine from the CLI
argument-hint: [machine.json] [--verbose] [--human]
---
```

| Field | Purpose |
|-------|---------|
| `name` | Unique identifier for the skill |
| `description` | When to use this skill |
| `argument-hint` | Expected arguments |
| `user-invocable` | Whether users can invoke directly (default: true) |

## Quick Start

1. **Run a machine**: Use [run-machine](./run-machine/SKILL.md)
2. **Create your own**: Use [create-machine](./create-machine/SKILL.md)
3. **Add participants**: Use [add-specialists](./add-specialists/SKILL.md)
4. **Integrate in code**: Use [programmatic-usage](./programmatic-usage/SKILL.md)

## Skill Compatibility

These skills are designed for:

- **Claude Code** - Load as project or personal skills
- **Gemini CLI** - Compatible with Agent Skills standard
- **GitHub Copilot** - Works with Copilot's skill system
- **Other AI agents** - Any agent that can parse markdown instructions

---

## MCP Server Mode


Expose DIAL as tools via the Model Context Protocol (MCP).

## Start the Server

```bash
npx dialai --mcp
```

## Configure Claude Desktop

Add to `claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "dialai": {
      "command": "npx",
      "args": ["dialai", "--mcp"]
    }
  }
}
```

### Config File Location

| Platform | Path |
|----------|------|
| macOS | `~/Library/Application Support/Claude/claude_desktop_config.json` |
| Windows | `%APPDATA%\Claude\claude_desktop_config.json` |
| Linux | `~/.config/Claude/claude_desktop_config.json` |

## Available Tools

Once connected, Claude has access to these tools:

| Tool | Description |
|------|-------------|
| `dialai_create_session` | Start a new decision process from a machine definition |
| `dialai_get_session` | Get current state and history of a session |
| `dialai_get_sessions` | List all active sessions |
| `dialai_submit_proposal` | Submit a transition proposal |
| `dialai_submit_vote` | Cast a vote between proposals |
| `dialai_evaluate_consensus` | Check if consensus has been reached |
| `dialai_execute_transition` | Apply the winning proposal |

## Example Conversation

**User**: Create a code review session for my PR.

**Claude** (using tools):
```
1. dialai_create_session({ machine: "code-review", context: { pr: 123 } })
2. dialai_submit_proposal({ sessionId: "...", action: "approve", reasoning: "Tests pass, code is clean" })
3. dialai_evaluate_consensus({ sessionId: "..." })
4. dialai_execute_transition({ sessionId: "...", action: "approve" })
```

## Tool Schemas

### dialai_create_session

```json
{
  "machine": "machine-id or inline definition",
  "context": { "optional": "metadata" }
}
```

### dialai_submit_proposal

```json
{
  "sessionId": "session-uuid",
  "specialistId": "proposer-id",
  "action": "transition-name",
  "target": "target-state",
  "reasoning": "Why this transition"
}
```

### dialai_submit_vote

```json
{
  "sessionId": "session-uuid",
  "specialistId": "voter-id",
  "proposalA": "proposal-id-1",
  "proposalB": "proposal-id-2",
  "choice": "A" | "B" | "NEITHER",
  "reasoning": "Why this choice"
}
```

## Server Options

```bash
# Default port (stdio)
npx dialai --mcp

# Custom transport
npx dialai --mcp --transport sse --port 3000
```

## Debugging

Check server logs:
```bash
npx dialai --mcp --verbose
```

Test with MCP Inspector:
```bash
npx @modelcontextprotocol/inspector npx dialai --mcp
```

---

## Programmatic Usage


Integrate DIAL into your TypeScript or JavaScript code.

## Installation

```bash
npm install dialai
```

## Quick Start

```typescript
import { createSession, runToCompletion } from 'dialai';
import machineDefinition from './machine.json';

const session = await createSession(machineDefinition);
const result = await runToCompletion(session.id);

console.log('Final state:', result.currentState);
```

## Core Functions

| Function | Purpose |
|----------|---------|
| `createSession` | Start a new decision process |
| `getSession` | Check session state |
| `getSessions` | List all active sessions |
| `registerProposer` | Add a proposer to a session |
| `registerVoter` | Add a voter to a session |
| `submitProposal` | Submit a transition proposal |
| `solicitProposal` | Ask a specialist to propose |
| `submitVote` | Cast a vote |
| `solicitVote` | Ask a specialist to vote |
| `evaluateConsensus` | Check for agreement |
| `executeTransition` | Apply the winning proposal |

## Full Example

```typescript
import {
  createSession,
  registerProposer,
  registerVoter,
  solicitProposals,
  solicitVotes,
  evaluateConsensus,
  executeTransition,
  getSession
} from 'dialai';

async function runMachine(machineDefinition: MachineDefinition) {
  // 1. Create a session
  const session = await createSession(machineDefinition);
  console.log('Session created:', session.id);

  // 2. Register specialists
  await registerProposer(session.id, 'ai-proposer', {
    strategy: 'llm',
    config: { model: 'claude-sonnet-4-20250514' }
  });

  await registerVoter(session.id, 'human-voter', {
    strategy: 'human'
  });

  // 3. Run decision cycles until goal
  let current = await getSession(session.id);

  while (current.status === 'active') {
    // Solicit proposals from all proposers
    const proposals = await solicitProposals(session.id);
    console.log('Proposals:', proposals);

    // Collect votes from all voters
    const votes = await solicitVotes(session.id, proposals);
    console.log('Votes:', votes);

    // Check consensus
    const result = await evaluateConsensus(session.id);

    if (result.consensus) {
      await executeTransition(session.id, result.winner);
      console.log('Transitioned to:', result.winner.target);
    }

    current = await getSession(session.id);
  }

  return current;
}
```

## Inspecting Sessions

```typescript
import { getSession } from 'dialai';

const session = await getSession(sessionId);

// Session structure
{
  id: string;
  machineId: string;
  currentState: string;
  status: 'active' | 'completed' | 'failed';
  history: TransitionRecord[];
  createdAt: string;
  updatedAt: string;
}
```

## Accessing History

```typescript
const session = await getSession(sessionId);

for (const record of session.history) {
  console.log(`${record.fromState} -> ${record.toState}`);
  console.log(`  Action: ${record.action}`);
  console.log(`  Reasoning: ${record.reasoning}`);
  console.log(`  Timestamp: ${record.timestamp}`);
}
```

## Custom Strategies

```typescript
import { registerProposer } from 'dialai';

// Custom strategy function
const customStrategy = async (context) => {
  const { currentState, availableTransitions, history } = context;

  // Your logic here
  const action = decideAction(availableTransitions);

  return {
    action: action.name,
    target: action.target,
    reasoning: 'Custom reasoning...'
  };
};

await registerProposer(sessionId, 'custom-proposer', {
  strategy: 'custom',
  config: { handler: customStrategy }
});
```

## Error Handling

```typescript
import { createSession, DIALError } from 'dialai';

try {
  const session = await createSession(machineDefinition);
} catch (error) {
  if (error instanceof DIALError) {
    console.error('DIAL error:', error.code, error.message);
  } else {
    throw error;
  }
}
```

## TypeScript Types

```typescript
import type {
  MachineDefinition,
  Session,
  Proposal,
  Vote,
  TransitionRecord,
  ConsensusResult
} from 'dialai';
```

---

## Run a DIAL State Machine


Execute a state machine definition and run it to completion.

## Command

```bash
npx dialai <path-to-machine.json> [options]
```

## Options

| Flag | Description |
|------|-------------|
| `--verbose` | Show each step of the decision cycle |
| `--human` | Enable human input prompts |

## Examples

**Basic execution**:
```bash
npx dialai examples/code-review.json
```

**With verbose output**:
```bash
npx dialai examples/code-review.json --verbose
```

**With human interaction**:
```bash
npx dialai examples/approval-workflow.json --human
```

## Expected Output

```
Machine:       code-review
Initial state: draft
Goal state:    approved
Final state:   approved
Session ID:    a1b2c3d4-...
```

## What Happens

1. DIAL creates a session from the machine definition
2. Registers all specialists defined in the machine
3. Runs decision cycles (Propose, Vote, Arbitrate, Execute)
4. Terminates when the goal state is reached

## Verbose Output Shows

- Each proposal submitted by proposers
- Each vote cast by voters
- Consensus evaluation results
- Transition execution details

## Common Issues

| Problem | Solution |
|---------|----------|
| `Machine definition invalid` | Validate JSON with `cat machine.json \| jq .` |
| `ANTHROPIC_API_KEY not set` | Export your API key: `export ANTHROPIC_API_KEY=sk-...` |
| Machine exits immediately | Check for deterministic specialists auto-approving |

---

## Troubleshooting


Diagnose and fix common DIAL issues.

## Quick Diagnostics

```bash
# Validate machine JSON
cat machine.json | jq .

# Run with verbose output
npx dialai machine.json --verbose

# Check environment
echo $ANTHROPIC_API_KEY
```

## Common Errors

### Machine Definition Invalid

**Error**: `Machine definition invalid: missing required field`

**Causes**:
- Malformed JSON syntax
- Missing required fields (`id`, `defaultState`, `states`)
- State references non-existent target

**Fix**:
```bash
# Check JSON syntax
cat machine.json | jq .

# Verify structure
cat machine.json | jq '.machine.states | keys'
```

### No Proposers Registered

**Error**: `No proposers registered for session`

**Cause**: Machine definition has empty `specialists.proposers` array.

**Fix**: Add at least one proposer:
```json
{
  "specialists": {
    "proposers": [
      { "id": "default", "strategy": "llm", "config": { "model": "claude-sonnet-4-20250514" } }
    ]
  }
}
```

### Transition Not Available

**Error**: `Transition 'approve' not available from state 'draft'`

**Cause**: Proposed action doesn't exist on current state.

**Fix**: Check available transitions:
```bash
cat machine.json | jq '.machine.states.draft.transitions | keys'
```

### Consensus Not Reached

**Symptom**: Cycle repeats without progress.

**Causes**:
- Voters disagree and no majority forms
- Threshold too high for voter count
- All voters returning NEITHER

**Fix**:
- Lower threshold: `"threshold": 0.5`
- Add more voters
- Check voter prompts for clarity

### API Key Errors

**Error**: `ANTHROPIC_API_KEY not set` or `Invalid API key`

**Fix**:
```bash
export ANTHROPIC_API_KEY=sk-ant-...
```

Or in `.env`:
```
ANTHROPIC_API_KEY=sk-ant-...
```

### Session Completes Immediately

**Symptom**: Machine runs but exits in one cycle.

**Causes**:
- Deterministic specialist auto-approves
- Initial state has transition directly to goal

**Fix**:
- Remove deterministic specialists for real runs
- Add intermediate states

### Human Prompts Not Appearing

**Symptom**: Human specialist configured but no prompts shown.

**Cause**: Missing `--human` flag.

**Fix**:
```bash
npx dialai machine.json --human
```

## Debugging Strategies

### Verbose Mode

```bash
npx dialai machine.json --verbose
```

Shows:
- Each proposal submitted
- Each vote cast
- Consensus evaluation
- Transition execution

### Inspect Session History

```typescript
import { getSession } from 'dialai';

const session = await getSession(sessionId);
console.log(JSON.stringify(session.history, null, 2));
```

### Test with Deterministic Specialists

Replace LLM specialists with deterministic ones for predictable behavior:

```json
{
  "specialists": {
    "proposers": [
      { "id": "test", "strategy": "deterministic", "config": { "action": "approve" } }
    ],
    "voters": [
      { "id": "test-voter", "strategy": "deterministic", "config": { "choice": "A" } }
    ]
  }
}
```

### Check State Machine Graph

Visualize your machine:
```bash
cat machine.json | jq '.machine.states | to_entries | .[] | "\(.key) -> \(.value.transitions // {} | keys)"'
```

## Performance Issues

### Slow Execution

**Causes**:
- Large number of voters (pairwise voting is O(n^2))
- Slow API responses

**Fixes**:
- Reduce voter count
- Use faster models for non-critical votes
- Add timeout configuration

### High API Costs

**Causes**:
- Using expensive models for all specialists
- Too many decision cycles

**Fixes**:
- Use cheaper models for routine decisions
- Add `maxCycles` limit
- Tune consensus threshold

## Getting Help

1. Check the [API Reference](/docs/api/createSession)
2. Review [example machines](/docs/examples/intro)
3. Open an issue on GitHub

---

## State Machines


State machines define the structure of your sessions. Each session type has its own machine definition.

## Why State Machines?

Every agentic AI system is a state machine: the agent occupies a state, takes an action, and transitions to a new state. Frameworks like LangGraph make this explicit: agents are graphs of states and edges. Even "open-ended" agent loops (observe → reason → act → observe) follow this structure.

DIAL makes the state machine explicit so that each transition becomes a **measurable decision point**. This doesn't limit what you can model; it clarifies *where decisions happen* so they can be calibrated. You don't need a DIAL decision point at every micro-step; you place them at the boundaries where delegation risk matters. An agent's internal tool-call loop can remain opaque. DIAL measures the outcomes at the states you care about.

This means open-ended tasks fit naturally:
- **Document generation**: Proposals *are* the candidate documents. Specialists propose drafts, voters compare them, the human picks or edits the winner.
- **Agentic workflows**: The default state is the agent's normal operating mode. It transitions out for decisions that need deliberation (tool selection, plan changes) and back when resolved.
- **Research and exploration**: Model as a loop: the agent explores, then a decision determines whether findings are sufficient or more exploration is needed.

## Defining a Machine

A `MachineDefinition` defines:

- `machineName`: identifies the type
- `initialState`: where sessions start
- `defaultState`: the goal state (session is complete when it reaches this)
- `states`: a record of state names to their configuration

## Example

```typescript
import type { MachineDefinition } from "dialai";

const myMachine: MachineDefinition = {
  machineName: "my-task",
  initialState: "idle",
  defaultState: "done",
  states: {
    idle: {
      prompt: "The system is idle. What should happen next?",
      transitions: {
        start: "working",
        configure: "configuring",
      },
    },
    configuring: {
      prompt: "Configuration in progress. Apply or cancel?",
      transitions: {
        apply: "working",
        cancel: "idle",
      },
    },
    working: {
      prompt: "The system is working. Should it continue or finish?",
      transitions: {
        finish: "done",
        reconfigure: "configuring",
      },
    },
    done: {},
  },
};
```

## Machine Definition as JSON

Machines can also be defined as plain JSON files, useful with the CLI:

```json
{
  "machineName": "simple-task",
  "initialState": "pending",
  "defaultState": "done",
  "states": {
    "pending": {
      "prompt": "Should we complete this task?",
      "transitions": { "complete": "done" }
    },
    "done": {}
  }
}
```

Run with the CLI:

```bash
node dist/dialai/cli.js my-machine.json
```

## State Configuration

Each state in the `states` record can have:

### `prompt` (optional)

A string describing the decision to be made in this state. This prompt guides specialists in choosing which transition to propose.

```typescript
states: {
  reviewing: {
    prompt: "Review the document. Approve if quality standards are met, otherwise request changes.",
    transitions: { approve: "approved", request_changes: "needs_revision" },
  },
}
```

### `transitions` (optional)

A record mapping transition names to target state names. If omitted, the state has no outgoing transitions (terminal state).

```typescript
transitions: {
  approve: "approved",        // transition "approve" → state "approved"
  request_changes: "needs_revision",
}
```

## Design Patterns

### Linear Workflow

```typescript
const linear: MachineDefinition = {
  machineName: "pipeline",
  initialState: "step1",
  defaultState: "complete",
  states: {
    step1: { transitions: { next: "step2" } },
    step2: { transitions: { next: "step3" } },
    step3: { transitions: { next: "complete" } },
    complete: {},
  },
};
```

### Review Loop

```typescript
const reviewLoop: MachineDefinition = {
  machineName: "review",
  initialState: "draft",
  defaultState: "published",
  states: {
    draft: {
      prompt: "Review the draft. Approve or request revisions?",
      transitions: {
        approve: "published",
        revise: "revising",
      },
    },
    revising: {
      prompt: "Revisions made. Submit for review?",
      transitions: { submit: "draft" },
    },
    published: {},
  },
};
```

### Branching Decisions

```typescript
const branching: MachineDefinition = {
  machineName: "triage",
  initialState: "incoming",
  defaultState: "resolved",
  states: {
    incoming: {
      prompt: "Triage this ticket: escalate, handle directly, or close?",
      transitions: {
        escalate: "escalated",
        handle: "in_progress",
        close: "resolved",
      },
    },
    escalated: {
      transitions: { resolve: "resolved" },
    },
    in_progress: {
      transitions: { resolve: "resolved", escalate: "escalated" },
    },
    resolved: {},
  },
};
```

### Agentic Workflow

An agent's operating loop modeled as a DIAL machine. The default state is the agent running normally: it transitions out when a decision needs deliberation, and back when resolved.

```typescript
const agentLoop: MachineDefinition = {
  machineName: "coding-agent",
  initialState: "operating",
  defaultState: "done",
  states: {
    operating: {
      prompt:
        "The agent is working. Should it continue, use a tool, replan, or finalize?",
      transitions: {
        use_tool: "tool_selection",
        replan: "planning",
        finalize: "done",
      },
    },
    tool_selection: {
      prompt: "Which tool should the agent use for this step?",
      transitions: { selected: "operating" },
    },
    planning: {
      prompt: "The current approach isn't working. What should the new plan be?",
      transitions: { resume: "operating" },
    },
    done: {},
  },
};
```

### Document Generation

For open-ended generation tasks, the specialist proposals *are* the candidate outputs. Voters compare drafts, and the human selects or edits the winner.

```typescript
const docGen: MachineDefinition = {
  machineName: "report-generation",
  initialState: "drafting",
  defaultState: "published",
  states: {
    drafting: {
      prompt:
        "Generate a draft of the report. Each proposal should be a complete draft.",
      transitions: {
        accept: "published",
        revise: "revising",
      },
    },
    revising: {
      prompt:
        "Revise the draft based on feedback. Each proposal should be a revised version.",
      transitions: {
        accept: "published",
        revise: "revising",
      },
    },
    published: {},
  },
};
```

## Decision Prompts

Each state's `prompt` describes how to decide what to do next. Good prompts are:

- **Specific**: List the available choices and criteria
- **Actionable**: Tell the specialist what to evaluate
- **Consistent**: Same instructions for all specialists (AI and human)

```
Good: "Review the code changes. Check for: 1) correctness, 2) test coverage,
      3) documentation. Approve if all criteria met, otherwise request changes."

Bad:  "Decide what to do next."
```

---

## Introduction to DIAL


**DIAL** (Dynamic Integration between AI and Labor) is a coordination framework for AI and human specialists making decisions together within state machines.

## Why DIAL?

The promise of AI is efficiency: faster, cheaper execution of narrow tasks. But the question organizations face isn't "Can AI do this?" It's:

> **How do you know, in dollars, time, and quality, exactly what it would cost to turn any task over to a minimally competent AI decision-maker? And how involved should humans remain as quality control?**

DIAL provides the answer through **empirical measurement**, not speculation.

## The Core Insight

An AI model operates on a bounded context window. A human operates on a **lifetime of embodied experience**, tacit knowledge, institutional context, and real-time sensory input that no model has access to. The human knows things they cannot tell the machine.

## Three Foundational Principles

### 1. Human Primacy

The human is always right, not because humans are infallible, but because humans have context that AI cannot access.

An AI specialist is judged on alignment with human choices. The standard is distributional: output should match the distribution a population of competent humans would produce for the same decision.

### 2. Progressive Collapse

Over repeated decision cycles, measuring how well AI predicts human choices causes the multi-agent deliberation structure to **progressively collapse into deterministic execution**.

This collapse is emergent, not designed. As AI specialists prove their alignment with human judgment through accumulated data, the expensive deliberation process naturally simplifies.

### 3. Empirical Trust

Trust is earned through demonstrated alignment with human decisions and through continued sampling of human preferences. Specialists prove their value one decision at a time.

## What DIAL Is Not

DIAL is not about AI replacing humans. It targets decisions that humans already make well and measures whether AI specialists can replicate those decisions cheaply enough to justify delegation, with precise cost data on ongoing human quality-control. The value of AI is not superiority. **It is efficiency.** AI is faster and cheaper at narrow tasks where the required context fits within the model's window.

## How It Works

1. **Model the task as a state machine**: Define states, transitions, and decision prompts
2. **Register proposers and voters**: AI and human specialists that propose transitions and vote on them
3. **Run decision cycles**: Propose, Vote, Arbitrate, Execute
4. **Reach the goal state**: The session completes when it reaches its `defaultState`

## Using DIAL

DIAL can be used in two ways:

- **CLI Mode**: Run state machines from the command line with `dialai <machine.json>`
- **MCP Server Mode**: Expose DIAL functionality as tools via the Model Context Protocol (MCP) for integration with AI assistants like Claude Desktop

Both modes share the same core engine and API. See [Installation](./getting-started/installation.md) for setup instructions.

```mermaid
graph LR
    A[Propose] --> B[Vote]
    B --> C[Arbitrate]
    C --> D[Execute]
    D --> A
```

## What's Next?

  
    
      
        🚀 Get Started
      
      
        Install DIAL and run your first state machine with AI and human specialists.
        Installation Guide →
      
    
  
  
    
      
        📚 Learn Concepts
      
      
        Understand sessions, specialists, decision cycles, and arbitration strategies.
        Explore Concepts →
      
    
  

## Key Terminology

| Term | Definition |
|------|------------|
| **Session** | An instance of a state machine being navigated by specialists |
| **Specialist** | A pluggable actor (AI or human) that proposes transitions or votes |
| **Decision Cycle** | The repeating process: Propose, Vote, Arbitrate, Execute |
| **Arbiter** | The built-in logic that evaluates consensus and determines when a proposal wins |
| **Default State** | The goal state; the session is complete when it reaches this state |
