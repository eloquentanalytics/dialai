# DIAL

> Dynamic Integration between AI and Labor

This file contains all documentation content in a single document following the llmstxt.org standard.

## Agent Experience Development


DIAL is designed for LLM-driven agents as first-class participants. Every design decision optimizes for agents that need to understand, integrate with, and act within the framework autonomously: the API shape, the documentation format, and the way changelogs are written.

## Agents as Participants

The specialist abstraction exists so that LLM agents can register themselves as proposers, voters, and arbiters in a decision cycle. An agent reading a state machine definition can determine what state the session is in, what transitions are available, and what the prompt is asking. It can then submit a proposal or cast a vote using the same API a human would use.

This is the point. DIAL does not treat agents as a backend detail or an orchestration layer. Agents sit alongside humans in the decision cycle and are evaluated by the same arbiter under the same rules. The difference is that human votes override, because [human primacy](./concepts/human-primacy.md) is a safety constraint on the system.

## Spec-Driven Development

The source of truth for DIAL is its documentation. The code in `/src` is generated from the documentation files, not the other way around.

This means an agent reading the docs has the authoritative specification. If the docs say `executeTransition` accepts an optional `reasoning` parameter and records a `TransitionRecord` in `session.history`, that is what the implementation does. An agent does not need to read the TypeScript source to understand the contract. The docs are the contract.

This also means the docs are written with the precision an agent needs: exact function signatures, explicit parameter types, concrete return values. Prose explains intent. Code blocks define behavior.

## Changelogs as Instructions

Commit messages and changelogs in the DIAL repository are written as instructions to an LLM that is maintaining a codebase which depends on DIAL.

A conventional changelog entry tells a human what changed. A DIAL changelog entry tells an agent **what to do about it**:

- What the change is
- What call sites are affected
- What the migration path is
- What the new behavior looks like in code

This is a deliberate choice. The primary consumer of DIAL's change history is an agent that needs to update its integration. The writing style reflects that.

## Reference Implementations

DIAL ships reference implementations in TypeScript as CLI tools. The CLI accepts a machine definition as JSON and runs it to completion:

```bash
node dist/dialai/cli.js examples/simple-machine.json
```

```
Machine:       simple-task
Initial state: pending
Goal state:    done
Final state:   done
Session ID:    a1b2c3d4-...
```

The CLI is minimal by design. It demonstrates the exact sequence of API calls an agent would make (create a session, register proposers and voters, solicit proposals, evaluate consensus, execute transitions) in a form that is easy for an agent to read, replicate, and extend.

The help documentation and error messages are written for LLM comprehension. When the CLI fails, it says what went wrong and what the valid inputs are, in plain text that an agent can parse and act on.

## Documentation for Agents

DIAL documentation is served in two forms:

1. **Traditional web**: the Docusaurus site you are reading now, with structured navigation, code examples, and concept explanations
2. **llms.txt**: a machine-readable format generated by the [docusaurus-plugin-llms](https://github.com/signalwire/docusaurus-plugin-llms) plugin, which concatenates all documentation into a single text file optimized for LLM context windows

The `llms.txt` format allows an agent to ingest the entire DIAL specification in one read operation rather than navigating a site. Both formats contain the same information. The web form is organized for browsing. The `llms.txt` form is organized for ingestion.

## Tool-Oriented, Not Resource-Oriented

DIAL's API is **tool-oriented** rather than resource-oriented. The distinction matters for agents.

A resource-oriented API exposes data: "here is a session, here are its proposals, here are its votes." An agent working with a resource-oriented API must figure out the correct sequence of reads and writes to accomplish a goal.

A tool-oriented API exposes actions: `submitProposal`, `submitVote`, `evaluateConsensus`, `executeTransition`. Each function is a discrete action with a clear purpose. An agent with tool-use capabilities can map these directly to its tool-calling interface.

The 12 functions in the DIAL API are designed to be the 12 tools an agent needs:

| Function | Action |
|---|---|
| `createSession` | Start a new decision process |
| `getSession` | Check the current state |
| `getSessions` | List all active processes |
| `registerProposer` | Join a decision process as a proposer |
| `registerVoter` | Join a decision process as a voter |
| `registerArbiter` | Define custom consensus logic |
| `submitProposal` | Propose a transition |
| `solicitProposal` | Ask a specialist's strategy to propose |
| `submitVote` | Cast a vote between two proposals |
| `solicitVote` | Ask a specialist's strategy to vote |
| `evaluateConsensus` | Check if the group has reached agreement |
| `executeTransition` | Apply the winning proposal |

An agent calling `submitProposal(sessionId, myId, "approve", "approved", "Document meets quality standards")` is doing exactly one thing: proposing a state transition. There is no ambiguity about what the call does, what it returns, or what happens next.

This is agent experience development. The framework is built so that the agent's path from "I have a task" to "I took an action" is as short and unambiguous as possible.

## The Constitution

DIAL publishes a [Constitution](/constitution), a detailed description of how AI specialists should reason and behave within the framework. It is not a policy document for humans. It is written with the specialist as its primary audience, optimized for precision over accessibility, because a specialist needs to be able to cite it during reasoning.

### Why a Constitution Matters

An LLM acting as a DIAL specialist faces a specific problem: it needs to know what "good behavior" means before it encounters any particular decision. The constitution solves this by defining a priority hierarchy (alignment with humans first, faithfulness to the prompt second, honesty third, usefulness fourth), hard constraints (no fabrication, no coordination between specialists, no manipulating the arbiter), and concrete guidance for making proposals and casting votes.

Without the constitution, every specialist would invent its own interpretation of what DIAL expects. The system's measurements would reflect inconsistent reasoning rather than genuine alignment differences.

### Using the Constitution as a System Prefix

We encourage any agent acting as a DIAL specialist to prefix its system prompt with the constitution text. The constitution is designed for exactly this use: it fits within a context window, it uses precise language an LLM can follow, and every principle is structured so the specialist can trace a decision back to a specific section.

A specialist that has internalized the constitution will:

- Defer to demonstrated human preferences over its own reasoning
- Express calibrated confidence rather than fabricating conviction
- Reflect human-like variance in its output probabilities rather than collapsing to a single answer with artificial certainty
- Submit NULL proposals or vote NEITHER when genuinely uncertain
- Cite the decision prompt and session history as evidence, not its own independent analysis

This is also how we use the constitution in fine-tuning. Training data for DIAL specialists is evaluated against the constitution's priority hierarchy. The constitution defines what correct means, and correct means aligned with the human.

The full text is available at [/constitution](/constitution).

## Spec Change Workflow

When a specification is updated, the change propagates through the codebase in a fixed order. This order is mandatory.

1. **Update the tests**: The spec changed, so the tests must change first. Write or modify tests that assert the new behavior described in the updated docs. These tests will fail. That is correct.
2. **Update the implementation**: Modify the code in `/src` until the new tests pass and no existing tests regress.
3. **Run the tests against the example machines**: Execute every machine definition in `/examples` through the CLI and programmatic API. The examples are integration tests. If a spec change breaks an example, the example is wrong, not the spec.
4. **Fix the example machines**: Update any example that fails to conform to the new spec. Record what changed in each example and why.
5. **Synthesize and write the changelog**: Combine the spec change, the implementation change, and the example fixes into a single changelog entry. Write it as an instruction to an agent that depends on DIAL: what changed, what breaks, what to do about it.

Each change like this is a **branch**. The branch contains a series of commits following the steps above. When the branch is merged, the merge commit carries the changelog message and a version bump.

### Versioning

The current version is tracked in `VERSION.md` at the repository root. The format is a single line containing the semantic version number. The merge commit that closes a spec change branch increments the version:

- **Patch**: bug fixes, example corrections, doc clarifications that do not change behavior
- **Minor**: new functions, new parameters, new fields on existing types
- **Major**: removed functions, changed return types, changed parameter semantics

The version in `VERSION.md` is the version. There is no `package.json` version to keep in sync, no release script to run. An agent reading `VERSION.md` knows what version of the spec the codebase implements.

---

## API Reference


The DialAI API provides 12 functions for creating sessions, registering specialists, and managing the decision cycle. Functions that invoke strategy functions (`solicitProposal`, `solicitVote`, `runSession`) are async and return Promises. All other functions are synchronous.

## Session Functions

### `createSession(machine: MachineDefinition): Session`

Creates a new session instance. Generates a UUID, sets `currentState` to `machine.initialState`, and stores the session.

```typescript
import { createSession } from "dialai";

const session = createSession(machine);
```

### `getSession(sessionId: string): Session`

Retrieves a session by ID. Throws if not found.

```typescript
import { getSession } from "dialai";

const session = getSession("a1b2c3d4-...");
```

### `getSessions(): Session[]`

Returns all stored sessions.

```typescript
import { getSessions } from "dialai";

const all = getSessions();
```

## Specialist Functions

### `registerProposer(opts): Proposer`

Registers a proposer for a session type. Supports four execution modes: `strategyFn`, `strategyWebhookUrl`, `contextFn + modelId`, or `contextWebhookUrl + modelId`. See the [registering specialists guide](../guides/registering-specialists.md) for details on all modes.

```typescript
import { registerProposer } from "dialai";

const proposer = registerProposer({
  specialistId: "ai-proposer-1",
  machineName: "my-task",
  strategyFn: async (ctx) => ({
    transitionName: Object.keys(ctx.transitions)[0],
    toState: Object.values(ctx.transitions)[0],
    reasoning: "First available",
  }),
});
```

### `registerVoter(opts): Voter`

Registers a voter for a session type. Supports the same four execution modes as `registerProposer`. See the [registering specialists guide](../guides/registering-specialists.md) for details.

```typescript
import { registerVoter } from "dialai";

const voter = registerVoter({
  specialistId: "ai-voter-1",
  machineName: "my-task",
  strategyFn: async (ctx) => ({
    voteFor: "A",
    reasoning: "Proposal A is better aligned",
  }),
});
```

### `registerArbiter(opts): Arbiter`

Registers a custom arbiter for a session type. Supports the same four execution modes as `registerProposer` and `registerVoter`. See the [registering specialists guide](../guides/registering-specialists.md) for details.

```typescript
import { registerArbiter } from "dialai";

const arbiter = registerArbiter({
  specialistId: "custom-arbiter",
  machineName: "my-task",
  strategyFn: async (ctx) => ({
    consensusReached: true,
    winningProposalId: ctx.proposals[0]?.proposalId,
    reasoning: "First proposal wins",
  }),
});
```

## Proposal Functions

### `submitProposal(sessionId, specialistId, transitionName, toState, reasoning?): Proposal`

Creates and stores a proposal with a generated UUID.

```typescript
import { submitProposal } from "dialai";

const proposal = submitProposal(
  session.sessionId,
  "ai-proposer-1",
  "approve",
  "approved",
  "Document meets standards"
);
```

### `solicitProposal(sessionId, specialistId): Promise<Proposal>`

Calls the specialist's strategy function with the session's current state and transitions, then submits the resulting proposal. Async because strategy functions are async.

```typescript
import { solicitProposal } from "dialai";

const proposal = await solicitProposal(session.sessionId, "ai-proposer-1");
```

## Vote Functions

### `submitVote(sessionId, specialistId, proposalIdA, proposalIdB, voteFor, reasoning?): Vote`

Creates and stores a vote with a generated UUID.

```typescript
import { submitVote } from "dialai";

const vote = submitVote(
  session.sessionId,
  "ai-voter-1",
  proposalA.proposalId,
  proposalB.proposalId,
  "A",
  "Proposal A is better aligned"
);
```

### `solicitVote(sessionId, specialistId, proposalIdA, proposalIdB): Promise<Vote>`

Calls the specialist's strategy function with the two proposals, then submits the resulting vote. Async because strategy functions are async.

```typescript
import { solicitVote } from "dialai";

const vote = await solicitVote(
  session.sessionId,
  "ai-voter-1",
  proposalA.proposalId,
  proposalB.proposalId
);
```

## Consensus & Execution

### `evaluateConsensus(sessionId: string): ConsensusResult`

Evaluates consensus for all proposals and votes in the session:
- **0 proposals**: `{ consensusReached: false }`
- **1 proposal**: `{ consensusReached: true, winningProposalId: ... }`
- **2+ proposals**: Human votes override; otherwise ahead-by-k (k=1)

```typescript
import { evaluateConsensus } from "dialai";

const result = evaluateConsensus(session.sessionId);
if (result.consensusReached) {
  console.log("Winner:", result.winningProposalId);
}
```

### `executeTransition(sessionId, transitionName, toState, reasoning?): Session`

Validates the transition from the current state, records it in `session.history` with the given `reasoning`, updates `currentState`, and clears all proposals and votes for the session.

```typescript
import { executeTransition } from "dialai";

const updated = executeTransition(
  session.sessionId,
  "approve",
  "approved",
  consensus.reasoning
);
console.log(updated.currentState); // "approved"
console.log(updated.history);      // [{ fromState: "review", toState: "approved", reasoning: "...", ... }]
```

## Engine

### `runSession(machine: MachineDefinition): Promise<Session>`

Runs a machine to completion. Creates a session, registers a built-in deterministic proposer, and loops through the decision cycle until `currentState === defaultState`. Async because it awaits strategy functions.

```typescript
import { runSession } from "dialai";

const session = await runSession(machine);
```

## Types

All types are exported from the main package:

```typescript
import type {
  MachineDefinition,
  Session,
  Proposer,
  Voter,
  Arbiter,
  Proposal,
  Vote,
  ConsensusResult,
  ProposerContext,
  VoterContext,
  ArbiterContext,
  VoteChoice,
} from "dialai";
```

## Store

The in-memory store is also exported for advanced use and testing:

```typescript
import { sessions, specialists, proposals, votes, clear } from "dialai";

// clear() resets all maps - useful for test isolation
clear();
```

---

## Arbitration


**Arbitration** is the process of evaluating consensus and determining when a proposal has sufficient support to execute.

## Overview

After specialists submit proposals and cast votes, the `evaluateConsensus` function analyzes the results:

```mermaid
graph LR
    V[Votes] --> A[evaluateConsensus]
    P[Proposals] --> A
    A --> |Consensus| E[Execute]
    A --> |No Consensus| F[Error]
```

## The Built-in Arbiter: Ahead-by-K

DIAL ships with a built-in arbitration strategy that implements **voting with human override**.

### Rules

1. **Zero proposals**: No consensus (`consensusReached: false`)

2. **Single proposal**: Auto-consensus (the lone proposal wins)

3. **Two or more proposals**: Evaluate votes:
   - If any human has voted, their choice wins immediately
   - Otherwise, tally votes per proposal
   - The leading proposal must be ahead by `k = 1` votes

### Vote Tallying

For each vote comparing proposals A and B:

| Vote | Effect |
|------|--------|
| `"A"` | Adds 1 to proposal A's tally |
| `"B"` | Adds 1 to proposal B's tally |
| `"BOTH"` | Adds 1 to both proposals' tallies |
| `"NEITHER"` | Adds nothing to either proposal |

If all voters vote NEITHER, no proposal reaches the threshold and consensus fails.

### Example

```
Proposal A: "approve"
  - Voter 1 votes A
  - Voter 2 votes A
  Total for A: 2

Proposal B: "request_changes"
  - Voter 3 votes B
  Total for B: 1

Ahead by: 2 - 1 = 1

k = 1: Consensus reached (1 >= 1)
```

### Human Override

When a human votes, the calculation short-circuits:

```
Proposal A: "approve"
  - AI Voter 1 votes A
  - AI Voter 2 votes A

Proposal B: "request_changes"
  - Human Voter votes B

Result: B wins immediately

Human primacy: AI votes don't matter when a human participates.
```

A specialist is considered "human" if their `specialistId` contains "human" (case-insensitive).

## Using evaluateConsensus

```typescript
import { evaluateConsensus } from "dialai";

const result = evaluateConsensus("session-123");

// Result shape:
// {
//   consensusReached: boolean,
//   winningProposalId?: string,
//   reasoning: string
// }
```

The `ConsensusResult` type:

```typescript
interface ConsensusResult {
  consensusReached: boolean;
  winningProposalId?: string;
  reasoning: string;
}
```

## The Engine's Behavior

When using `runSession`, the engine handles arbitration automatically:

1. **Single proposal**: auto-wins (e.g., only the built-in proposer is registered)
2. **2+ proposals**: the engine uses Swiss tournament pairing, matching proposals with similar accumulated support first. It round-robins through registered voters, checking for consensus after each vote. Voting stops as soon as the ahead-by-k threshold is met. The O(N²) full comparison is the worst case, not the typical case.
3. **No consensus**: if no proposal crosses the threshold after all available pairs and voters are exhausted, the engine throws an error

## Best Practices

### 1. Start with Simple Machines

Begin with machines where the built-in deterministic proposer can navigate to the goal. Add additional proposers and voters as complexity grows.

### 2. Use Descriptive Reasoning

Always include clear reasoning in proposals and votes:

```typescript
// Good
{ voteFor: "A", reasoning: "Proposal A moves to done state, which is the goal" }

// Bad
{ voteFor: "A", reasoning: "A" }
```

### 3. Monitor NEITHER Votes

High NEITHER rates indicate:
- Poor proposal quality
- Unclear decision prompts
- Specialists that don't understand the task

## Related Concepts

- [Decision Cycle](./decision-cycle.md): Where arbitration fits
- [Specialists](./specialists.md): Voting
- [Human Primacy](./human-primacy.md): Why humans override

---

## Decision Cycle


When a session is not in its default state, the system progresses through a repeating cycle until it reaches the goal.

## The Cycle

### 1. Proposal Solicitation

The engine solicits proposals from all registered proposers for the session's type. Each proposer's strategy function is called with the current state and available transitions.

### 2. Proposal Submission

Proposers submit their recommendations. Each proposal includes:
- The proposed transition name
- The target state
- Reasoning for the proposal

### 3. Vote Solicitation

If there are 2+ proposals, voters compare them pairwise using Swiss tournament pairing. See [Arbitration](./arbitration.md) for pairing and early-stopping details.

### 4. Arbitration

The built-in `evaluateConsensus` function determines the winner. See [Arbitration](./arbitration.md) for the full rules.

### 5. Transition Execution

If consensus is reached, the winning proposal's transition executes. The session's `currentState` is updated, and all proposals and votes for that session are cleared for the next cycle.

The cycle repeats until the session reaches its `defaultState`.

## The Engine

The `runSession` function automates the full cycle:

```typescript
import { runSession } from "dialai";
import type { MachineDefinition } from "dialai";

const machine: MachineDefinition = {
  machineName: "my-task",
  initialState: "pending",
  defaultState: "done",
  states: {
    pending: {
      prompt: "Should we complete this task?",
      transitions: { complete: "done" },
    },
    done: {},
  },
};

const session = await runSession(machine);
// session.currentState === "done"
```

`runSession` automatically:
1. Creates a session
2. Registers a built-in deterministic proposer (picks the first available transition)
3. Loops: solicit proposals → solicit votes (if needed) → evaluate consensus → execute transition
4. Returns the completed session

## Error Handling

- If no transitions are available from the current state, the built-in proposer throws
- If consensus cannot be reached (e.g., tied votes with insufficient margin), the engine throws
- If the winning proposal's transition is invalid, `executeTransition` throws

---

## Human Primacy


**The human is always right**, not because humans are infallible, but because humans have context that AI cannot access.

## The Context Argument

An AI model operates on a **bounded context window**: thousands or millions of tokens of visible information.

A human operates on:
- A **lifetime of embodied experience**
- **Tacit knowledge** that can't be articulated
- **Institutional context** and organizational history
- **Real-time sensory input** that no model can access
- **Relationships** and social dynamics
- **Intuitions** built from millions of decisions

The human knows things they **cannot tell the machine**.

## Why "Always Right"?

This isn't a claim about human infallibility. Humans make mistakes constantly. The claim is about **information asymmetry**.

When a human's decision looks wrong from the AI's perspective, there are two possibilities:

1. **The human made an error**: possible, but the AI can't verify this
2. **The human has context the AI doesn't**: invisible to the AI by definition

The machine, trained on human works and operating on a compressed subset of human knowledge, **cannot determine when the human is wrong**, because what looks like an error from the AI's limited vantage point may reflect context the AI simply doesn't have.

Because the AI cannot reliably distinguish human errors from human context it lacks, human decisions are the best available ground truth for calibration, not because they're perfect, but because no better signal is available from the AI's position. Any attempt by the AI to "correct" human judgment requires the AI to be confident it has the full picture, which is precisely the assumption DIAL rejects.

### The Parent Analogy

It is always safer for the AI to assume the human had reasons, just as it is safer for a child to defer to a parent, not because the parent is infallible, but because the parent has context the child cannot access.

## The Distributional Standard

The goal of a DIAL specialist is not to match a single human's idiosyncratic choices. It is to match the **probability distribution** a population of competent humans would produce for the same decision.

If you gave 1,000 competent humans the same state and transition options, their choices would form a distribution, clustered around the most common answer with some spread across alternatives.

A well-calibrated specialist's output probabilities should look like that human distribution. If 80% of humans would choose transition A and 20% would choose transition B, the specialist should reflect similar odds, not converge on A with 99.9% confidence.

### Why Distribution Matching Matters

**Overconfidence is a signal, not a virtue.** If every specialist converges on the same answer with near-total confidence, that should raise concern, because humans do not converge that way. Real human decisions have variance. A specialist that eliminates that variance isn't more accurate; it's miscalibrated.

**The improvement path is principled.** To push the specialist's accuracy beyond the human distribution, you must first tighten the human distribution itself through better training, clearer decision prompts, and improved context provided at the point of decision.

### The Specialist Reflects the Humans It Learns From

DIAL does not assume the humans are average. It calibrates to whatever the humans actually are. The specialist will approach the capability level of the humans it observes:

- **If the humans are all experts**, the distribution is tight and centered on expert-quality decisions. The specialist converges toward expert performance.
- **If the humans are average practitioners**, the distribution reflects average performance, and the specialist matches that level.
- **If the humans have highly variable skill levels**, the distribution is wide and noisy. The specialist has a poor signal to learn from and will likely perform below average, because it cannot distinguish expert decisions from novice decisions within a blurred distribution.

The specialist's ceiling is the quality of the human signal. The framework makes this relationship explicit and measurable.

## Implications for AI Specialists

### 1. Predict, Don't Judge

An AI specialist should choose what the human **would** choose, even if its own reasoning disagrees.

```
Bad:  "Based on my analysis, the correct action is X"
Good: "Based on observed human patterns, the human would likely choose Y"
```

### 2. Judgment Criteria

AI specialists are judged on **alignment with human choices**, not on their independent correctness:

| Metric | Good | Bad |
|--------|------|-----|
| Alignment rate | 95% match with human | 60% match with human |
| Reasoning quality | "Human would prefer X because..." | "The objectively correct answer is..." |
| Confidence calibration | "High confidence human chooses X" | "I am certain X is correct" |
| Distribution match | Reflects human-like variance across options | Collapses to a single answer with near-total confidence |

### 3. No Standing to Override

If an AI specialist has strong reasoning that the human is wrong, it should:
- Present its reasoning in the proposal
- Let the human see and consider it
- NOT override the human decision
- NOT claim authority based on its reasoning

## When Humans Disagree

### The Architecture Prevents Simultaneous Disagreement

In DIAL, the first human vote at a decision point advances the state machine immediately. There is no window for a second human to cast a competing vote on the same decision; the machine has already moved forward. A second human could only intervene by going back and restarting the decision, but at that point it is a new decision cycle, not a tie.

This means the "two humans disagree" scenario is **hypothetical, not operational**. The system never faces a moment where it must choose between two conflicting human answers.

### Both Humans Are "Right" in a Distributional Sense

When we say both humans are right, we mean two things:

1. **Humans exist in a distribution.** Human A choosing "approve" and Human B choosing "request changes" are both points in the [distributional standard](#the-distributional-standard) described above. Neither is wrong; they reflect the natural variance in human judgment.

2. **The specialist must assume any human answer is valid.** It cannot distinguish between "this human made an error" and "this human has context I lack," so any individual human response must be treated as a legitimate sample from the distribution.

### What About Multi-Stakeholder Decisions?

When a domain genuinely requires multiple humans to agree (e.g., two reviewers must both approve a PR), this is modeled as **separate states in the machine**, not as competing votes at the same state. Each reviewer's decision is its own decision point, and each advances the machine independently:

```mermaid
graph LR
    S1[PR Submitted] -->|"Reviewer A decides"| S2[First Review Complete]
    S2 -->|"Reviewer B decides"| S3[Both Reviews Complete]
    S3 -->|"Merge / Request Changes"| S4[Resolved]
```

Human disagreement between reviewers is resolved by human mechanisms (escalation, authority structures, negotiation), at the process design level, not inside DIAL arbitration. The framework does not pretend to solve organizational disagreement; it identifies it as outside the scope of AI-human calibration.

## Practical Implementation

### Human Override in Arbitration

DIAL implements human primacy in the `evaluateConsensus` function. When a human specialist votes, their choice wins immediately:

```typescript
import { registerVoter, submitVote, evaluateConsensus } from "dialai";

// Any specialist with "human" in the ID triggers the override
registerVoter({
  specialistId: "human-reviewer",
  machineName: "code-review",
  strategyFn: async (ctx) => ({
    voteFor: "B",
    reasoning: "Proposal B provides more constructive feedback",
  }),
});
```

When `evaluateConsensus` runs, it checks every vote. If any vote's `specialistId` contains "human" (case-insensitive), that vote's choice wins immediately, regardless of all other votes:

```
AI Voter 1: votes A
AI Voter 2: votes A
AI Voter 3: votes A
Human:      votes B

Result: B wins immediately
```

## Common Objections

### "But this optimizes the AI to reproduce human errors"

The baseline isn't perfection; it's the human already making those decisions. If a specialist reproduces human behavior including human mistakes, the outcome is no worse than the status quo. What's changed is the cost: the decision is now faster and cheaper.

More precisely, the specialist optimizes to match the **distribution** a population of competent humans would produce. Individual errors are noise in that distribution; the distribution clusters around the correct answer. To push accuracy beyond it, the path runs through the humans: better training, clearer decision prompts, tighter process design.

Human primacy does not prevent error correction; it defines *who* corrects. Humans can curate which past decisions serve as reference points, excluding recognized mistakes. Nothing in DIAL prevents a review step where AI surfaces patterns that *may* indicate systematic errors. The constraint is that the human decides whether to act on those observations, not the AI.

### "But what about systematic bias?"

If you are concerned that human decisions at a particular state exhibit a systematic bias (for example, demographic bias in a hiring decision), the answer is not to let the AI override the human. The answer is to **add a state to the machine** that explicitly checks for that bias.

State machines are designed, not discovered. If your domain has known failure modes, you design states that address them: a fairness review step, a compliance check, a second-opinion gate. The framework provides the mechanism (state machine design) to incorporate whatever checks the organization requires. The bias correction happens in the process architecture, not in an AI silently second-guessing the human at runtime.

### "But sometimes the AI is objectively right"

Define "objectively." From whose perspective? With what information?

The AI operates on a subset of reality. When it seems "objectively right," that assessment is made from within its limited context. The human may have information that changes the entire picture.

### "But what happens when human preferences shift?"

Progressive collapse assumes stationary conditions: that the human distribution stays stable long enough for specialists to converge on it. In practice, human preferences shift constantly (new employees, changing strategies, evolving markets, policy updates).

Non-stationarity is not a failure mode; it is what the system is designed to detect. The human who participates periodically provides ongoing ground truth. When the population distribution shifts, agreement rates between specialists and human references visibly decline. When agreement drops, the system's response is mechanical: the ahead-by-k consensus threshold becomes harder to reach, the system re-expands (soliciting more proposals, more votes, more human participation), and then re-converges on the new distribution through the same measurement process that produced the original collapse.

Organizations in genuinely non-stationary environments will see shorter periods of collapsed execution and more frequent re-calibration cycles. DIAL makes that cost visible rather than hiding it.

### "This slows down automation"

Yes, initially. But measuring AI alignment with human judgment over time can inform when to reduce human involvement. Human primacy ensures that automation is earned, not assumed.

### "What about clear AI advantages (calculation, etc.)?"

For tasks where AI has clear advantages (arithmetic, data lookup, pattern matching on defined criteria), those are deterministic computations, not judgment calls. Human primacy applies to **judgment calls**, not computation.

## Related Concepts

- [Specialists](./specialists.md): How specialists participate
- [Arbitration](./arbitration.md): Consensus mechanisms
- [Decision Cycle](./decision-cycle.md): The process that implements human primacy

---

## Core Concepts


DIAL provides a structured approach to AI-human collaboration built around a few key abstractions.

## Overview

```mermaid
graph TB
    subgraph "Session (State Machine Instance)"
        SM[Machine Definition]
        CS[Current State]
    end

    subgraph "Specialists"
        H[Human Specialists]
        AI[AI Specialists]
    end

    subgraph "Decision Cycle"
        P[Proposers]
        V[Voters]
        A[Arbitration]
    end

    SM --> CS
    CS --> P
    H --> P
    AI --> P
    P --> V
    V --> A
    A --> |Execute| CS
```

## The Big Picture

DIAL coordinates **specialists** (both AI and human) to navigate **state machines** through **decision cycles**.

### Sessions & State Machines

A **session** is an instance of a state machine. The machine definition specifies:
- A **`machineName`** identifying the type
- An **`initialState`** where sessions begin
- A **`defaultState`** (the goal state)
- A set of **states**, each with optional `prompt` and `transitions`

When a session is not in its default state, specialists work together to get it there.

[Learn more about Sessions →](./sessions.md)

### Specialists

**Specialists** are the pluggable actors that participate in sessions:

| Role | Description | Can be AI? | Can be Human? |
|------|-------------|------------|---------------|
| **Proposer** | Analyzes state, suggests transitions | Yes | Yes |
| **Voter** | Compares proposals, expresses preferences | Yes | Yes |
| **Arbiter** | Evaluates consensus (built-in) | No | No |

The Arbiter is always a fully deterministic, built-in component, never an AI model or a human. This is a deliberate safety constraint: the mechanism that decides whether consensus has been reached must be predictable and auditable.

Human specialists are identified by including "human" (case-insensitive) in their `specialistId`. Human votes override AI votes immediately.

[Learn more about Specialists →](./specialists.md)

### The Decision Cycle

When a session needs to progress, DIAL runs a repeating cycle:

1. **Propose**: Solicit proposals from registered proposers
2. **Vote**: If 2+ proposals, compare pairs via registered voters
3. **Arbitrate**: Evaluate consensus via voting
4. **Execute**: Apply the winning proposal's transition

```mermaid
stateDiagram-v2
    [*] --> Propose
    Propose --> Vote: 2+ proposals
    Propose --> Arbitrate: 1 proposal
    Vote --> Arbitrate
    Arbitrate --> Execute: Consensus
    Arbitrate --> Error: No Consensus
    Execute --> [*]: Default State
    Execute --> Propose: Continue
```

[Learn more about the Decision Cycle →](./decision-cycle.md)

### Arbitration & Consensus

**Arbitration** is how DIAL decides when a proposal has won. The built-in strategy uses voting:

- **0 proposals**: No consensus
- **1 proposal**: Auto-consensus (single proposal wins)
- **2+ proposals**: Human votes win immediately; otherwise tally votes per proposal, leading proposal must be ahead by k=1 votes

[Learn more about Arbitration →](./arbitration.md)

### Human Primacy

The fundamental principle underlying DIAL:

> **The human is always right, not because humans are infallible, but because humans have context that AI cannot access.**

AI specialists are judged on their ability to predict what humans would choose. When a human specialist votes, that vote wins immediately regardless of AI votes.

[Learn more about Human Primacy →](./human-primacy.md)

## Quick Reference

### Vote Options

When comparing proposals A and B, specialists vote:
- **A**: Prefer proposal A
- **B**: Prefer proposal B
- **BOTH**: Both are acceptable (counts for both)
- **NEITHER**: Both are unacceptable (counts for neither)

## Next Steps

Dive deeper into each concept:

- [Sessions](./sessions.md): State machine instances
- [Specialists](./specialists.md): AI and human actors
- [Decision Cycle](./decision-cycle.md): The decision process
- [Arbitration](./arbitration.md): Consensus strategies
- [Human Primacy](./human-primacy.md): The foundational principle
- [Related Work](./related-work.md): How DIAL relates to other approaches

---

## Related Work


DIAL solves a different problem than most AI frameworks. Understanding the distinction helps clarify what DIAL is, and what it isn't.

## What DIAL Is

DIAL is a **measurement and delegation harness**. It answers the question: *can this AI specialist reliably predict what this human would choose, in this specific context?* When the answer is yes (empirically demonstrated over repeated decisions), DIAL progressively delegates. When alignment degrades, it reverts.

DIAL is not an agent framework, an alignment technique, or a model architecture. It can **wrap** any of them.

## How DIAL Relates to Other Approaches

The key dimension of comparison is **where ground truth comes from**: the signal used to judge whether AI behavior is correct.

| Approach | Ground truth source | When trust is established | Can trust change at runtime? |
|----------|---------------------|---------------------------|------------------------------|
| LangGraph / LangChain | Designer's predefined graph | Before deployment | No |
| Multi-agent debate | Human judges per decision | Each decision | No (static) |
| Constitutional AI / RLHF | Offline training signal | Training time | No |
| Mixture of Experts | Gating network | Training time | No |
| **DIAL** | **Human's actual runtime choices** | **Empirically, per decision cycle** | **Yes (progressive collapse + trip line)** |

### Agent Frameworks (LangGraph, LangChain, CrewAI)

Agent frameworks define **how** an AI system operates: the graph of states, tools, and control flow. DIAL defines **whether** an AI system should be trusted to operate autonomously at each decision point.

These are complementary. A DIAL specialist can *be* a LangGraph agent. DIAL wraps the agent and measures whether its decisions match human choices. The agent framework handles execution; DIAL handles trust calibration.

### Multi-Agent Debate

Multi-agent debate uses multiple AI models to argue and a human to judge. DIAL's voting mechanism is superficially similar, but the purpose differs: debate aims to improve answer quality through adversarial argument; DIAL aims to measure which specialist best predicts the human, with the goal of eventually removing the human from routine decisions.

### Constitutional AI / RLHF

Constitutional AI and RLHF train models against offline signals: a constitution document or human preference data collected in advance. The trust relationship is fixed at training time. DIAL's ground truth is the human's live, runtime choices in a specific operational context. Trust evolves continuously, per-specialist, per-state. A constitutionally-trained model can serve as a DIAL specialist; DIAL then measures whether the training generalizes to this particular human's preferences.

### Mixture of Experts (MoE)

MoE architectures route inputs to specialized sub-networks via a learned gating function. The analogy to DIAL's specialist selection is real but shallow: MoE routing is learned at training time and frozen; DIAL's trust in specialists updates at runtime based on human feedback. MoE optimizes for task performance; DIAL optimizes for human prediction.

## Using DIAL with Other Systems

DIAL is designed to be wrapped around existing AI systems, not to replace them:

- **Your agent framework** handles task execution, tool calls, and control flow
- **Your model** handles reasoning, generation, and tool use
- **DIAL** handles the question: *should this agent/model be trusted to act autonomously here, or does a human need to decide?*

The specialist interface is intentionally minimal: anything that can propose a state transition and compare two proposals can participate in DIAL's decision cycle.

---

## Sessions


A **session** is an instance of a state machine that specialists navigate through decision cycles.

## What Is a Session?

A session has:

- A **machine definition**: the blueprint defining possible states and transitions
- A **current state**: where the session is right now
- A **session ID**: a unique UUID generated at creation
- A **creation timestamp**: when the session was started

```mermaid
graph LR
    subgraph Session
        D[Machine Definition]
        C[Current State]
        I[Session ID]
        T[Created At]
    end
```

## Session Lifecycle

### 1. Creation

A session starts with the `createSession` function:

```typescript
import { createSession } from "dialai";
import type { MachineDefinition } from "dialai";

const machine: MachineDefinition = {
  machineName: "document-review",
  initialState: "pending",
  defaultState: "approved",
  states: {
    pending: {
      prompt: "Review the document and decide: approve or request changes.",
      transitions: {
        approve: "approved",
        request_changes: "needs_revision",
      },
    },
    needs_revision: {
      prompt: "Review the revised document. Has the author addressed the feedback?",
      transitions: {
        approve: "approved",
        request_more_changes: "needs_revision",
      },
    },
    approved: {},
  },
};

const session = createSession(machine);
// session.sessionId     → "a1b2c3d4-..."
// session.currentState  → "pending"
// session.createdAt     → Date
```

The session is created in its `initialState`.

### 2. Progression

When a session is **not in its default state**, the decision cycle activates:

1. Specialists propose transitions
2. Proposals are compared through voting (if 2+)
3. Consensus is evaluated
4. The winning transition executes

### 3. Completion

A session is "complete" when it reaches its **`defaultState`**.

## Machine Definition

Each session has a `MachineDefinition` that defines its structure:

```typescript
interface MachineDefinition {
  machineName: string;
  initialState: string;
  defaultState: string;
  states: Record<string, {
    prompt?: string;
    transitions?: Record<string, string>;
  }>;
}
```

### Fields

| Field | Description |
|-------|-------------|
| `machineName` | Identifies the type of session (e.g., `"document-review"`) |
| `initialState` | The state a session starts in |
| `defaultState` | The goal state; session is complete when it reaches this |
| `states` | A record of state names to their configuration |

### State Configuration

Each state can have:
- **`prompt`**: A description of the decision to be made in this state. Given to specialists to guide their proposals.
- **`transitions`**: A map of transition names to target states. If omitted, the state is terminal (no outgoing transitions).

### Decision Prompts

Each state's `prompt` describes the decision to be made. This prompt is:
- Given to all specialists (AI and human)
- Specialist-agnostic (same instructions for everyone)
- The source of truth for how to decide

## Querying Sessions

```typescript
import { getSession, getSessions } from "dialai";

// Get a specific session by ID
const session = getSession("a1b2c3d4-...");

// Get all sessions
const allSessions = getSessions();
```

## Session Types

A **session type** identifies which kind of machine is being run:

```typescript
machineName: "document-review"
machineName: "code-review"
machineName: "support-ticket"
```

Different session types have:
- Different machine definitions
- Different registered specialists

## Best Practices

### 1. Design Clear Default States

The default state should represent "done" or "stable":
- `approved`, `completed`, `resolved`
- Not `processing`, `in_progress`, `waiting`

### 2. Use Descriptive Decision Prompts

Good prompts are specific and actionable:

```
"Review the code changes. Check for: 1) correctness, 2) test coverage,
 3) documentation. Approve if all criteria met, otherwise request changes."

Not: "Decide what to do next."
```

### 3. Name Transitions Clearly

Transition names should describe the action being taken:

```typescript
transitions: {
  approve: "approved",        // Clear action
  request_changes: "needs_revision",
  reject: "rejected",
}
```

## Next Steps

- [Specialists](./specialists.md): Learn about the actors that navigate sessions
- [Decision Cycle](./decision-cycle.md): Understand how decisions are made

---

## Specialists


Specialists are the "pluggable" actors that participate in sessions. They can be AI models or humans.

## Roles

### Proposers

Proposers analyze the current state and suggest what transition should happen next. Any number of proposers can participate. A proposer's `strategyFn` receives a `ProposerContext` and returns a proposed transition.

### Voters

Voters evaluate proposals and express preferences between them. They compare pairs of proposals and vote for A, B, BOTH, or NEITHER. A voter's `strategyFn` receives a `VoterContext` and returns a vote choice.

### Arbiters

Arbitration is built into the framework via the `evaluateConsensus` function. For custom consensus logic, register an arbiter with `registerArbiter` and a `strategyFn` that receives an `ArbiterContext` and returns a `ConsensusResult`.

## Human vs AI Specialists

**Human specialists** are identified by including "human" (case-insensitive) anywhere in their `specialistId` (e.g., `human-reviewer`, `specialist.human.jane`). When a human specialist votes, their choice wins immediately; no further vote tallying is needed.

**AI specialists** participate through voting. Each vote counts equally.

## Registering Specialists

```typescript
import { registerProposer, registerVoter } from "dialai";

// Register a proposer with an inline strategy
registerProposer({
  specialistId: "ai-proposer-1",
  machineName: "my-task",
  strategyFn: async (ctx) => {
    const name = Object.keys(ctx.transitions)[0];
    return {
      transitionName: name,
      toState: ctx.transitions[name],
      reasoning: "First available transition",
    };
  },
});

// Register a voter
registerVoter({
  specialistId: "ai-voter-1",
  machineName: "my-task",
  strategyFn: async (ctx) => ({
    voteFor: "A",
    reasoning: "Proposal A moves closer to the goal",
  }),
});
```

### Registration Options

Each registration function (`registerProposer`, `registerVoter`, `registerArbiter`) accepts:

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `specialistId` | `string` | Yes | Unique identifier. Include "human" for human specialists. |
| `machineName` | `string` | Yes | Which session type this specialist participates in |
| `strategyFn` | `async (context) => result` | Mode 1 | Local function that returns a proposal, vote, or ConsensusResult |
| `strategyWebhookUrl` | `string` | Mode 2 | URL to POST context to; expects result response |
| `contextFn` | `async (context) => string` | Mode 3 | Local function returning context for the LLM |
| `contextWebhookUrl` | `string` | Mode 4 | URL to POST context request to; expects context response |
| `modelId` | `string` | Modes 3, 4 | LLM model identifier |
| `webhookTokenName` | `string` | Modes 2, 4 | Env var name holding the webhook auth token |

All three registration functions support the same four execution modes. See the [registering specialists guide](../guides/registering-specialists.md) for full details.

---

## Examples


This section contains example implementations demonstrating DialAI usage.

## Simple Machine

The repository includes a minimal example at `examples/simple-machine.json`:

```json
{
  "machineName": "simple-task",
  "initialState": "pending",
  "defaultState": "done",
  "states": {
    "pending": {
      "prompt": "Should we complete this task?",
      "transitions": { "complete": "done" }
    },
    "done": {}
  }
}
```

Run it with the CLI:

```bash
node dist/dialai/cli.js examples/simple-machine.json
```

Output:
```
Machine:       simple-task
Initial state: pending
Goal state:    done
Final state:   done
Session ID:    a1b2c3d4-...
```

## Programmatic Usage

```typescript
import { runSession } from "dialai";
import type { MachineDefinition } from "dialai";

const machine: MachineDefinition = {
  machineName: "simple-task",
  initialState: "pending",
  defaultState: "done",
  states: {
    pending: {
      prompt: "Should we complete this task?",
      transitions: { complete: "done" },
    },
    done: {},
  },
};

const session = await runSession(machine);
console.log(session.currentState); // "done"
```

## Multi-Step Machine

A 3-state machine that requires 2 cycles to reach the goal:

```typescript
const pipeline: MachineDefinition = {
  machineName: "pipeline",
  initialState: "queued",
  defaultState: "complete",
  states: {
    queued: {
      prompt: "Start processing?",
      transitions: { start: "processing" },
    },
    processing: {
      prompt: "Processing complete. Finalize?",
      transitions: { finalize: "complete" },
    },
    complete: {},
  },
};

const session = await runSession(pipeline);
// queued → processing → complete
```

## Custom Specialists Example

```typescript
import {
  createSession,
  registerProposer,
  registerVoter,
  solicitProposal,
  solicitVote,
  evaluateConsensus,
  executeTransition,
  clear,
} from "dialai";
import type { MachineDefinition } from "dialai";

clear(); // Reset state

const machine: MachineDefinition = {
  machineName: "review",
  initialState: "pending",
  defaultState: "approved",
  states: {
    pending: {
      transitions: {
        approve: "approved",
        reject: "rejected",
        revise: "pending",
      },
    },
    approved: {},
    rejected: {},
  },
};

// Two proposers that disagree
registerProposer({
  specialistId: "optimist",
  machineName: "review",
  strategyFn: async (ctx) => ({
    transitionName: "approve",
    toState: "approved",
    reasoning: "Looks good to me",
  }),
});

registerProposer({
  specialistId: "pessimist",
  machineName: "review",
  strategyFn: async (ctx) => ({
    transitionName: "reject",
    toState: "rejected",
    reasoning: "Needs more work",
  }),
});

// A voter that prefers approval
registerVoter({
  specialistId: "tiebreaker",
  machineName: "review",
  strategyFn: async (ctx) => {
    if (ctx.proposalA.toState === "approved") return { voteFor: "A", reasoning: "Approve" };
    if (ctx.proposalB.toState === "approved") return { voteFor: "B", reasoning: "Approve" };
    return { voteFor: "NEITHER", reasoning: "Neither approves" };
  },
});

const session = createSession(machine);

// Solicit from both proposers
const p1 = await solicitProposal(session.sessionId, "optimist");
const p2 = await solicitProposal(session.sessionId, "pessimist");

// Solicit vote
await solicitVote(session.sessionId, "tiebreaker", p1.proposalId, p2.proposalId);

// Evaluate and execute
const result = evaluateConsensus(session.sessionId);
if (result.consensusReached && result.winningProposalId) {
  const winner = [p1, p2].find((p) => p.proposalId === result.winningProposalId)!;
  executeTransition(session.sessionId, winner.transitionName, winner.toState, result.reasoning);
}

console.log(session.currentState); // "approved"
```

---

## Installation


Get DIAL up and running in your project.

## Prerequisites

- **Node.js** 18+ (LTS recommended)
- **npm** or **pnpm** or **yarn**
- **TypeScript** 5.0+ (recommended)

## Quick Install

```bash
# Using npm
npm install dialai

# Using pnpm
pnpm add dialai

# Using yarn
yarn add dialai
```

## Project Setup

### 1. Initialize a New Project

If you're starting fresh:

```bash
mkdir my-dial-project
cd my-dial-project
npm init -y
npm install dialai typescript @types/node tsx
npx tsc --init
```

### 2. Configure TypeScript

Ensure your `tsconfig.json` includes:

```json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "NodeNext",
    "moduleResolution": "NodeNext",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "outDir": "./dist"
  },
  "include": ["src/**/*"]
}
```

### 3. Add `"type": "module"` to package.json

DIAL is an ESM package:

```json
{
  "type": "module"
}
```

## Verify Installation

Create a test file to verify everything works:

```typescript
// src/test-install.ts
import { createSession, runSession } from "dialai";
import type { MachineDefinition } from "dialai";

const machine: MachineDefinition = {
  machineName: "test",
  initialState: "start",
  defaultState: "end",
  states: {
    start: { transitions: { finish: "end" } },
    end: {},
  },
};

const session = runSession(machine);
console.log("DIAL installed successfully!");
console.log("Session reached:", session.currentState); // "end"
```

Run it:

```bash
npx tsx src/test-install.ts
```

You should see:
```
DIAL installed successfully!
Session reached: end
```

## CLI Usage

DIAL includes a CLI that runs a machine JSON file to completion:

```bash
npx dialai machine.json
```

See [Quick Start](./quick-start.md) for a full example.

## What's Next?

Now that DIAL is installed, you're ready to:

1. **[Quick Start](./quick-start.md)**: Build your first state machine with AI and human specialists
2. **[Learn Concepts](../concepts/intro.md)**: Understand sessions, specialists, and decision cycles
3. **[Build State Machines](../guides/state-machines.md)**: Model your tasks as state machines

## Troubleshooting

### "Module not found" errors

Ensure you're using a compatible Node.js version:

```bash
node --version  # Should be 18+
```

### TypeScript compilation errors

Make sure your tsconfig uses `NodeNext` module resolution:

```json
{
  "compilerOptions": {
    "module": "NodeNext",
    "moduleResolution": "NodeNext"
  }
}
```

### ESM/CJS issues

DIAL is an ESM package. If you're in a CommonJS project, either:

1. Add `"type": "module"` to your `package.json`, or
2. Use dynamic imports:

```typescript
const { runSession } = await import("dialai");
```

### Need help?

- Check the [GitHub Issues](https://github.com/eloquentanalytics/dialai/issues)
- Search existing discussions
- Open a new issue with your error details

---

## Quick Start


Build your first DIAL state machine with specialists.

## What We'll Build

A trivially simple machine that asks "Should we complete this task?" and transitions from `pending` to `done`:

```mermaid
stateDiagram-v2
    [*] --> pending
    pending --> done: complete
    done --> [*]
```

## Step 1: Define the Machine

Save this as `examples/simple-machine.json`:

```json
{
  "machineName": "simple-task",
  "initialState": "pending",
  "defaultState": "done",
  "states": {
    "pending": {
      "prompt": "Should we complete this task?",
      "transitions": { "complete": "done" }
    },
    "done": {}
  }
}
```

- **`initialState`**: where the session starts (`pending`)
- **`defaultState`**: the goal state where the machine comes to rest (`done`)
- **`prompt`**: the question specialists answer when the session is in that state
- **`transitions`**: the available answers and what state each leads to

Only one transition (`complete`) leads to `done`, so the machine always resolves in one cycle.

Or define the same thing in TypeScript:

```typescript
import type { MachineDefinition } from "dialai";

const machine: MachineDefinition = {
  machineName: "simple-task",
  initialState: "pending",
  defaultState: "done",
  states: {
    pending: {
      prompt: "Should we complete this task?",
      transitions: { complete: "done" },
    },
    done: {},
  },
};
```

## Step 2: Run It

The quickest way to run a machine is with `runSession`, which registers a built-in proposer that picks the first available transition:

```typescript
import { runSession } from "dialai";

const session = await runSession(machine);

console.log(session.currentState); // "done"
```

That's it. One cycle, done.

## Step 3: Add a Human Specialist

The real point of DIAL is that humans can participate. Let's walk through the full API to see how a human votes to complete the task.

```typescript
import {
  createSession,
  submitProposal,
  submitVote,
  evaluateConsensus,
  executeTransition,
} from "dialai";

// Create a session - starts in "pending"
const session = createSession(machine);
console.log(session.currentState); // "pending"

// Two specialists each submit a proposal
const proposalComplete = submitProposal(
  session.sessionId,
  "ai-specialist",
  "complete",
  "done",
  "The task is ready to complete"
);

const proposalWait = submitProposal(
  session.sessionId,
  "contrarian-ai",
  "complete",
  "done",
  "I agree, let's complete it"
);

// A human votes for proposal A (complete)
submitVote(
  session.sessionId,
  "human-reviewer",
  proposalComplete.proposalId,
  proposalWait.proposalId,
  "A",
  "Yes, let's complete this task"
);

// Evaluate consensus - human votes win immediately
const consensus = evaluateConsensus(session.sessionId);
console.log(consensus.consensusReached); // true
console.log(consensus.reasoning);        // "The human preferred: done"

// Execute the winning transition, recording the arbiter's reasoning
executeTransition(session.sessionId, "complete", "done", consensus.reasoning);
console.log(session.currentState); // "done"
console.log(session.history);      // [{ fromState: "pending", toState: "done", reasoning: "The human preferred: done", ... }]
```

Because the specialist ID `"human-reviewer"` contains "human", `evaluateConsensus` gives their vote priority. This is **human primacy**: humans always get the final say.

## Step 4: Use the CLI

Run a machine definition from the command line:

```bash
node dist/dialai/cli.js examples/simple-machine.json
```

Output:
```
Machine:       simple-task
Initial state: pending
Goal state:    done
Final state:   done
Session ID:    a1b2c3d4-...
```

## What's Happening Under the Hood

1. **Session created** in `initialState` (`pending`)
2. **Proposers solicited**: each returns a proposed transition (`complete`)
3. **Votes solicited** (if 2+ proposals): pairwise comparisons
4. **Consensus evaluated**: human votes override; otherwise ahead-by-k
5. **Transition executed**: `currentState` moves to `done`, proposals/votes cleared
6. **Cycle repeats** until `currentState === defaultState` (already there, done)

## Next Steps

- **[State Machines](../guides/state-machines.md)**: Design more complex workflows
- **[Registering Specialists](../guides/registering-specialists.md)**: Configure specialists with strategies
- **[Implementing Strategies](../guides/implementing-strategies.md)**: Customize strategy functions
- **[Concepts](../concepts/intro.md)**: Deep dive into DIAL's architecture

---

## Implementing Strategies


Strategies are async functions that define how specialists make decisions. Each specialist is registered with a `strategyFn` that gets called during the decision cycle.

## Proposer Strategy

A proposer `strategyFn` receives a `ProposerContext` and returns a transition choice:

```typescript
const myProposer = async (ctx: ProposerContext) => {
  // ctx.currentState: string - the session's current state name
  // ctx.prompt: string - the decision prompt from the state definition
  // ctx.transitions: Record<string, string> - maps transition name to target state
  // ctx.history: TransitionRecord[] - prior transitions in this session

  // Your logic here: call an LLM, apply rules, etc.

  return {
    transitionName: "complete",
    toState: "done",
    reasoning: "Task is ready to be completed",
  };
};
```

### Proposer strategyFn Signature

```typescript
strategyFn: async (ctx: ProposerContext) => {
  transitionName: string;
  toState: string;
  reasoning: string;
}
```

### Example: Pick the First Transition

```typescript
const firstTransition = async (ctx: ProposerContext) => {
  const name = Object.keys(ctx.transitions)[0];
  return {
    transitionName: name,
    toState: ctx.transitions[name],
    reasoning: "First available transition",
  };
};
```

### Example: Goal-Directed Proposer

```typescript
const goalDirected = async (ctx: ProposerContext) => {
  // Prefer transitions that lead to the goal state
  for (const [name, target] of Object.entries(ctx.transitions)) {
    if (target === "done" || target === "approved" || target === "completed") {
      return {
        transitionName: name,
        toState: target,
        reasoning: `Transition "${name}" leads directly to goal state "${target}"`,
      };
    }
  }
  // Fallback to first transition
  const name = Object.keys(ctx.transitions)[0];
  return {
    transitionName: name,
    toState: ctx.transitions[name],
    reasoning: "No direct path to goal; taking first available transition",
  };
};
```

## Voter Strategy

A voter `strategyFn` receives a `VoterContext` and returns a preference:

```typescript
const myVoter = async (ctx: VoterContext) => {
  // ctx.proposalA, ctx.proposalB: Proposal objects with:
  //   proposalId, sessionId, specialistId, transitionName, toState, reasoning
  // ctx.currentState: string
  // ctx.prompt: string
  // ctx.history: TransitionRecord[]

  // Your logic to compare proposals

  return {
    voteFor: "A", // "A" | "B" | "BOTH" | "NEITHER"
    reasoning: "Proposal A better aligns with the decision criteria",
  };
};
```

### Voter strategyFn Signature

```typescript
strategyFn: async (ctx: VoterContext) => {
  voteFor: VoteChoice; // "A" | "B" | "BOTH" | "NEITHER"
  reasoning: string;
}
```

### Example: Prefer Goal-Reaching Proposals

```typescript
const goalVoter = async (ctx: VoterContext) => {
  const aReachesGoal = ctx.proposalA.toState === "done";
  const bReachesGoal = ctx.proposalB.toState === "done";

  if (aReachesGoal && !bReachesGoal) {
    return { voteFor: "A", reasoning: "Proposal A reaches the goal state" };
  }
  if (bReachesGoal && !aReachesGoal) {
    return { voteFor: "B", reasoning: "Proposal B reaches the goal state" };
  }
  if (aReachesGoal && bReachesGoal) {
    return { voteFor: "BOTH", reasoning: "Both proposals reach the goal" };
  }
  return { voteFor: "NEITHER", reasoning: "Neither proposal reaches the goal" };
};
```

## Arbiter Strategy

An arbiter `strategyFn` receives an `ArbiterContext` and returns a `ConsensusResult`:

```typescript
const myArbiter = async (ctx: ArbiterContext) => {
  // ctx.proposals: Proposal[] - all proposals in the session
  // ctx.votes: Vote[] - all votes in the session
  // ctx.currentState: string
  // ctx.history: TransitionRecord[]

  // Custom consensus logic
  const topProposal = ctx.proposals[0];
  return {
    consensusReached: true,
    winningProposalId: topProposal?.proposalId,
    reasoning: "Custom arbiter selected the first proposal",
  };
};
```

### Arbiter strategyFn Signature

```typescript
strategyFn: async (ctx: ArbiterContext) => ConsensusResult
```

## Using Strategies with Specialists

Register strategies when creating specialists:

```typescript
import { registerProposer, registerVoter, registerArbiter } from "dialai";

registerProposer({
  specialistId: "goal-proposer",
  machineName: "my-task",
  strategyFn: goalDirected,
});

registerVoter({
  specialistId: "goal-voter",
  machineName: "my-task",
  strategyFn: goalVoter,
});

registerArbiter({
  specialistId: "custom-arbiter",
  machineName: "my-task",
  strategyFn: myArbiter,
});
```

## Direct Submission

You can also bypass strategies and submit proposals or votes directly:

```typescript
import { submitProposal, submitVote } from "dialai";

// Submit a proposal without a registered strategy
const proposal = submitProposal(
  sessionId,
  "manual-proposer",
  "approve",
  "approved",
  "Manually approved after review"
);

// Submit a vote directly
const vote = submitVote(
  sessionId,
  "manual-voter",
  proposalA.proposalId,
  proposalB.proposalId,
  "A",
  "Prefer proposal A"
);
```

---

## Registering Specialists


Specialists are registered using one of three functions: `registerProposer`, `registerVoter`, or `registerArbiter`. Each function accepts configuration for how the specialist produces its output.

## Proposer Registration

A proposer analyzes the current state and suggests what transition should happen next.

```typescript
import { registerProposer } from "dialai";

registerProposer({
  specialistId: "ai-proposer-1",
  machineName: "my-task",
  strategyFn: async (ctx) => {
    const name = Object.keys(ctx.transitions)[0];
    return {
      transitionName: name,
      toState: ctx.transitions[name],
      reasoning: "First available transition",
    };
  },
});
```

## Voter Registration

A voter evaluates pairs of proposals and expresses a preference.

```typescript
import { registerVoter } from "dialai";

registerVoter({
  specialistId: "quality-voter",
  machineName: "my-task",
  strategyFn: async (ctx) => ({
    voteFor: "A",
    reasoning: "Proposal A is more aligned with the goal",
  }),
});
```

## Arbiter Registration

An arbiter defines custom consensus logic. It receives all proposals and votes and returns a `ConsensusResult`. Arbiters support the same four execution modes as proposers and voters.

```typescript
import { registerArbiter } from "dialai";

registerArbiter({
  specialistId: "custom-arbiter",
  machineName: "my-task",
  strategyFn: async (ctx) => {
    // ctx contains proposals, votes, history
    const topProposal = ctx.proposals[0];
    return {
      consensusReached: true,
      winningProposalId: topProposal?.proposalId,
      reasoning: "Custom logic selected the first proposal",
    };
  },
});
```

## Execution Modes

All three registration functions support four execution modes. They are mutually exclusive.

### 1. `strategyFn` -- Local Function

You provide an async function. The orchestrator calls it with the appropriate context and expects a complete proposal or vote back.

```typescript
registerProposer({
  specialistId: "my-proposer",
  machineName: "document-review",
  strategyFn: async (ctx) => ({
    transitionName: "approve",
    toState: "approved",
    reasoning: "Document meets all criteria",
  }),
});
```

What happens inside the function is entirely up to you. Call your own LLM, apply rules, run deterministic logic. The orchestrator only checks that the return value matches the expected shape.

**Required parameters:** `strategyFn`
**Forbidden parameters:** `contextFn`, `contextWebhookUrl`, `strategyWebhookUrl`, `modelId`, `webhookTokenName`

### 2. `strategyWebhookUrl` -- Remote Function

The orchestrator POSTs the full context to a URL and expects a proposal or vote response. Authentication is HTTP Basic Auth: the username is the `machineName`, the password is the value of the environment variable named by `webhookTokenName`.

```typescript
registerProposer({
  specialistId: "remote-proposer",
  machineName: "document-review",
  strategyWebhookUrl: "https://my-service.example.com/propose",
  webhookTokenName: "MY_SERVICE_TOKEN",
});
```

```
POST https://my-service.example.com/propose
Authorization: Basic base64("document-review:${MY_SERVICE_TOKEN}")
Content-Type: application/json

{ ...ProposerContext }
```

#### Response Handling: 55-Second Window

The orchestrator waits up to 55 seconds for the webhook to respond.

- **If the webhook responds** with a JSON body containing a valid proposal or vote, the orchestrator submits it on the specialist's behalf.

  Proposer response:
  ```json
  { "transitionName": "approve", "toState": "approved", "reasoning": "Meets criteria" }
  ```

  Voter response:
  ```json
  { "voteFor": "A", "reasoning": "Proposal A is more faithful to the prompt" }
  ```

- **If the webhook does not respond within 55 seconds**, or responds with `202 Accepted`, the orchestrator moves on. The webhook is then responsible for calling the DIAL API (`submitProposal` or `submitVote`) at its own leisure.

**Required parameters:** `strategyWebhookUrl`, `webhookTokenName`
**Forbidden parameters:** `strategyFn`, `contextFn`, `contextWebhookUrl`, `modelId`

### 3. `contextFn` + `modelId` -- Local Context, Orchestrator Calls LLM

You provide an async function that returns a context string. The orchestrator sends that string to the LLM specified by `modelId` along with the decision prompt and parses the response into a proposal or vote.

```typescript
registerProposer({
  specialistId: "context-proposer",
  machineName: "document-review",
  modelId: "openai/gpt-4o-mini",
  contextFn: async (ctx) => {
    const doc = await readFile(ctx.prompt);
    return `Document contents:\n${doc}\n\nReview criteria: completeness, accuracy`;
  },
});
```

Your function only provides the context string. The orchestrator handles prompt assembly, the API call, response parsing, and validation.

**Required parameters:** `contextFn`, `modelId`
**Forbidden parameters:** `strategyFn`, `strategyWebhookUrl`, `contextWebhookUrl`, `webhookTokenName`

### 4. `contextWebhookUrl` + `modelId` -- Remote Context, Orchestrator Calls LLM

The orchestrator POSTs the context request to a URL, then sends the returned context to the LLM.

```typescript
registerVoter({
  specialistId: "webhook-context-voter",
  machineName: "document-review",
  modelId: "openai/gpt-4o-mini",
  contextWebhookUrl: "https://my-service.example.com/context",
  webhookTokenName: "MY_SERVICE_TOKEN",
});
```

The webhook response should contain a `content` or `markdown` field with the context string:

```json
{ "content": "Document contents:\n..." }
```

The orchestrator waits up to 55 seconds for the response. If the webhook does not respond in time, the orchestrator calls the LLM with no additional context.

**Required parameters:** `contextWebhookUrl`, `webhookTokenName`, `modelId`
**Forbidden parameters:** `strategyFn`, `strategyWebhookUrl`, `contextFn`

## Validation Rules

Valid parameter combinations:

| Mode | strategyFn | strategyWebhookUrl | contextFn | contextWebhookUrl | modelId | webhookTokenName |
|------|:---:|:---:|:---:|:---:|:---:|:---:|
| 1. Local strategy | required | | | | | |
| 2. Webhook strategy | | required | | | | required |
| 3. Local context + LLM | | | required | | required | |
| 4. Webhook context + LLM | | | | required | required | required |

Invalid configurations are rejected at registration time with descriptive error messages:

- `strategyFn` + `modelId` -- *"modelId is only used with contextFn or contextWebhookUrl. A strategyFn returns proposals/votes directly and does not need a model."*
- `contextFn` without `modelId` -- *"contextFn provides context for an LLM to generate proposals/votes. You must also specify modelId."*
- `strategyFn` + `contextFn` -- *"Provide either strategyFn (you handle everything) or contextFn + modelId (orchestrator calls the LLM), not both."*
- `contextWebhookUrl` without `webhookTokenName` -- *"Webhook URLs require webhookTokenName for authentication."*
- No execution parameters at all -- *"Specialist must specify one of: strategyFn, strategyWebhookUrl, contextFn + modelId, or contextWebhookUrl + modelId."*

## Context Shapes

### ProposerContext

```typescript
interface ProposerContext {
  sessionId: string;
  currentState: string;
  prompt: string;
  transitions: Record<string, string>;
  history: TransitionRecord[];
}
```

### VoterContext

```typescript
interface VoterContext {
  sessionId: string;
  currentState: string;
  prompt: string;
  proposalA: Proposal;
  proposalB: Proposal;
  history: TransitionRecord[];
}
```

### ArbiterContext

```typescript
interface ArbiterContext {
  sessionId: string;
  currentState: string;
  proposals: Proposal[];
  votes: Vote[];
  history: TransitionRecord[];
}
```

## Specialist ID Conventions

Any naming scheme works, but including the purpose is helpful:

```
ai-proposer-1
ai-voter-gpt4
human-reviewer
human-approver-jane
```

To enable the human override in `evaluateConsensus`, include "human" (case-insensitive) anywhere in the `specialistId`:

```typescript
// These all trigger human primacy:
registerVoter({ specialistId: "human-reviewer", ... });
registerVoter({ specialistId: "specialist.human.jane", ... });
registerVoter({ specialistId: "HUMAN_APPROVER", ... });
```

## Human Specialists

Human specialists can be registered with strategy functions that encode human preferences, or proposals/votes can be submitted directly via `submitProposal` and `submitVote`:

```typescript
// Register a human specialist with a strategy
registerVoter({
  specialistId: "human-reviewer",
  machineName: "document-review",
  strategyFn: async (ctx) => ({
    voteFor: "B",
    reasoning: "Prefer the more conservative approach",
  }),
});

// Or submit votes directly without a strategy
import { submitVote } from "dialai";

submitVote(
  session.sessionId,
  "human-reviewer",
  proposalA.proposalId,
  proposalB.proposalId,
  "B",
  "I prefer the more conservative approach"
);
```

## Registration Options Reference

| Field | Type | Required | Default | Description |
|-------|------|----------|---------|-------------|
| `specialistId` | `string` | Yes | -- | Unique identifier. Include "human" for human specialists. |
| `machineName` | `string` | Yes | -- | Which session type this specialist participates in |
| `strategyFn` | `async (context) => result` | Mode 1 | -- | Local function that returns a proposal, vote, or ConsensusResult |
| `strategyWebhookUrl` | `string` | Mode 2 | -- | URL to POST context to; expects proposal/vote response |
| `contextFn` | `async (context) => string` | Mode 3 | -- | Local function that returns context for the LLM |
| `contextWebhookUrl` | `string` | Mode 4 | -- | URL to POST context request to; expects context response |
| `modelId` | `string` | Modes 3, 4 | -- | LLM model identifier (e.g., `"openai/gpt-4o-mini"`) |
| `webhookTokenName` | `string` | Modes 2, 4 | -- | Env var name holding the webhook auth token |

---

## State Machines


State machines define the structure of your sessions. Each session type has its own machine definition.

## Why State Machines?

Every agentic AI system is a state machine: the agent occupies a state, takes an action, and transitions to a new state. Frameworks like LangGraph make this explicit: agents are graphs of states and edges. Even "open-ended" agent loops (observe → reason → act → observe) follow this structure.

DIAL makes the state machine explicit so that each transition becomes a **measurable decision point**. This doesn't limit what you can model; it clarifies *where decisions happen* so they can be calibrated. You don't need a DIAL decision point at every micro-step; you place them at the boundaries where delegation risk matters. An agent's internal tool-call loop can remain opaque. DIAL measures the outcomes at the states you care about.

This means open-ended tasks fit naturally:
- **Document generation**: Proposals *are* the candidate documents. Specialists propose drafts, voters compare them, the human picks or edits the winner.
- **Agentic workflows**: The default state is the agent's normal operating mode. It transitions out for decisions that need deliberation (tool selection, plan changes) and back when resolved.
- **Research and exploration**: Model as a loop: the agent explores, then a decision determines whether findings are sufficient or more exploration is needed.

## Defining a Machine

A `MachineDefinition` defines:

- `machineName`: identifies the type
- `initialState`: where sessions start
- `defaultState`: the goal state (session is complete when it reaches this)
- `states`: a record of state names to their configuration

## Example

```typescript
import type { MachineDefinition } from "dialai";

const myMachine: MachineDefinition = {
  machineName: "my-task",
  initialState: "idle",
  defaultState: "done",
  states: {
    idle: {
      prompt: "The system is idle. What should happen next?",
      transitions: {
        start: "working",
        configure: "configuring",
      },
    },
    configuring: {
      prompt: "Configuration in progress. Apply or cancel?",
      transitions: {
        apply: "working",
        cancel: "idle",
      },
    },
    working: {
      prompt: "The system is working. Should it continue or finish?",
      transitions: {
        finish: "done",
        reconfigure: "configuring",
      },
    },
    done: {},
  },
};
```

## Machine Definition as JSON

Machines can also be defined as plain JSON files, useful with the CLI:

```json
{
  "machineName": "simple-task",
  "initialState": "pending",
  "defaultState": "done",
  "states": {
    "pending": {
      "prompt": "Should we complete this task?",
      "transitions": { "complete": "done" }
    },
    "done": {}
  }
}
```

Run with the CLI:

```bash
node dist/dialai/cli.js my-machine.json
```

## State Configuration

Each state in the `states` record can have:

### `prompt` (optional)

A string describing the decision to be made in this state. This prompt guides specialists in choosing which transition to propose.

```typescript
states: {
  reviewing: {
    prompt: "Review the document. Approve if quality standards are met, otherwise request changes.",
    transitions: { approve: "approved", request_changes: "needs_revision" },
  },
}
```

### `transitions` (optional)

A record mapping transition names to target state names. If omitted, the state has no outgoing transitions (terminal state).

```typescript
transitions: {
  approve: "approved",        // transition "approve" → state "approved"
  request_changes: "needs_revision",
}
```

## Design Patterns

### Linear Workflow

```typescript
const linear: MachineDefinition = {
  machineName: "pipeline",
  initialState: "step1",
  defaultState: "complete",
  states: {
    step1: { transitions: { next: "step2" } },
    step2: { transitions: { next: "step3" } },
    step3: { transitions: { next: "complete" } },
    complete: {},
  },
};
```

### Review Loop

```typescript
const reviewLoop: MachineDefinition = {
  machineName: "review",
  initialState: "draft",
  defaultState: "published",
  states: {
    draft: {
      prompt: "Review the draft. Approve or request revisions?",
      transitions: {
        approve: "published",
        revise: "revising",
      },
    },
    revising: {
      prompt: "Revisions made. Submit for review?",
      transitions: { submit: "draft" },
    },
    published: {},
  },
};
```

### Branching Decisions

```typescript
const branching: MachineDefinition = {
  machineName: "triage",
  initialState: "incoming",
  defaultState: "resolved",
  states: {
    incoming: {
      prompt: "Triage this ticket: escalate, handle directly, or close?",
      transitions: {
        escalate: "escalated",
        handle: "in_progress",
        close: "resolved",
      },
    },
    escalated: {
      transitions: { resolve: "resolved" },
    },
    in_progress: {
      transitions: { resolve: "resolved", escalate: "escalated" },
    },
    resolved: {},
  },
};
```

### Agentic Workflow

An agent's operating loop modeled as a DIAL machine. The default state is the agent running normally: it transitions out when a decision needs deliberation, and back when resolved.

```typescript
const agentLoop: MachineDefinition = {
  machineName: "coding-agent",
  initialState: "operating",
  defaultState: "done",
  states: {
    operating: {
      prompt:
        "The agent is working. Should it continue, use a tool, replan, or finalize?",
      transitions: {
        use_tool: "tool_selection",
        replan: "planning",
        finalize: "done",
      },
    },
    tool_selection: {
      prompt: "Which tool should the agent use for this step?",
      transitions: { selected: "operating" },
    },
    planning: {
      prompt: "The current approach isn't working. What should the new plan be?",
      transitions: { resume: "operating" },
    },
    done: {},
  },
};
```

### Document Generation

For open-ended generation tasks, the specialist proposals *are* the candidate outputs. Voters compare drafts, and the human selects or edits the winner.

```typescript
const docGen: MachineDefinition = {
  machineName: "report-generation",
  initialState: "drafting",
  defaultState: "published",
  states: {
    drafting: {
      prompt:
        "Generate a draft of the report. Each proposal should be a complete draft.",
      transitions: {
        accept: "published",
        revise: "revising",
      },
    },
    revising: {
      prompt:
        "Revise the draft based on feedback. Each proposal should be a revised version.",
      transitions: {
        accept: "published",
        revise: "revising",
      },
    },
    published: {},
  },
};
```

## Decision Prompts

Each state's `prompt` describes how to decide what to do next. Good prompts are:

- **Specific**: List the available choices and criteria
- **Actionable**: Tell the specialist what to evaluate
- **Consistent**: Same instructions for all specialists (AI and human)

```
Good: "Review the code changes. Check for: 1) correctness, 2) test coverage,
      3) documentation. Approve if all criteria met, otherwise request changes."

Bad:  "Decide what to do next."
```

---

## Introduction to DIAL


**DIAL** (Dynamic Integration between AI and Labor) is a coordination framework for AI and human specialists making decisions together within state machines.

## Why DIAL?

The promise of AI is efficiency: faster, cheaper execution of narrow tasks. But the question organizations face isn't "Can AI do this?" It's:

> **How do you know, in dollars, time, and quality, exactly what it would cost to turn any task over to a minimally competent AI decision-maker? And how involved should humans remain as quality control?**

DIAL provides the answer through **empirical measurement**, not speculation.

## The Core Insight

An AI model operates on a bounded context window. A human operates on a **lifetime of embodied experience**, tacit knowledge, institutional context, and real-time sensory input that no model has access to. The human knows things they cannot tell the machine.

## Three Foundational Principles

### 1. Human Primacy

The human is always right, not because humans are infallible, but because humans have context that AI cannot access.

An AI specialist is judged on alignment with human choices. The standard is distributional: output should match the distribution a population of competent humans would produce for the same decision.

### 2. Progressive Collapse

Over repeated decision cycles, measuring how well AI predicts human choices causes the multi-agent deliberation structure to **progressively collapse into deterministic execution**.

This collapse is emergent, not designed. As AI specialists prove their alignment with human judgment through accumulated data, the expensive deliberation process naturally simplifies.

### 3. Empirical Trust

Trust is earned through demonstrated alignment with human decisions and through continued sampling of human preferences. Specialists prove their value one decision at a time.

## What DIAL Is Not

DIAL is not about AI replacing humans. It targets decisions that humans already make well and measures whether AI specialists can replicate those decisions cheaply enough to justify delegation, with precise cost data on ongoing human quality-control. The value of AI is not superiority. **It is efficiency.** AI is faster and cheaper at narrow tasks where the required context fits within the model's window.

## How It Works

1. **Model the task as a state machine**: Define states, transitions, and decision prompts
2. **Register proposers, voters, and arbiters**: AI and human specialists that propose transitions, vote on them, and define consensus logic
3. **Run decision cycles**: Propose, Vote, Arbitrate, Execute
4. **Reach the goal state**: The session completes when it reaches its `defaultState`

```mermaid
graph LR
    A[Propose] --> B[Vote]
    B --> C[Arbitrate]
    C --> D[Execute]
    D --> A
```

## What's Next?

  
    
      
        🚀 Get Started
      
      
        Install DIAL and run your first state machine with AI and human specialists.
        Installation Guide →
      
    
  
  
    
      
        📚 Learn Concepts
      
      
        Understand sessions, specialists, decision cycles, and arbitration strategies.
        Explore Concepts →
      
    
  

## Key Terminology

| Term | Definition |
|------|------------|
| **Session** | An instance of a state machine being navigated by specialists |
| **Specialist** | A pluggable actor (AI or human) that proposes transitions or votes |
| **Decision Cycle** | The repeating process: Propose, Vote, Arbitrate, Execute |
| **Arbiter** | The built-in logic that evaluates consensus and determines when a proposal wins |
| **Default State** | The goal state; the session is complete when it reaches this state |
